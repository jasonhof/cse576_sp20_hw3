2.2.1 Question
Q: Why might we be interested in both training accuracy and testing accuracy? What do these two numbers tell us about our current model?
A: The training and testing accuracy, and the rate they are changing on each pass relative to each other, can tell us about the way our model is currently fitting the data and can give us hints about its future performance.  For example, if we get a 

2.2.2 Question
Q: Try varying the model parameter for learning rate to different powers of 10 (i.e. 10^1, 10^0, 10^-1, 10^-2, 10^-3) and training the model. What patterns do you see and how does the choice of learning rate affect both the loss during training and the final model accuracy?
A: When varying the learning rate, there seems to be a "sweet spot" somewhere in the middle of that range that allows for the best balance of model convergence time and accuracy.  At the highest learning rate I tested (10^1), the model performs with poor accuracy at the end (<10% training and test accuracy), and the loss quickly becomes nan after 4 iterations.  As we decrease the learning rate (to 10^0), we get a much better accuracy at the end (~89.9% training and test accuracy).  We get slightly better accuracy with slower learning rates (91.7% with 10^-1 and 90.2% with 10^-2), but the time required to converge differs: the first iteration to reach over 90% Batch Accuracy is Iteration 22 for 10^-1 vs Iteration 95 for 10^-2.  This pattern is inversely correlated with the Training Loss, as well.  The higher learning rate in 10^-1 results in a faster decline in Training Loss (from 2.3 in Iteration 0 to .37 in Iteration 22).  In 10^-2, the Training Loss declines more slowly (from 2.3 in Iteration 0 to 1.2 in Iteration 22).  This contrasts with the Training Loss from 10^1, which increases from 2.3 in Iteration 0 to 62.5 in Iteration 3, followed by 'nan', indicating that the Training Loss has continued increasing beyond the capacity of the data type to store it.

2.2.3 Question
Q: Try varying the parameter for weight decay to different powers of 10: (10^0, 10^-1, 10^-2, 10^-3, 10^-4, 10^-5). How does weight decay affect the final model training and test accuracy?
A:

2.3.1 Question
Q: Currently the model uses a logistic activation for the first layer. Try using all the other activation functions we programmed. How well do they perform? What's best?
A:

2.3.2 Question
Q: Using the same activation, find the best (power of 10) learning rate for your model. What is the training accuracy and testing accuracy?
A:

2.3.3 Question
Q: Right now the regularization parameter `decay` is set to 0. Try adding some decay to your model. What happens, does it help? Why or why not may this be?
A:

2.3.4 Question
Q: Modify your model so it has 3 layers instead of 2. The layers should be `inputs -> 64`, `64 -> 32`, and `32 -> outputs`. Also modify your model to train for 3000 iterations instead of 1000. Look at the training and testing accuracy for different values of decay (powers of 10, 10^-4 -> 10^0). Which is best? Why?
A:

2.3.5 Question
Q: Modify your model so it has 4 layers instead of 2. The layers should be `inputs -> 128`, `128 -> 64`, `64 -> 32`, and `32 -> outputs`. Do the same analysis as in 2.3.4.
A:

2.3.6 Question
Q: Use the 2 layer model with the best activation for layer 1 but linear activation for layer 2. Now implement the functions `l1_loss` and `l2_loss` and change the necessary code in `classifier.cpp` to use these loss functions. Observe the output values and accuracy of the model and write down your observations for both the loss functions compared to cross-entropy loss. P.S. L2 and L1 losses are generally used for regression, but this is a classification problem.
A:

3.2.1 Question
Q: How well does your network perform on the CIFAR dataset?
A:
