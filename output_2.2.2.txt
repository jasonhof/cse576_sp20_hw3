Last login: Mon May  4 16:55:32 on ttys004
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./compile.sh 
-- Configuring done
CMake Warning (dev):
  Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run "cmake
  --help-policy CMP0042" for policy details.  Use the cmake_policy command to
  set the policy and suppress this warning.

  MACOSX_RPATH is not specified for the following targets:

   nn

This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /Users/jasonhoffman/repos/cv576/cse576_sp20_hw3/build
[ 55%] Built target nn
[100%] Built target train
[100%] Built target test
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./train
Loading dataset
Training model...
Iteration:      0: Loss:     2.305447   Batch Accuracy:    0.094 
Iteration:      1: Loss:     2.312885   Batch Accuracy:    0.047 
Iteration:      2: Loss:     2.288629   Batch Accuracy:    0.117 
Iteration:      3: Loss:     2.277914   Batch Accuracy:    0.109 
Iteration:      4: Loss:     2.205979   Batch Accuracy:    0.156 
Iteration:      5: Loss:     2.181271   Batch Accuracy:    0.195 
Iteration:      6: Loss:     2.132293   Batch Accuracy:    0.297 
Iteration:      7: Loss:     2.083115   Batch Accuracy:    0.367 
Iteration:      8: Loss:     2.022332   Batch Accuracy:    0.383 
Iteration:      9: Loss:     1.986233   Batch Accuracy:    0.430 
Iteration:     10: Loss:     1.929137   Batch Accuracy:    0.422 
Iteration:     11: Loss:     1.865869   Batch Accuracy:    0.453 
Iteration:     12: Loss:     1.825265   Batch Accuracy:    0.555 
Iteration:     13: Loss:     1.801974   Batch Accuracy:    0.492 
Iteration:     14: Loss:     1.715767   Batch Accuracy:    0.578 
Iteration:     15: Loss:     1.598987   Batch Accuracy:    0.711 
Iteration:     16: Loss:     1.533111   Batch Accuracy:    0.742 
Iteration:     17: Loss:     1.578413   Batch Accuracy:    0.680 
Iteration:     18: Loss:     1.548540   Batch Accuracy:    0.680 
Iteration:     19: Loss:     1.500443   Batch Accuracy:    0.719 
Iteration:     20: Loss:     1.398893   Batch Accuracy:    0.797 
Iteration:     21: Loss:     1.313986   Batch Accuracy:    0.727 
Iteration:     22: Loss:     1.228117   Batch Accuracy:    0.766 
Iteration:     23: Loss:     1.336982   Batch Accuracy:    0.766 
Iteration:     24: Loss:     1.306732   Batch Accuracy:    0.734 
Iteration:     25: Loss:     1.268805   Batch Accuracy:    0.727 
Iteration:     26: Loss:     1.114982   Batch Accuracy:    0.781 
Iteration:     27: Loss:     1.214090   Batch Accuracy:    0.750 
Iteration:     28: Loss:     1.081687   Batch Accuracy:    0.781 
Iteration:     29: Loss:     1.065684   Batch Accuracy:    0.766 
Iteration:     30: Loss:     1.073326   Batch Accuracy:    0.742 
Iteration:     31: Loss:     1.012687   Batch Accuracy:    0.789 
Iteration:     32: Loss:     1.021062   Batch Accuracy:    0.781 
Iteration:     33: Loss:     0.916445   Batch Accuracy:    0.828 
Iteration:     34: Loss:     0.977361   Batch Accuracy:    0.742 
Iteration:     35: Loss:     0.926220   Batch Accuracy:    0.820 
Iteration:     36: Loss:     0.946078   Batch Accuracy:    0.781 
Iteration:     37: Loss:     0.949531   Batch Accuracy:    0.797 
Iteration:     38: Loss:     0.842609   Batch Accuracy:    0.844 
Iteration:     39: Loss:     0.890660   Batch Accuracy:    0.812 
Iteration:     40: Loss:     0.946475   Batch Accuracy:    0.805 
Iteration:     41: Loss:     0.872257   Batch Accuracy:    0.797 
Iteration:     42: Loss:     0.933221   Batch Accuracy:    0.734 
Iteration:     43: Loss:     0.791373   Batch Accuracy:    0.859 
Iteration:     44: Loss:     0.975238   Batch Accuracy:    0.773 
Iteration:     45: Loss:     0.820331   Batch Accuracy:    0.836 
Iteration:     46: Loss:     0.783941   Batch Accuracy:    0.812 
Iteration:     47: Loss:     0.854890   Batch Accuracy:    0.797 
Iteration:     48: Loss:     0.862059   Batch Accuracy:    0.773 
Iteration:     49: Loss:     0.900260   Batch Accuracy:    0.773 
Iteration:     50: Loss:     0.896435   Batch Accuracy:    0.766 
Iteration:     51: Loss:     0.751762   Batch Accuracy:    0.820 
Iteration:     52: Loss:     0.761615   Batch Accuracy:    0.836 
Iteration:     53: Loss:     0.788631   Batch Accuracy:    0.820 
Iteration:     54: Loss:     0.762458   Batch Accuracy:    0.805 
Iteration:     55: Loss:     0.761292   Batch Accuracy:    0.852 
Iteration:     56: Loss:     0.766755   Batch Accuracy:    0.812 
Iteration:     57: Loss:     0.706284   Batch Accuracy:    0.836 
Iteration:     58: Loss:     0.697706   Batch Accuracy:    0.875 
Iteration:     59: Loss:     0.708254   Batch Accuracy:    0.844 
Iteration:     60: Loss:     0.884744   Batch Accuracy:    0.805 
Iteration:     61: Loss:     0.677417   Batch Accuracy:    0.867 
Iteration:     62: Loss:     0.873406   Batch Accuracy:    0.766 
Iteration:     63: Loss:     0.732811   Batch Accuracy:    0.844 
Iteration:     64: Loss:     0.717891   Batch Accuracy:    0.859 
Iteration:     65: Loss:     0.850188   Batch Accuracy:    0.812 
Iteration:     66: Loss:     0.720047   Batch Accuracy:    0.852 
Iteration:     67: Loss:     0.665109   Batch Accuracy:    0.883 
Iteration:     68: Loss:     0.726727   Batch Accuracy:    0.812 
Iteration:     69: Loss:     0.782462   Batch Accuracy:    0.820 
Iteration:     70: Loss:     0.798580   Batch Accuracy:    0.805 
Iteration:     71: Loss:     0.706837   Batch Accuracy:    0.805 
Iteration:     72: Loss:     0.825092   Batch Accuracy:    0.773 
Iteration:     73: Loss:     0.637983   Batch Accuracy:    0.797 
Iteration:     74: Loss:     0.599104   Batch Accuracy:    0.867 
Iteration:     75: Loss:     0.595619   Batch Accuracy:    0.898 
Iteration:     76: Loss:     0.697830   Batch Accuracy:    0.836 
Iteration:     77: Loss:     0.636599   Batch Accuracy:    0.875 
Iteration:     78: Loss:     0.625662   Batch Accuracy:    0.852 
Iteration:     79: Loss:     0.714174   Batch Accuracy:    0.820 
Iteration:     80: Loss:     0.637682   Batch Accuracy:    0.852 
Iteration:     81: Loss:     0.662699   Batch Accuracy:    0.844 
Iteration:     82: Loss:     0.593937   Batch Accuracy:    0.914 
Iteration:     83: Loss:     0.630150   Batch Accuracy:    0.844 
Iteration:     84: Loss:     0.626952   Batch Accuracy:    0.844 
Iteration:     85: Loss:     0.560647   Batch Accuracy:    0.867 
Iteration:     86: Loss:     0.678083   Batch Accuracy:    0.812 
Iteration:     87: Loss:     0.594675   Batch Accuracy:    0.852 
Iteration:     88: Loss:     0.685303   Batch Accuracy:    0.828 
Iteration:     89: Loss:     0.549566   Batch Accuracy:    0.883 
Iteration:     90: Loss:     0.632413   Batch Accuracy:    0.859 
Iteration:     91: Loss:     0.736367   Batch Accuracy:    0.789 
Iteration:     92: Loss:     0.514290   Batch Accuracy:    0.883 
Iteration:     93: Loss:     0.733145   Batch Accuracy:    0.789 
Iteration:     94: Loss:     0.699182   Batch Accuracy:    0.820 
Iteration:     95: Loss:     0.519610   Batch Accuracy:    0.906 
Iteration:     96: Loss:     0.670903   Batch Accuracy:    0.852 
Iteration:     97: Loss:     0.607403   Batch Accuracy:    0.852 
Iteration:     98: Loss:     0.657640   Batch Accuracy:    0.773 
Iteration:     99: Loss:     0.513714   Batch Accuracy:    0.867 
Iteration:    100: Loss:     0.528230   Batch Accuracy:    0.859 
Iteration:    101: Loss:     0.635868   Batch Accuracy:    0.852 
Iteration:    102: Loss:     0.512873   Batch Accuracy:    0.875 
Iteration:    103: Loss:     0.615968   Batch Accuracy:    0.852 
Iteration:    104: Loss:     0.557722   Batch Accuracy:    0.867 
Iteration:    105: Loss:     0.591128   Batch Accuracy:    0.805 
Iteration:    106: Loss:     0.644620   Batch Accuracy:    0.820 
Iteration:    107: Loss:     0.656488   Batch Accuracy:    0.836 
Iteration:    108: Loss:     0.668268   Batch Accuracy:    0.789 
Iteration:    109: Loss:     0.577840   Batch Accuracy:    0.859 
Iteration:    110: Loss:     0.632731   Batch Accuracy:    0.836 
Iteration:    111: Loss:     0.548849   Batch Accuracy:    0.859 
Iteration:    112: Loss:     0.669541   Batch Accuracy:    0.820 
Iteration:    113: Loss:     0.591102   Batch Accuracy:    0.852 
Iteration:    114: Loss:     0.522295   Batch Accuracy:    0.891 
Iteration:    115: Loss:     0.577880   Batch Accuracy:    0.883 
Iteration:    116: Loss:     0.546453   Batch Accuracy:    0.867 
Iteration:    117: Loss:     0.535340   Batch Accuracy:    0.852 
Iteration:    118: Loss:     0.578386   Batch Accuracy:    0.828 
Iteration:    119: Loss:     0.567301   Batch Accuracy:    0.844 
Iteration:    120: Loss:     0.605654   Batch Accuracy:    0.828 
Iteration:    121: Loss:     0.612160   Batch Accuracy:    0.859 
Iteration:    122: Loss:     0.528236   Batch Accuracy:    0.844 
Iteration:    123: Loss:     0.576620   Batch Accuracy:    0.844 
Iteration:    124: Loss:     0.706692   Batch Accuracy:    0.789 
Iteration:    125: Loss:     0.532307   Batch Accuracy:    0.906 
Iteration:    126: Loss:     0.493185   Batch Accuracy:    0.891 
Iteration:    127: Loss:     0.569636   Batch Accuracy:    0.859 
Iteration:    128: Loss:     0.511471   Batch Accuracy:    0.914 
Iteration:    129: Loss:     0.500992   Batch Accuracy:    0.891 
Iteration:    130: Loss:     0.593138   Batch Accuracy:    0.852 
Iteration:    131: Loss:     0.587722   Batch Accuracy:    0.820 
Iteration:    132: Loss:     0.503703   Batch Accuracy:    0.891 
Iteration:    133: Loss:     0.522661   Batch Accuracy:    0.898 
Iteration:    134: Loss:     0.632600   Batch Accuracy:    0.812 
Iteration:    135: Loss:     0.457085   Batch Accuracy:    0.883 
Iteration:    136: Loss:     0.593033   Batch Accuracy:    0.859 
Iteration:    137: Loss:     0.654840   Batch Accuracy:    0.797 
Iteration:    138: Loss:     0.573796   Batch Accuracy:    0.844 
Iteration:    139: Loss:     0.614316   Batch Accuracy:    0.828 
Iteration:    140: Loss:     0.541797   Batch Accuracy:    0.883 
Iteration:    141: Loss:     0.541498   Batch Accuracy:    0.875 
Iteration:    142: Loss:     0.497511   Batch Accuracy:    0.922 
Iteration:    143: Loss:     0.508338   Batch Accuracy:    0.875 
Iteration:    144: Loss:     0.543020   Batch Accuracy:    0.891 
Iteration:    145: Loss:     0.544659   Batch Accuracy:    0.883 
Iteration:    146: Loss:     0.580920   Batch Accuracy:    0.836 
Iteration:    147: Loss:     0.511924   Batch Accuracy:    0.867 
Iteration:    148: Loss:     0.544021   Batch Accuracy:    0.852 
Iteration:    149: Loss:     0.524089   Batch Accuracy:    0.867 
Iteration:    150: Loss:     0.626664   Batch Accuracy:    0.836 
Iteration:    151: Loss:     0.533428   Batch Accuracy:    0.883 
Iteration:    152: Loss:     0.484948   Batch Accuracy:    0.875 
Iteration:    153: Loss:     0.561455   Batch Accuracy:    0.836 
Iteration:    154: Loss:     0.498616   Batch Accuracy:    0.875 
Iteration:    155: Loss:     0.610498   Batch Accuracy:    0.852 
Iteration:    156: Loss:     0.447903   Batch Accuracy:    0.930 
Iteration:    157: Loss:     0.420174   Batch Accuracy:    0.914 
Iteration:    158: Loss:     0.500811   Batch Accuracy:    0.852 
Iteration:    159: Loss:     0.536904   Batch Accuracy:    0.859 
Iteration:    160: Loss:     0.491264   Batch Accuracy:    0.906 
Iteration:    161: Loss:     0.595553   Batch Accuracy:    0.828 
Iteration:    162: Loss:     0.612130   Batch Accuracy:    0.844 
Iteration:    163: Loss:     0.525592   Batch Accuracy:    0.852 
Iteration:    164: Loss:     0.467993   Batch Accuracy:    0.891 
Iteration:    165: Loss:     0.503241   Batch Accuracy:    0.852 
Iteration:    166: Loss:     0.543267   Batch Accuracy:    0.859 
Iteration:    167: Loss:     0.542572   Batch Accuracy:    0.844 
Iteration:    168: Loss:     0.497353   Batch Accuracy:    0.875 
Iteration:    169: Loss:     0.455275   Batch Accuracy:    0.906 
Iteration:    170: Loss:     0.461122   Batch Accuracy:    0.891 
Iteration:    171: Loss:     0.588328   Batch Accuracy:    0.828 
Iteration:    172: Loss:     0.637441   Batch Accuracy:    0.844 
Iteration:    173: Loss:     0.595052   Batch Accuracy:    0.852 
Iteration:    174: Loss:     0.584508   Batch Accuracy:    0.836 
Iteration:    175: Loss:     0.453014   Batch Accuracy:    0.906 
Iteration:    176: Loss:     0.499164   Batch Accuracy:    0.875 
Iteration:    177: Loss:     0.554013   Batch Accuracy:    0.859 
Iteration:    178: Loss:     0.425104   Batch Accuracy:    0.898 
Iteration:    179: Loss:     0.512024   Batch Accuracy:    0.867 
Iteration:    180: Loss:     0.419407   Batch Accuracy:    0.875 
Iteration:    181: Loss:     0.520151   Batch Accuracy:    0.898 
Iteration:    182: Loss:     0.507504   Batch Accuracy:    0.906 
Iteration:    183: Loss:     0.406010   Batch Accuracy:    0.906 
Iteration:    184: Loss:     0.578882   Batch Accuracy:    0.805 
Iteration:    185: Loss:     0.420160   Batch Accuracy:    0.867 
Iteration:    186: Loss:     0.535590   Batch Accuracy:    0.875 
Iteration:    187: Loss:     0.546675   Batch Accuracy:    0.852 
Iteration:    188: Loss:     0.481977   Batch Accuracy:    0.883 
Iteration:    189: Loss:     0.441713   Batch Accuracy:    0.891 
Iteration:    190: Loss:     0.544515   Batch Accuracy:    0.859 
Iteration:    191: Loss:     0.377247   Batch Accuracy:    0.883 
Iteration:    192: Loss:     0.433610   Batch Accuracy:    0.898 
Iteration:    193: Loss:     0.529263   Batch Accuracy:    0.883 
Iteration:    194: Loss:     0.462038   Batch Accuracy:    0.867 
Iteration:    195: Loss:     0.456403   Batch Accuracy:    0.883 
Iteration:    196: Loss:     0.441631   Batch Accuracy:    0.883 
Iteration:    197: Loss:     0.422717   Batch Accuracy:    0.922 
Iteration:    198: Loss:     0.470748   Batch Accuracy:    0.867 
Iteration:    199: Loss:     0.618792   Batch Accuracy:    0.812 
Iteration:    200: Loss:     0.442768   Batch Accuracy:    0.914 
Iteration:    201: Loss:     0.536858   Batch Accuracy:    0.852 
Iteration:    202: Loss:     0.548781   Batch Accuracy:    0.859 
Iteration:    203: Loss:     0.515046   Batch Accuracy:    0.844 
Iteration:    204: Loss:     0.599522   Batch Accuracy:    0.844 
Iteration:    205: Loss:     0.435575   Batch Accuracy:    0.891 
Iteration:    206: Loss:     0.376387   Batch Accuracy:    0.914 
Iteration:    207: Loss:     0.364812   Batch Accuracy:    0.930 
Iteration:    208: Loss:     0.507405   Batch Accuracy:    0.859 
Iteration:    209: Loss:     0.367927   Batch Accuracy:    0.891 
Iteration:    210: Loss:     0.513912   Batch Accuracy:    0.859 
Iteration:    211: Loss:     0.466493   Batch Accuracy:    0.875 
Iteration:    212: Loss:     0.448635   Batch Accuracy:    0.883 
Iteration:    213: Loss:     0.485384   Batch Accuracy:    0.875 
Iteration:    214: Loss:     0.501184   Batch Accuracy:    0.859 
Iteration:    215: Loss:     0.464958   Batch Accuracy:    0.891 
Iteration:    216: Loss:     0.535641   Batch Accuracy:    0.875 
Iteration:    217: Loss:     0.389930   Batch Accuracy:    0.922 
Iteration:    218: Loss:     0.465661   Batch Accuracy:    0.875 
Iteration:    219: Loss:     0.505671   Batch Accuracy:    0.875 
Iteration:    220: Loss:     0.511498   Batch Accuracy:    0.883 
Iteration:    221: Loss:     0.355503   Batch Accuracy:    0.961 
Iteration:    222: Loss:     0.429105   Batch Accuracy:    0.898 
Iteration:    223: Loss:     0.648741   Batch Accuracy:    0.859 
Iteration:    224: Loss:     0.579164   Batch Accuracy:    0.828 
Iteration:    225: Loss:     0.466482   Batch Accuracy:    0.875 
Iteration:    226: Loss:     0.648917   Batch Accuracy:    0.797 
Iteration:    227: Loss:     0.574844   Batch Accuracy:    0.867 
Iteration:    228: Loss:     0.454141   Batch Accuracy:    0.875 
Iteration:    229: Loss:     0.416591   Batch Accuracy:    0.906 
Iteration:    230: Loss:     0.424970   Batch Accuracy:    0.891 
Iteration:    231: Loss:     0.404584   Batch Accuracy:    0.922 
Iteration:    232: Loss:     0.372842   Batch Accuracy:    0.906 
Iteration:    233: Loss:     0.518569   Batch Accuracy:    0.875 
Iteration:    234: Loss:     0.281161   Batch Accuracy:    0.961 
Iteration:    235: Loss:     0.491916   Batch Accuracy:    0.883 
Iteration:    236: Loss:     0.368737   Batch Accuracy:    0.906 
Iteration:    237: Loss:     0.431375   Batch Accuracy:    0.883 
Iteration:    238: Loss:     0.545423   Batch Accuracy:    0.859 
Iteration:    239: Loss:     0.542440   Batch Accuracy:    0.867 
Iteration:    240: Loss:     0.427345   Batch Accuracy:    0.906 
Iteration:    241: Loss:     0.427842   Batch Accuracy:    0.898 
Iteration:    242: Loss:     0.371293   Batch Accuracy:    0.906 
Iteration:    243: Loss:     0.392303   Batch Accuracy:    0.891 
Iteration:    244: Loss:     0.469950   Batch Accuracy:    0.891 
Iteration:    245: Loss:     0.474238   Batch Accuracy:    0.875 
Iteration:    246: Loss:     0.471805   Batch Accuracy:    0.906 
Iteration:    247: Loss:     0.420157   Batch Accuracy:    0.898 
Iteration:    248: Loss:     0.467152   Batch Accuracy:    0.891 
Iteration:    249: Loss:     0.368297   Batch Accuracy:    0.898 
Iteration:    250: Loss:     0.444158   Batch Accuracy:    0.867 
Iteration:    251: Loss:     0.462444   Batch Accuracy:    0.883 
Iteration:    252: Loss:     0.577724   Batch Accuracy:    0.852 
Iteration:    253: Loss:     0.477602   Batch Accuracy:    0.883 
Iteration:    254: Loss:     0.529226   Batch Accuracy:    0.836 
Iteration:    255: Loss:     0.476641   Batch Accuracy:    0.875 
Iteration:    256: Loss:     0.447708   Batch Accuracy:    0.922 
Iteration:    257: Loss:     0.439873   Batch Accuracy:    0.883 
Iteration:    258: Loss:     0.499774   Batch Accuracy:    0.867 
Iteration:    259: Loss:     0.418692   Batch Accuracy:    0.914 
Iteration:    260: Loss:     0.504439   Batch Accuracy:    0.859 
Iteration:    261: Loss:     0.522274   Batch Accuracy:    0.883 
Iteration:    262: Loss:     0.512696   Batch Accuracy:    0.867 
Iteration:    263: Loss:     0.442473   Batch Accuracy:    0.891 
Iteration:    264: Loss:     0.555867   Batch Accuracy:    0.859 
Iteration:    265: Loss:     0.565542   Batch Accuracy:    0.852 
Iteration:    266: Loss:     0.434612   Batch Accuracy:    0.875 
Iteration:    267: Loss:     0.401264   Batch Accuracy:    0.891 
Iteration:    268: Loss:     0.407107   Batch Accuracy:    0.914 
Iteration:    269: Loss:     0.368468   Batch Accuracy:    0.906 
Iteration:    270: Loss:     0.463016   Batch Accuracy:    0.883 
Iteration:    271: Loss:     0.454066   Batch Accuracy:    0.859 
Iteration:    272: Loss:     0.431391   Batch Accuracy:    0.898 
Iteration:    273: Loss:     0.433900   Batch Accuracy:    0.914 
Iteration:    274: Loss:     0.523524   Batch Accuracy:    0.844 
Iteration:    275: Loss:     0.509503   Batch Accuracy:    0.859 
Iteration:    276: Loss:     0.501362   Batch Accuracy:    0.883 
Iteration:    277: Loss:     0.631232   Batch Accuracy:    0.828 
Iteration:    278: Loss:     0.444968   Batch Accuracy:    0.883 
Iteration:    279: Loss:     0.427986   Batch Accuracy:    0.930 
Iteration:    280: Loss:     0.546301   Batch Accuracy:    0.859 
Iteration:    281: Loss:     0.418403   Batch Accuracy:    0.906 
Iteration:    282: Loss:     0.497979   Batch Accuracy:    0.836 
Iteration:    283: Loss:     0.527462   Batch Accuracy:    0.859 
Iteration:    284: Loss:     0.507076   Batch Accuracy:    0.859 
Iteration:    285: Loss:     0.368265   Batch Accuracy:    0.898 
Iteration:    286: Loss:     0.444366   Batch Accuracy:    0.891 
Iteration:    287: Loss:     0.474471   Batch Accuracy:    0.875 
Iteration:    288: Loss:     0.468952   Batch Accuracy:    0.883 
Iteration:    289: Loss:     0.621141   Batch Accuracy:    0.828 
Iteration:    290: Loss:     0.393593   Batch Accuracy:    0.914 
Iteration:    291: Loss:     0.514137   Batch Accuracy:    0.867 
Iteration:    292: Loss:     0.386429   Batch Accuracy:    0.898 
Iteration:    293: Loss:     0.376326   Batch Accuracy:    0.906 
Iteration:    294: Loss:     0.549033   Batch Accuracy:    0.828 
Iteration:    295: Loss:     0.490666   Batch Accuracy:    0.867 
Iteration:    296: Loss:     0.432731   Batch Accuracy:    0.891 
Iteration:    297: Loss:     0.437082   Batch Accuracy:    0.883 
Iteration:    298: Loss:     0.434241   Batch Accuracy:    0.883 
Iteration:    299: Loss:     0.484833   Batch Accuracy:    0.859 
Iteration:    300: Loss:     0.428255   Batch Accuracy:    0.875 
Iteration:    301: Loss:     0.422688   Batch Accuracy:    0.906 
Iteration:    302: Loss:     0.361354   Batch Accuracy:    0.859 
Iteration:    303: Loss:     0.494511   Batch Accuracy:    0.883 
Iteration:    304: Loss:     0.478630   Batch Accuracy:    0.859 
Iteration:    305: Loss:     0.398940   Batch Accuracy:    0.914 
Iteration:    306: Loss:     0.261292   Batch Accuracy:    0.938 
Iteration:    307: Loss:     0.409957   Batch Accuracy:    0.875 
Iteration:    308: Loss:     0.529424   Batch Accuracy:    0.836 
Iteration:    309: Loss:     0.417469   Batch Accuracy:    0.859 
Iteration:    310: Loss:     0.525010   Batch Accuracy:    0.844 
Iteration:    311: Loss:     0.392678   Batch Accuracy:    0.859 
Iteration:    312: Loss:     0.374691   Batch Accuracy:    0.922 
Iteration:    313: Loss:     0.380268   Batch Accuracy:    0.906 
Iteration:    314: Loss:     0.484288   Batch Accuracy:    0.859 
Iteration:    315: Loss:     0.444255   Batch Accuracy:    0.875 
Iteration:    316: Loss:     0.379808   Batch Accuracy:    0.914 
Iteration:    317: Loss:     0.429718   Batch Accuracy:    0.883 
Iteration:    318: Loss:     0.559161   Batch Accuracy:    0.844 
Iteration:    319: Loss:     0.456838   Batch Accuracy:    0.891 
Iteration:    320: Loss:     0.506246   Batch Accuracy:    0.906 
Iteration:    321: Loss:     0.624437   Batch Accuracy:    0.812 
Iteration:    322: Loss:     0.367374   Batch Accuracy:    0.914 
Iteration:    323: Loss:     0.322857   Batch Accuracy:    0.930 
Iteration:    324: Loss:     0.452610   Batch Accuracy:    0.891 
Iteration:    325: Loss:     0.359155   Batch Accuracy:    0.938 
Iteration:    326: Loss:     0.467001   Batch Accuracy:    0.883 
Iteration:    327: Loss:     0.417854   Batch Accuracy:    0.914 
Iteration:    328: Loss:     0.382474   Batch Accuracy:    0.891 
Iteration:    329: Loss:     0.574933   Batch Accuracy:    0.836 
Iteration:    330: Loss:     0.250477   Batch Accuracy:    0.977 
Iteration:    331: Loss:     0.311368   Batch Accuracy:    0.938 
Iteration:    332: Loss:     0.489835   Batch Accuracy:    0.859 
Iteration:    333: Loss:     0.381057   Batch Accuracy:    0.891 
Iteration:    334: Loss:     0.604630   Batch Accuracy:    0.828 
Iteration:    335: Loss:     0.324734   Batch Accuracy:    0.922 
Iteration:    336: Loss:     0.306905   Batch Accuracy:    0.930 
Iteration:    337: Loss:     0.420106   Batch Accuracy:    0.875 
Iteration:    338: Loss:     0.422659   Batch Accuracy:    0.875 
Iteration:    339: Loss:     0.493360   Batch Accuracy:    0.891 
Iteration:    340: Loss:     0.389631   Batch Accuracy:    0.898 
Iteration:    341: Loss:     0.416336   Batch Accuracy:    0.898 
Iteration:    342: Loss:     0.404890   Batch Accuracy:    0.883 
Iteration:    343: Loss:     0.400645   Batch Accuracy:    0.922 
Iteration:    344: Loss:     0.425441   Batch Accuracy:    0.891 
Iteration:    345: Loss:     0.493806   Batch Accuracy:    0.867 
Iteration:    346: Loss:     0.364000   Batch Accuracy:    0.930 
Iteration:    347: Loss:     0.408929   Batch Accuracy:    0.883 
Iteration:    348: Loss:     0.550505   Batch Accuracy:    0.836 
Iteration:    349: Loss:     0.523485   Batch Accuracy:    0.852 
Iteration:    350: Loss:     0.336766   Batch Accuracy:    0.945 
Iteration:    351: Loss:     0.389589   Batch Accuracy:    0.914 
Iteration:    352: Loss:     0.371387   Batch Accuracy:    0.922 
Iteration:    353: Loss:     0.552347   Batch Accuracy:    0.859 
Iteration:    354: Loss:     0.420086   Batch Accuracy:    0.898 
Iteration:    355: Loss:     0.470715   Batch Accuracy:    0.891 
Iteration:    356: Loss:     0.386730   Batch Accuracy:    0.883 
Iteration:    357: Loss:     0.470594   Batch Accuracy:    0.859 
Iteration:    358: Loss:     0.354329   Batch Accuracy:    0.906 
Iteration:    359: Loss:     0.337543   Batch Accuracy:    0.898 
Iteration:    360: Loss:     0.479242   Batch Accuracy:    0.859 
Iteration:    361: Loss:     0.444089   Batch Accuracy:    0.914 
Iteration:    362: Loss:     0.453748   Batch Accuracy:    0.906 
Iteration:    363: Loss:     0.501534   Batch Accuracy:    0.852 
Iteration:    364: Loss:     0.378886   Batch Accuracy:    0.883 
Iteration:    365: Loss:     0.504257   Batch Accuracy:    0.836 
Iteration:    366: Loss:     0.570586   Batch Accuracy:    0.836 
Iteration:    367: Loss:     0.390758   Batch Accuracy:    0.914 
Iteration:    368: Loss:     0.432406   Batch Accuracy:    0.891 
Iteration:    369: Loss:     0.596586   Batch Accuracy:    0.836 
Iteration:    370: Loss:     0.356182   Batch Accuracy:    0.945 
Iteration:    371: Loss:     0.417208   Batch Accuracy:    0.906 
Iteration:    372: Loss:     0.461770   Batch Accuracy:    0.891 
Iteration:    373: Loss:     0.346094   Batch Accuracy:    0.930 
Iteration:    374: Loss:     0.390608   Batch Accuracy:    0.891 
Iteration:    375: Loss:     0.388453   Batch Accuracy:    0.898 
Iteration:    376: Loss:     0.288627   Batch Accuracy:    0.930 
Iteration:    377: Loss:     0.443506   Batch Accuracy:    0.875 
Iteration:    378: Loss:     0.385408   Batch Accuracy:    0.906 
Iteration:    379: Loss:     0.418361   Batch Accuracy:    0.875 
Iteration:    380: Loss:     0.453506   Batch Accuracy:    0.891 
Iteration:    381: Loss:     0.448533   Batch Accuracy:    0.875 
Iteration:    382: Loss:     0.450114   Batch Accuracy:    0.891 
Iteration:    383: Loss:     0.374253   Batch Accuracy:    0.898 
Iteration:    384: Loss:     0.442948   Batch Accuracy:    0.852 
Iteration:    385: Loss:     0.338929   Batch Accuracy:    0.891 
Iteration:    386: Loss:     0.441165   Batch Accuracy:    0.859 
Iteration:    387: Loss:     0.362196   Batch Accuracy:    0.930 
Iteration:    388: Loss:     0.511401   Batch Accuracy:    0.859 
Iteration:    389: Loss:     0.453249   Batch Accuracy:    0.867 
Iteration:    390: Loss:     0.472833   Batch Accuracy:    0.883 
Iteration:    391: Loss:     0.379854   Batch Accuracy:    0.922 
Iteration:    392: Loss:     0.383607   Batch Accuracy:    0.906 
Iteration:    393: Loss:     0.404985   Batch Accuracy:    0.906 
Iteration:    394: Loss:     0.513293   Batch Accuracy:    0.844 
Iteration:    395: Loss:     0.445056   Batch Accuracy:    0.875 
Iteration:    396: Loss:     0.323555   Batch Accuracy:    0.914 
Iteration:    397: Loss:     0.527300   Batch Accuracy:    0.828 
Iteration:    398: Loss:     0.498609   Batch Accuracy:    0.867 
Iteration:    399: Loss:     0.592816   Batch Accuracy:    0.883 
Iteration:    400: Loss:     0.343450   Batch Accuracy:    0.930 
Iteration:    401: Loss:     0.386673   Batch Accuracy:    0.875 
Iteration:    402: Loss:     0.403462   Batch Accuracy:    0.914 
Iteration:    403: Loss:     0.391295   Batch Accuracy:    0.898 
Iteration:    404: Loss:     0.366281   Batch Accuracy:    0.898 
Iteration:    405: Loss:     0.383287   Batch Accuracy:    0.883 
Iteration:    406: Loss:     0.496410   Batch Accuracy:    0.883 
Iteration:    407: Loss:     0.343155   Batch Accuracy:    0.898 
Iteration:    408: Loss:     0.529590   Batch Accuracy:    0.820 
Iteration:    409: Loss:     0.355243   Batch Accuracy:    0.898 
Iteration:    410: Loss:     0.435519   Batch Accuracy:    0.891 
Iteration:    411: Loss:     0.325379   Batch Accuracy:    0.945 
Iteration:    412: Loss:     0.417715   Batch Accuracy:    0.891 
Iteration:    413: Loss:     0.417629   Batch Accuracy:    0.867 
Iteration:    414: Loss:     0.339720   Batch Accuracy:    0.906 
Iteration:    415: Loss:     0.400634   Batch Accuracy:    0.852 
Iteration:    416: Loss:     0.442645   Batch Accuracy:    0.883 
Iteration:    417: Loss:     0.501739   Batch Accuracy:    0.836 
Iteration:    418: Loss:     0.584194   Batch Accuracy:    0.859 
Iteration:    419: Loss:     0.487259   Batch Accuracy:    0.852 
Iteration:    420: Loss:     0.521628   Batch Accuracy:    0.867 
Iteration:    421: Loss:     0.363840   Batch Accuracy:    0.914 
Iteration:    422: Loss:     0.418943   Batch Accuracy:    0.867 
Iteration:    423: Loss:     0.366681   Batch Accuracy:    0.914 
Iteration:    424: Loss:     0.469792   Batch Accuracy:    0.883 
Iteration:    425: Loss:     0.371807   Batch Accuracy:    0.883 
Iteration:    426: Loss:     0.449421   Batch Accuracy:    0.875 
Iteration:    427: Loss:     0.465096   Batch Accuracy:    0.875 
Iteration:    428: Loss:     0.332516   Batch Accuracy:    0.922 
Iteration:    429: Loss:     0.319779   Batch Accuracy:    0.930 
Iteration:    430: Loss:     0.397537   Batch Accuracy:    0.883 
Iteration:    431: Loss:     0.431903   Batch Accuracy:    0.906 
Iteration:    432: Loss:     0.438330   Batch Accuracy:    0.859 
Iteration:    433: Loss:     0.433387   Batch Accuracy:    0.852 
Iteration:    434: Loss:     0.364806   Batch Accuracy:    0.922 
Iteration:    435: Loss:     0.345529   Batch Accuracy:    0.930 
Iteration:    436: Loss:     0.330215   Batch Accuracy:    0.945 
Iteration:    437: Loss:     0.337646   Batch Accuracy:    0.938 
Iteration:    438: Loss:     0.541040   Batch Accuracy:    0.836 
Iteration:    439: Loss:     0.317721   Batch Accuracy:    0.891 
Iteration:    440: Loss:     0.354601   Batch Accuracy:    0.906 
Iteration:    441: Loss:     0.407952   Batch Accuracy:    0.891 
Iteration:    442: Loss:     0.412960   Batch Accuracy:    0.891 
Iteration:    443: Loss:     0.428552   Batch Accuracy:    0.891 
Iteration:    444: Loss:     0.306417   Batch Accuracy:    0.953 
Iteration:    445: Loss:     0.322944   Batch Accuracy:    0.930 
Iteration:    446: Loss:     0.391676   Batch Accuracy:    0.906 
Iteration:    447: Loss:     0.418712   Batch Accuracy:    0.867 
Iteration:    448: Loss:     0.314459   Batch Accuracy:    0.898 
Iteration:    449: Loss:     0.370413   Batch Accuracy:    0.922 
Iteration:    450: Loss:     0.456601   Batch Accuracy:    0.852 
Iteration:    451: Loss:     0.390302   Batch Accuracy:    0.883 
Iteration:    452: Loss:     0.427939   Batch Accuracy:    0.844 
Iteration:    453: Loss:     0.329154   Batch Accuracy:    0.875 
Iteration:    454: Loss:     0.431875   Batch Accuracy:    0.867 
Iteration:    455: Loss:     0.507278   Batch Accuracy:    0.883 
Iteration:    456: Loss:     0.328438   Batch Accuracy:    0.930 
Iteration:    457: Loss:     0.272952   Batch Accuracy:    0.938 
Iteration:    458: Loss:     0.497761   Batch Accuracy:    0.867 
Iteration:    459: Loss:     0.355386   Batch Accuracy:    0.914 
Iteration:    460: Loss:     0.282151   Batch Accuracy:    0.922 
Iteration:    461: Loss:     0.538264   Batch Accuracy:    0.898 
Iteration:    462: Loss:     0.481548   Batch Accuracy:    0.875 
Iteration:    463: Loss:     0.424776   Batch Accuracy:    0.867 
Iteration:    464: Loss:     0.342989   Batch Accuracy:    0.906 
Iteration:    465: Loss:     0.467152   Batch Accuracy:    0.844 
Iteration:    466: Loss:     0.319740   Batch Accuracy:    0.914 
Iteration:    467: Loss:     0.457925   Batch Accuracy:    0.875 
Iteration:    468: Loss:     0.528016   Batch Accuracy:    0.812 
Iteration:    469: Loss:     0.328056   Batch Accuracy:    0.906 
Iteration:    470: Loss:     0.506689   Batch Accuracy:    0.844 
Iteration:    471: Loss:     0.425715   Batch Accuracy:    0.867 
Iteration:    472: Loss:     0.358345   Batch Accuracy:    0.914 
Iteration:    473: Loss:     0.363238   Batch Accuracy:    0.891 
Iteration:    474: Loss:     0.439708   Batch Accuracy:    0.898 
Iteration:    475: Loss:     0.365994   Batch Accuracy:    0.922 
Iteration:    476: Loss:     0.404501   Batch Accuracy:    0.898 
Iteration:    477: Loss:     0.427614   Batch Accuracy:    0.891 
Iteration:    478: Loss:     0.449986   Batch Accuracy:    0.875 
Iteration:    479: Loss:     0.449666   Batch Accuracy:    0.891 
Iteration:    480: Loss:     0.373573   Batch Accuracy:    0.844 
Iteration:    481: Loss:     0.485593   Batch Accuracy:    0.891 
Iteration:    482: Loss:     0.373417   Batch Accuracy:    0.898 
Iteration:    483: Loss:     0.342592   Batch Accuracy:    0.891 
Iteration:    484: Loss:     0.383825   Batch Accuracy:    0.898 
Iteration:    485: Loss:     0.360983   Batch Accuracy:    0.883 
Iteration:    486: Loss:     0.351889   Batch Accuracy:    0.914 
Iteration:    487: Loss:     0.402777   Batch Accuracy:    0.867 
Iteration:    488: Loss:     0.356768   Batch Accuracy:    0.898 
Iteration:    489: Loss:     0.402799   Batch Accuracy:    0.883 
Iteration:    490: Loss:     0.333276   Batch Accuracy:    0.914 
Iteration:    491: Loss:     0.393941   Batch Accuracy:    0.898 
Iteration:    492: Loss:     0.422897   Batch Accuracy:    0.883 
Iteration:    493: Loss:     0.378815   Batch Accuracy:    0.883 
Iteration:    494: Loss:     0.300898   Batch Accuracy:    0.922 
Iteration:    495: Loss:     0.447626   Batch Accuracy:    0.867 
Iteration:    496: Loss:     0.561502   Batch Accuracy:    0.836 
Iteration:    497: Loss:     0.348290   Batch Accuracy:    0.922 
Iteration:    498: Loss:     0.262665   Batch Accuracy:    0.938 
Iteration:    499: Loss:     0.360753   Batch Accuracy:    0.914 
Iteration:    500: Loss:     0.390631   Batch Accuracy:    0.906 
Iteration:    501: Loss:     0.391616   Batch Accuracy:    0.891 
Iteration:    502: Loss:     0.414089   Batch Accuracy:    0.898 
Iteration:    503: Loss:     0.580460   Batch Accuracy:    0.844 
Iteration:    504: Loss:     0.332088   Batch Accuracy:    0.906 
Iteration:    505: Loss:     0.496952   Batch Accuracy:    0.883 
Iteration:    506: Loss:     0.456194   Batch Accuracy:    0.836 
Iteration:    507: Loss:     0.336740   Batch Accuracy:    0.914 
Iteration:    508: Loss:     0.264760   Batch Accuracy:    0.914 
Iteration:    509: Loss:     0.437060   Batch Accuracy:    0.891 
Iteration:    510: Loss:     0.473900   Batch Accuracy:    0.844 
Iteration:    511: Loss:     0.531245   Batch Accuracy:    0.812 
Iteration:    512: Loss:     0.299844   Batch Accuracy:    0.914 
Iteration:    513: Loss:     0.377202   Batch Accuracy:    0.891 
Iteration:    514: Loss:     0.316664   Batch Accuracy:    0.914 
Iteration:    515: Loss:     0.350527   Batch Accuracy:    0.898 
Iteration:    516: Loss:     0.355218   Batch Accuracy:    0.898 
Iteration:    517: Loss:     0.293412   Batch Accuracy:    0.930 
Iteration:    518: Loss:     0.388101   Batch Accuracy:    0.906 
Iteration:    519: Loss:     0.341142   Batch Accuracy:    0.906 
Iteration:    520: Loss:     0.307858   Batch Accuracy:    0.922 
Iteration:    521: Loss:     0.471863   Batch Accuracy:    0.852 
Iteration:    522: Loss:     0.445472   Batch Accuracy:    0.883 
Iteration:    523: Loss:     0.337767   Batch Accuracy:    0.906 
Iteration:    524: Loss:     0.597499   Batch Accuracy:    0.859 
Iteration:    525: Loss:     0.381465   Batch Accuracy:    0.906 
Iteration:    526: Loss:     0.329315   Batch Accuracy:    0.922 
Iteration:    527: Loss:     0.415533   Batch Accuracy:    0.867 
Iteration:    528: Loss:     0.352520   Batch Accuracy:    0.898 
Iteration:    529: Loss:     0.324087   Batch Accuracy:    0.914 
Iteration:    530: Loss:     0.385485   Batch Accuracy:    0.891 
Iteration:    531: Loss:     0.426385   Batch Accuracy:    0.898 
Iteration:    532: Loss:     0.368926   Batch Accuracy:    0.891 
Iteration:    533: Loss:     0.367735   Batch Accuracy:    0.891 
Iteration:    534: Loss:     0.462204   Batch Accuracy:    0.891 
Iteration:    535: Loss:     0.321396   Batch Accuracy:    0.914 
Iteration:    536: Loss:     0.397098   Batch Accuracy:    0.883 
Iteration:    537: Loss:     0.362429   Batch Accuracy:    0.930 
Iteration:    538: Loss:     0.543901   Batch Accuracy:    0.844 
Iteration:    539: Loss:     0.455475   Batch Accuracy:    0.859 
Iteration:    540: Loss:     0.459274   Batch Accuracy:    0.867 
Iteration:    541: Loss:     0.319098   Batch Accuracy:    0.914 
Iteration:    542: Loss:     0.582328   Batch Accuracy:    0.852 
Iteration:    543: Loss:     0.402890   Batch Accuracy:    0.891 
Iteration:    544: Loss:     0.294443   Batch Accuracy:    0.930 
Iteration:    545: Loss:     0.318242   Batch Accuracy:    0.906 
Iteration:    546: Loss:     0.440746   Batch Accuracy:    0.875 
Iteration:    547: Loss:     0.369792   Batch Accuracy:    0.914 
Iteration:    548: Loss:     0.432765   Batch Accuracy:    0.883 
Iteration:    549: Loss:     0.397095   Batch Accuracy:    0.914 
Iteration:    550: Loss:     0.315981   Batch Accuracy:    0.930 
Iteration:    551: Loss:     0.461758   Batch Accuracy:    0.875 
Iteration:    552: Loss:     0.257353   Batch Accuracy:    0.945 
Iteration:    553: Loss:     0.371088   Batch Accuracy:    0.906 
Iteration:    554: Loss:     0.557176   Batch Accuracy:    0.844 
Iteration:    555: Loss:     0.389740   Batch Accuracy:    0.875 
Iteration:    556: Loss:     0.470853   Batch Accuracy:    0.875 
Iteration:    557: Loss:     0.330360   Batch Accuracy:    0.922 
Iteration:    558: Loss:     0.582198   Batch Accuracy:    0.867 
Iteration:    559: Loss:     0.335293   Batch Accuracy:    0.906 
Iteration:    560: Loss:     0.296896   Batch Accuracy:    0.930 
Iteration:    561: Loss:     0.338169   Batch Accuracy:    0.898 
Iteration:    562: Loss:     0.479064   Batch Accuracy:    0.859 
Iteration:    563: Loss:     0.504331   Batch Accuracy:    0.859 
Iteration:    564: Loss:     0.419814   Batch Accuracy:    0.891 
Iteration:    565: Loss:     0.293500   Batch Accuracy:    0.930 
Iteration:    566: Loss:     0.470310   Batch Accuracy:    0.906 
Iteration:    567: Loss:     0.334136   Batch Accuracy:    0.891 
Iteration:    568: Loss:     0.399672   Batch Accuracy:    0.891 
Iteration:    569: Loss:     0.502209   Batch Accuracy:    0.875 
Iteration:    570: Loss:     0.372919   Batch Accuracy:    0.922 
Iteration:    571: Loss:     0.362000   Batch Accuracy:    0.906 
Iteration:    572: Loss:     0.337997   Batch Accuracy:    0.898 
Iteration:    573: Loss:     0.284037   Batch Accuracy:    0.922 
Iteration:    574: Loss:     0.497732   Batch Accuracy:    0.875 
Iteration:    575: Loss:     0.340270   Batch Accuracy:    0.875 
Iteration:    576: Loss:     0.454364   Batch Accuracy:    0.875 
Iteration:    577: Loss:     0.413920   Batch Accuracy:    0.859 
Iteration:    578: Loss:     0.464234   Batch Accuracy:    0.859 
Iteration:    579: Loss:     0.285036   Batch Accuracy:    0.945 
Iteration:    580: Loss:     0.402503   Batch Accuracy:    0.867 
Iteration:    581: Loss:     0.320946   Batch Accuracy:    0.938 
Iteration:    582: Loss:     0.355737   Batch Accuracy:    0.891 
Iteration:    583: Loss:     0.310344   Batch Accuracy:    0.906 
Iteration:    584: Loss:     0.439525   Batch Accuracy:    0.891 
Iteration:    585: Loss:     0.304983   Batch Accuracy:    0.891 
Iteration:    586: Loss:     0.292302   Batch Accuracy:    0.930 
Iteration:    587: Loss:     0.347864   Batch Accuracy:    0.906 
Iteration:    588: Loss:     0.325390   Batch Accuracy:    0.898 
Iteration:    589: Loss:     0.293465   Batch Accuracy:    0.938 
Iteration:    590: Loss:     0.531691   Batch Accuracy:    0.852 
Iteration:    591: Loss:     0.276765   Batch Accuracy:    0.922 
Iteration:    592: Loss:     0.327714   Batch Accuracy:    0.906 
Iteration:    593: Loss:     0.321674   Batch Accuracy:    0.930 
Iteration:    594: Loss:     0.518504   Batch Accuracy:    0.859 
Iteration:    595: Loss:     0.366143   Batch Accuracy:    0.906 
Iteration:    596: Loss:     0.341672   Batch Accuracy:    0.906 
Iteration:    597: Loss:     0.575659   Batch Accuracy:    0.867 
Iteration:    598: Loss:     0.388107   Batch Accuracy:    0.891 
Iteration:    599: Loss:     0.445308   Batch Accuracy:    0.875 
Iteration:    600: Loss:     0.312110   Batch Accuracy:    0.906 
Iteration:    601: Loss:     0.328329   Batch Accuracy:    0.906 
Iteration:    602: Loss:     0.450848   Batch Accuracy:    0.875 
Iteration:    603: Loss:     0.426800   Batch Accuracy:    0.891 
Iteration:    604: Loss:     0.335683   Batch Accuracy:    0.930 
Iteration:    605: Loss:     0.355627   Batch Accuracy:    0.891 
Iteration:    606: Loss:     0.413394   Batch Accuracy:    0.898 
Iteration:    607: Loss:     0.352425   Batch Accuracy:    0.883 
Iteration:    608: Loss:     0.451824   Batch Accuracy:    0.875 
Iteration:    609: Loss:     0.415575   Batch Accuracy:    0.883 
Iteration:    610: Loss:     0.339212   Batch Accuracy:    0.930 
Iteration:    611: Loss:     0.417845   Batch Accuracy:    0.891 
Iteration:    612: Loss:     0.436977   Batch Accuracy:    0.867 
Iteration:    613: Loss:     0.445532   Batch Accuracy:    0.930 
Iteration:    614: Loss:     0.280000   Batch Accuracy:    0.906 
Iteration:    615: Loss:     0.371532   Batch Accuracy:    0.914 
Iteration:    616: Loss:     0.373811   Batch Accuracy:    0.906 
Iteration:    617: Loss:     0.498582   Batch Accuracy:    0.852 
Iteration:    618: Loss:     0.316563   Batch Accuracy:    0.938 
Iteration:    619: Loss:     0.383869   Batch Accuracy:    0.898 
Iteration:    620: Loss:     0.404344   Batch Accuracy:    0.898 
Iteration:    621: Loss:     0.233048   Batch Accuracy:    0.953 
Iteration:    622: Loss:     0.441314   Batch Accuracy:    0.875 
Iteration:    623: Loss:     0.345424   Batch Accuracy:    0.914 
Iteration:    624: Loss:     0.587654   Batch Accuracy:    0.859 
Iteration:    625: Loss:     0.371259   Batch Accuracy:    0.891 
Iteration:    626: Loss:     0.499665   Batch Accuracy:    0.859 
Iteration:    627: Loss:     0.350758   Batch Accuracy:    0.891 
Iteration:    628: Loss:     0.362072   Batch Accuracy:    0.867 
Iteration:    629: Loss:     0.258532   Batch Accuracy:    0.922 
Iteration:    630: Loss:     0.338951   Batch Accuracy:    0.914 
Iteration:    631: Loss:     0.299611   Batch Accuracy:    0.906 
Iteration:    632: Loss:     0.480208   Batch Accuracy:    0.922 
Iteration:    633: Loss:     0.329571   Batch Accuracy:    0.906 
Iteration:    634: Loss:     0.386569   Batch Accuracy:    0.898 
Iteration:    635: Loss:     0.369526   Batch Accuracy:    0.883 
Iteration:    636: Loss:     0.328250   Batch Accuracy:    0.922 
Iteration:    637: Loss:     0.312807   Batch Accuracy:    0.930 
Iteration:    638: Loss:     0.315456   Batch Accuracy:    0.922 
Iteration:    639: Loss:     0.269111   Batch Accuracy:    0.930 
Iteration:    640: Loss:     0.379702   Batch Accuracy:    0.891 
Iteration:    641: Loss:     0.335326   Batch Accuracy:    0.914 
Iteration:    642: Loss:     0.333835   Batch Accuracy:    0.914 
Iteration:    643: Loss:     0.416706   Batch Accuracy:    0.898 
Iteration:    644: Loss:     0.308289   Batch Accuracy:    0.883 
Iteration:    645: Loss:     0.416799   Batch Accuracy:    0.914 
Iteration:    646: Loss:     0.330721   Batch Accuracy:    0.898 
Iteration:    647: Loss:     0.391069   Batch Accuracy:    0.914 
Iteration:    648: Loss:     0.320818   Batch Accuracy:    0.914 
Iteration:    649: Loss:     0.410078   Batch Accuracy:    0.906 
Iteration:    650: Loss:     0.392455   Batch Accuracy:    0.875 
Iteration:    651: Loss:     0.429666   Batch Accuracy:    0.883 
Iteration:    652: Loss:     0.383013   Batch Accuracy:    0.891 
Iteration:    653: Loss:     0.478912   Batch Accuracy:    0.867 
Iteration:    654: Loss:     0.356385   Batch Accuracy:    0.906 
Iteration:    655: Loss:     0.337419   Batch Accuracy:    0.898 
Iteration:    656: Loss:     0.420440   Batch Accuracy:    0.906 
Iteration:    657: Loss:     0.428118   Batch Accuracy:    0.875 
Iteration:    658: Loss:     0.304524   Batch Accuracy:    0.906 
Iteration:    659: Loss:     0.371699   Batch Accuracy:    0.852 
Iteration:    660: Loss:     0.297880   Batch Accuracy:    0.930 
Iteration:    661: Loss:     0.352082   Batch Accuracy:    0.883 
Iteration:    662: Loss:     0.338227   Batch Accuracy:    0.938 
Iteration:    663: Loss:     0.302954   Batch Accuracy:    0.922 
Iteration:    664: Loss:     0.403358   Batch Accuracy:    0.906 
Iteration:    665: Loss:     0.422952   Batch Accuracy:    0.898 
Iteration:    666: Loss:     0.440092   Batch Accuracy:    0.859 
Iteration:    667: Loss:     0.347507   Batch Accuracy:    0.891 
Iteration:    668: Loss:     0.383716   Batch Accuracy:    0.859 
Iteration:    669: Loss:     0.366992   Batch Accuracy:    0.914 
Iteration:    670: Loss:     0.488309   Batch Accuracy:    0.844 
Iteration:    671: Loss:     0.277605   Batch Accuracy:    0.938 
Iteration:    672: Loss:     0.526160   Batch Accuracy:    0.859 
Iteration:    673: Loss:     0.318592   Batch Accuracy:    0.922 
Iteration:    674: Loss:     0.384729   Batch Accuracy:    0.875 
Iteration:    675: Loss:     0.264135   Batch Accuracy:    0.945 
Iteration:    676: Loss:     0.313470   Batch Accuracy:    0.930 
Iteration:    677: Loss:     0.333246   Batch Accuracy:    0.898 
Iteration:    678: Loss:     0.294485   Batch Accuracy:    0.891 
Iteration:    679: Loss:     0.263490   Batch Accuracy:    0.938 
Iteration:    680: Loss:     0.361682   Batch Accuracy:    0.883 
Iteration:    681: Loss:     0.305051   Batch Accuracy:    0.922 
Iteration:    682: Loss:     0.458942   Batch Accuracy:    0.906 
Iteration:    683: Loss:     0.346164   Batch Accuracy:    0.914 
Iteration:    684: Loss:     0.379042   Batch Accuracy:    0.906 
Iteration:    685: Loss:     0.348750   Batch Accuracy:    0.898 
Iteration:    686: Loss:     0.498244   Batch Accuracy:    0.859 
Iteration:    687: Loss:     0.395027   Batch Accuracy:    0.883 
Iteration:    688: Loss:     0.466862   Batch Accuracy:    0.844 
Iteration:    689: Loss:     0.419472   Batch Accuracy:    0.883 
Iteration:    690: Loss:     0.407113   Batch Accuracy:    0.867 
Iteration:    691: Loss:     0.483979   Batch Accuracy:    0.883 
Iteration:    692: Loss:     0.309820   Batch Accuracy:    0.938 
Iteration:    693: Loss:     0.491413   Batch Accuracy:    0.859 
Iteration:    694: Loss:     0.422625   Batch Accuracy:    0.914 
Iteration:    695: Loss:     0.447709   Batch Accuracy:    0.844 
Iteration:    696: Loss:     0.362695   Batch Accuracy:    0.906 
Iteration:    697: Loss:     0.336617   Batch Accuracy:    0.891 
Iteration:    698: Loss:     0.424452   Batch Accuracy:    0.883 
Iteration:    699: Loss:     0.425017   Batch Accuracy:    0.852 
Iteration:    700: Loss:     0.377697   Batch Accuracy:    0.906 
Iteration:    701: Loss:     0.275755   Batch Accuracy:    0.945 
Iteration:    702: Loss:     0.476837   Batch Accuracy:    0.875 
Iteration:    703: Loss:     0.356751   Batch Accuracy:    0.930 
Iteration:    704: Loss:     0.360967   Batch Accuracy:    0.906 
Iteration:    705: Loss:     0.385162   Batch Accuracy:    0.875 
Iteration:    706: Loss:     0.581332   Batch Accuracy:    0.844 
Iteration:    707: Loss:     0.265275   Batch Accuracy:    0.930 
Iteration:    708: Loss:     0.454681   Batch Accuracy:    0.875 
Iteration:    709: Loss:     0.350711   Batch Accuracy:    0.898 
Iteration:    710: Loss:     0.371138   Batch Accuracy:    0.898 
Iteration:    711: Loss:     0.361809   Batch Accuracy:    0.898 
Iteration:    712: Loss:     0.451085   Batch Accuracy:    0.844 
Iteration:    713: Loss:     0.400430   Batch Accuracy:    0.891 
Iteration:    714: Loss:     0.327217   Batch Accuracy:    0.883 
Iteration:    715: Loss:     0.286774   Batch Accuracy:    0.930 
Iteration:    716: Loss:     0.463224   Batch Accuracy:    0.844 
Iteration:    717: Loss:     0.306618   Batch Accuracy:    0.930 
Iteration:    718: Loss:     0.349831   Batch Accuracy:    0.891 
Iteration:    719: Loss:     0.322356   Batch Accuracy:    0.922 
Iteration:    720: Loss:     0.397861   Batch Accuracy:    0.898 
Iteration:    721: Loss:     0.340549   Batch Accuracy:    0.922 
Iteration:    722: Loss:     0.357233   Batch Accuracy:    0.906 
Iteration:    723: Loss:     0.309965   Batch Accuracy:    0.922 
Iteration:    724: Loss:     0.403308   Batch Accuracy:    0.898 
Iteration:    725: Loss:     0.362539   Batch Accuracy:    0.906 
Iteration:    726: Loss:     0.367617   Batch Accuracy:    0.914 
Iteration:    727: Loss:     0.288226   Batch Accuracy:    0.945 
Iteration:    728: Loss:     0.340942   Batch Accuracy:    0.914 
Iteration:    729: Loss:     0.444805   Batch Accuracy:    0.836 
Iteration:    730: Loss:     0.494097   Batch Accuracy:    0.859 
Iteration:    731: Loss:     0.219038   Batch Accuracy:    0.930 
Iteration:    732: Loss:     0.272031   Batch Accuracy:    0.945 
Iteration:    733: Loss:     0.501997   Batch Accuracy:    0.891 
Iteration:    734: Loss:     0.360497   Batch Accuracy:    0.883 
Iteration:    735: Loss:     0.390328   Batch Accuracy:    0.906 
Iteration:    736: Loss:     0.341534   Batch Accuracy:    0.945 
Iteration:    737: Loss:     0.238690   Batch Accuracy:    0.945 
Iteration:    738: Loss:     0.335538   Batch Accuracy:    0.914 
Iteration:    739: Loss:     0.387672   Batch Accuracy:    0.852 
Iteration:    740: Loss:     0.312414   Batch Accuracy:    0.891 
Iteration:    741: Loss:     0.422670   Batch Accuracy:    0.867 
Iteration:    742: Loss:     0.283531   Batch Accuracy:    0.930 
Iteration:    743: Loss:     0.232910   Batch Accuracy:    0.938 
Iteration:    744: Loss:     0.268432   Batch Accuracy:    0.922 
Iteration:    745: Loss:     0.388027   Batch Accuracy:    0.891 
Iteration:    746: Loss:     0.278178   Batch Accuracy:    0.930 
Iteration:    747: Loss:     0.328621   Batch Accuracy:    0.914 
Iteration:    748: Loss:     0.251766   Batch Accuracy:    0.930 
Iteration:    749: Loss:     0.307786   Batch Accuracy:    0.945 
Iteration:    750: Loss:     0.376179   Batch Accuracy:    0.883 
Iteration:    751: Loss:     0.279908   Batch Accuracy:    0.945 
Iteration:    752: Loss:     0.306181   Batch Accuracy:    0.922 
Iteration:    753: Loss:     0.393577   Batch Accuracy:    0.898 
Iteration:    754: Loss:     0.377751   Batch Accuracy:    0.859 
Iteration:    755: Loss:     0.360834   Batch Accuracy:    0.906 
Iteration:    756: Loss:     0.422935   Batch Accuracy:    0.898 
Iteration:    757: Loss:     0.314400   Batch Accuracy:    0.930 
Iteration:    758: Loss:     0.303213   Batch Accuracy:    0.914 
Iteration:    759: Loss:     0.469613   Batch Accuracy:    0.867 
Iteration:    760: Loss:     0.304108   Batch Accuracy:    0.930 
Iteration:    761: Loss:     0.319075   Batch Accuracy:    0.914 
Iteration:    762: Loss:     0.326864   Batch Accuracy:    0.891 
Iteration:    763: Loss:     0.373571   Batch Accuracy:    0.883 
Iteration:    764: Loss:     0.494507   Batch Accuracy:    0.828 
Iteration:    765: Loss:     0.433171   Batch Accuracy:    0.859 
Iteration:    766: Loss:     0.385793   Batch Accuracy:    0.914 
Iteration:    767: Loss:     0.252671   Batch Accuracy:    0.914 
Iteration:    768: Loss:     0.429849   Batch Accuracy:    0.891 
Iteration:    769: Loss:     0.395804   Batch Accuracy:    0.914 
Iteration:    770: Loss:     0.429237   Batch Accuracy:    0.867 
Iteration:    771: Loss:     0.290368   Batch Accuracy:    0.898 
Iteration:    772: Loss:     0.426820   Batch Accuracy:    0.875 
Iteration:    773: Loss:     0.454687   Batch Accuracy:    0.844 
Iteration:    774: Loss:     0.452279   Batch Accuracy:    0.891 
Iteration:    775: Loss:     0.359936   Batch Accuracy:    0.875 
Iteration:    776: Loss:     0.529445   Batch Accuracy:    0.891 
Iteration:    777: Loss:     0.304740   Batch Accuracy:    0.914 
Iteration:    778: Loss:     0.300732   Batch Accuracy:    0.938 
Iteration:    779: Loss:     0.332251   Batch Accuracy:    0.922 
Iteration:    780: Loss:     0.434604   Batch Accuracy:    0.859 
Iteration:    781: Loss:     0.350312   Batch Accuracy:    0.914 
Iteration:    782: Loss:     0.403649   Batch Accuracy:    0.891 
Iteration:    783: Loss:     0.365434   Batch Accuracy:    0.906 
Iteration:    784: Loss:     0.241223   Batch Accuracy:    0.953 
Iteration:    785: Loss:     0.321185   Batch Accuracy:    0.922 
Iteration:    786: Loss:     0.349262   Batch Accuracy:    0.930 
Iteration:    787: Loss:     0.362914   Batch Accuracy:    0.922 
Iteration:    788: Loss:     0.343015   Batch Accuracy:    0.898 
Iteration:    789: Loss:     0.336425   Batch Accuracy:    0.922 
Iteration:    790: Loss:     0.417011   Batch Accuracy:    0.875 
Iteration:    791: Loss:     0.352929   Batch Accuracy:    0.898 
Iteration:    792: Loss:     0.407191   Batch Accuracy:    0.891 
Iteration:    793: Loss:     0.415239   Batch Accuracy:    0.875 
Iteration:    794: Loss:     0.429187   Batch Accuracy:    0.906 
Iteration:    795: Loss:     0.205432   Batch Accuracy:    0.945 
Iteration:    796: Loss:     0.319903   Batch Accuracy:    0.922 
Iteration:    797: Loss:     0.411169   Batch Accuracy:    0.914 
Iteration:    798: Loss:     0.431748   Batch Accuracy:    0.875 
Iteration:    799: Loss:     0.368540   Batch Accuracy:    0.867 
Iteration:    800: Loss:     0.290893   Batch Accuracy:    0.922 
Iteration:    801: Loss:     0.370394   Batch Accuracy:    0.875 
Iteration:    802: Loss:     0.374519   Batch Accuracy:    0.898 
Iteration:    803: Loss:     0.334019   Batch Accuracy:    0.883 
Iteration:    804: Loss:     0.328348   Batch Accuracy:    0.898 
Iteration:    805: Loss:     0.410538   Batch Accuracy:    0.859 
Iteration:    806: Loss:     0.377476   Batch Accuracy:    0.891 
Iteration:    807: Loss:     0.562880   Batch Accuracy:    0.836 
Iteration:    808: Loss:     0.277795   Batch Accuracy:    0.938 
Iteration:    809: Loss:     0.326848   Batch Accuracy:    0.914 
Iteration:    810: Loss:     0.301949   Batch Accuracy:    0.938 
Iteration:    811: Loss:     0.337080   Batch Accuracy:    0.898 
Iteration:    812: Loss:     0.394033   Batch Accuracy:    0.867 
Iteration:    813: Loss:     0.292227   Batch Accuracy:    0.930 
Iteration:    814: Loss:     0.419697   Batch Accuracy:    0.891 
Iteration:    815: Loss:     0.454315   Batch Accuracy:    0.875 
Iteration:    816: Loss:     0.413876   Batch Accuracy:    0.898 
Iteration:    817: Loss:     0.398775   Batch Accuracy:    0.875 
Iteration:    818: Loss:     0.370078   Batch Accuracy:    0.883 
Iteration:    819: Loss:     0.309788   Batch Accuracy:    0.906 
Iteration:    820: Loss:     0.333256   Batch Accuracy:    0.906 
Iteration:    821: Loss:     0.370549   Batch Accuracy:    0.906 
Iteration:    822: Loss:     0.319457   Batch Accuracy:    0.922 
Iteration:    823: Loss:     0.313699   Batch Accuracy:    0.898 
Iteration:    824: Loss:     0.465247   Batch Accuracy:    0.867 
Iteration:    825: Loss:     0.425739   Batch Accuracy:    0.898 
Iteration:    826: Loss:     0.367663   Batch Accuracy:    0.906 
Iteration:    827: Loss:     0.345544   Batch Accuracy:    0.914 
Iteration:    828: Loss:     0.492827   Batch Accuracy:    0.891 
Iteration:    829: Loss:     0.427203   Batch Accuracy:    0.867 
Iteration:    830: Loss:     0.406676   Batch Accuracy:    0.898 
Iteration:    831: Loss:     0.361861   Batch Accuracy:    0.898 
Iteration:    832: Loss:     0.407250   Batch Accuracy:    0.914 
Iteration:    833: Loss:     0.398459   Batch Accuracy:    0.867 
Iteration:    834: Loss:     0.385429   Batch Accuracy:    0.898 
Iteration:    835: Loss:     0.373481   Batch Accuracy:    0.914 
Iteration:    836: Loss:     0.418859   Batch Accuracy:    0.844 
Iteration:    837: Loss:     0.293223   Batch Accuracy:    0.922 
Iteration:    838: Loss:     0.404125   Batch Accuracy:    0.891 
Iteration:    839: Loss:     0.332049   Batch Accuracy:    0.898 
Iteration:    840: Loss:     0.322215   Batch Accuracy:    0.906 
Iteration:    841: Loss:     0.365631   Batch Accuracy:    0.883 
Iteration:    842: Loss:     0.433686   Batch Accuracy:    0.875 
Iteration:    843: Loss:     0.412582   Batch Accuracy:    0.875 
Iteration:    844: Loss:     0.405115   Batch Accuracy:    0.883 
Iteration:    845: Loss:     0.281641   Batch Accuracy:    0.922 
Iteration:    846: Loss:     0.301170   Batch Accuracy:    0.914 
Iteration:    847: Loss:     0.307440   Batch Accuracy:    0.922 
Iteration:    848: Loss:     0.409262   Batch Accuracy:    0.914 
Iteration:    849: Loss:     0.344289   Batch Accuracy:    0.898 
Iteration:    850: Loss:     0.374685   Batch Accuracy:    0.898 
Iteration:    851: Loss:     0.250297   Batch Accuracy:    0.938 
Iteration:    852: Loss:     0.302433   Batch Accuracy:    0.906 
Iteration:    853: Loss:     0.363844   Batch Accuracy:    0.883 
Iteration:    854: Loss:     0.388880   Batch Accuracy:    0.898 
Iteration:    855: Loss:     0.469848   Batch Accuracy:    0.883 
Iteration:    856: Loss:     0.428826   Batch Accuracy:    0.875 
Iteration:    857: Loss:     0.392508   Batch Accuracy:    0.883 
Iteration:    858: Loss:     0.379322   Batch Accuracy:    0.875 
Iteration:    859: Loss:     0.431310   Batch Accuracy:    0.891 
Iteration:    860: Loss:     0.385293   Batch Accuracy:    0.891 
Iteration:    861: Loss:     0.260652   Batch Accuracy:    0.922 
Iteration:    862: Loss:     0.377405   Batch Accuracy:    0.914 
Iteration:    863: Loss:     0.392624   Batch Accuracy:    0.898 
Iteration:    864: Loss:     0.333920   Batch Accuracy:    0.922 
Iteration:    865: Loss:     0.325460   Batch Accuracy:    0.930 
Iteration:    866: Loss:     0.339001   Batch Accuracy:    0.906 
Iteration:    867: Loss:     0.325698   Batch Accuracy:    0.875 
Iteration:    868: Loss:     0.353953   Batch Accuracy:    0.930 
Iteration:    869: Loss:     0.407865   Batch Accuracy:    0.852 
Iteration:    870: Loss:     0.259689   Batch Accuracy:    0.938 
Iteration:    871: Loss:     0.324945   Batch Accuracy:    0.906 
Iteration:    872: Loss:     0.380992   Batch Accuracy:    0.891 
Iteration:    873: Loss:     0.337022   Batch Accuracy:    0.906 
Iteration:    874: Loss:     0.339206   Batch Accuracy:    0.883 
Iteration:    875: Loss:     0.242284   Batch Accuracy:    0.922 
Iteration:    876: Loss:     0.263724   Batch Accuracy:    0.891 
Iteration:    877: Loss:     0.484128   Batch Accuracy:    0.867 
Iteration:    878: Loss:     0.265200   Batch Accuracy:    0.930 
Iteration:    879: Loss:     0.451455   Batch Accuracy:    0.867 
Iteration:    880: Loss:     0.422722   Batch Accuracy:    0.883 
Iteration:    881: Loss:     0.491040   Batch Accuracy:    0.852 
Iteration:    882: Loss:     0.312216   Batch Accuracy:    0.922 
Iteration:    883: Loss:     0.376956   Batch Accuracy:    0.898 
Iteration:    884: Loss:     0.381487   Batch Accuracy:    0.891 
Iteration:    885: Loss:     0.330552   Batch Accuracy:    0.938 
Iteration:    886: Loss:     0.383750   Batch Accuracy:    0.906 
Iteration:    887: Loss:     0.246547   Batch Accuracy:    0.930 
Iteration:    888: Loss:     0.369880   Batch Accuracy:    0.906 
Iteration:    889: Loss:     0.302812   Batch Accuracy:    0.930 
Iteration:    890: Loss:     0.319167   Batch Accuracy:    0.906 
Iteration:    891: Loss:     0.278530   Batch Accuracy:    0.945 
Iteration:    892: Loss:     0.375567   Batch Accuracy:    0.898 
Iteration:    893: Loss:     0.330187   Batch Accuracy:    0.914 
Iteration:    894: Loss:     0.387545   Batch Accuracy:    0.883 
Iteration:    895: Loss:     0.298321   Batch Accuracy:    0.906 
Iteration:    896: Loss:     0.395480   Batch Accuracy:    0.883 
Iteration:    897: Loss:     0.283886   Batch Accuracy:    0.922 
Iteration:    898: Loss:     0.427138   Batch Accuracy:    0.898 
Iteration:    899: Loss:     0.329607   Batch Accuracy:    0.930 
Iteration:    900: Loss:     0.347261   Batch Accuracy:    0.875 
Iteration:    901: Loss:     0.282901   Batch Accuracy:    0.938 
Iteration:    902: Loss:     0.338555   Batch Accuracy:    0.898 
Iteration:    903: Loss:     0.368080   Batch Accuracy:    0.859 
Iteration:    904: Loss:     0.322456   Batch Accuracy:    0.922 
Iteration:    905: Loss:     0.275027   Batch Accuracy:    0.930 
Iteration:    906: Loss:     0.288421   Batch Accuracy:    0.906 
Iteration:    907: Loss:     0.359738   Batch Accuracy:    0.898 
Iteration:    908: Loss:     0.300485   Batch Accuracy:    0.922 
Iteration:    909: Loss:     0.268303   Batch Accuracy:    0.945 
Iteration:    910: Loss:     0.214718   Batch Accuracy:    0.961 
Iteration:    911: Loss:     0.228236   Batch Accuracy:    0.961 
Iteration:    912: Loss:     0.379049   Batch Accuracy:    0.898 
Iteration:    913: Loss:     0.471458   Batch Accuracy:    0.844 
Iteration:    914: Loss:     0.432014   Batch Accuracy:    0.859 
Iteration:    915: Loss:     0.460453   Batch Accuracy:    0.867 
Iteration:    916: Loss:     0.366449   Batch Accuracy:    0.867 
Iteration:    917: Loss:     0.326911   Batch Accuracy:    0.906 
Iteration:    918: Loss:     0.311876   Batch Accuracy:    0.922 
Iteration:    919: Loss:     0.238375   Batch Accuracy:    0.938 
Iteration:    920: Loss:     0.414822   Batch Accuracy:    0.844 
Iteration:    921: Loss:     0.276267   Batch Accuracy:    0.922 
Iteration:    922: Loss:     0.277650   Batch Accuracy:    0.898 
Iteration:    923: Loss:     0.382052   Batch Accuracy:    0.883 
Iteration:    924: Loss:     0.420448   Batch Accuracy:    0.875 
Iteration:    925: Loss:     0.342428   Batch Accuracy:    0.898 
Iteration:    926: Loss:     0.370776   Batch Accuracy:    0.898 
Iteration:    927: Loss:     0.423051   Batch Accuracy:    0.875 
Iteration:    928: Loss:     0.508753   Batch Accuracy:    0.812 
Iteration:    929: Loss:     0.398675   Batch Accuracy:    0.891 
Iteration:    930: Loss:     0.344417   Batch Accuracy:    0.898 
Iteration:    931: Loss:     0.444863   Batch Accuracy:    0.852 
Iteration:    932: Loss:     0.355592   Batch Accuracy:    0.930 
Iteration:    933: Loss:     0.277985   Batch Accuracy:    0.938 
Iteration:    934: Loss:     0.411699   Batch Accuracy:    0.859 
Iteration:    935: Loss:     0.221485   Batch Accuracy:    0.961 
Iteration:    936: Loss:     0.413918   Batch Accuracy:    0.906 
Iteration:    937: Loss:     0.381108   Batch Accuracy:    0.859 
Iteration:    938: Loss:     0.501662   Batch Accuracy:    0.875 
Iteration:    939: Loss:     0.390364   Batch Accuracy:    0.891 
Iteration:    940: Loss:     0.398470   Batch Accuracy:    0.883 
Iteration:    941: Loss:     0.271938   Batch Accuracy:    0.914 
Iteration:    942: Loss:     0.358311   Batch Accuracy:    0.914 
Iteration:    943: Loss:     0.347592   Batch Accuracy:    0.891 
Iteration:    944: Loss:     0.320289   Batch Accuracy:    0.898 
Iteration:    945: Loss:     0.401647   Batch Accuracy:    0.891 
Iteration:    946: Loss:     0.430705   Batch Accuracy:    0.859 
Iteration:    947: Loss:     0.255156   Batch Accuracy:    0.945 
Iteration:    948: Loss:     0.357314   Batch Accuracy:    0.906 
Iteration:    949: Loss:     0.476093   Batch Accuracy:    0.891 
Iteration:    950: Loss:     0.408043   Batch Accuracy:    0.883 
Iteration:    951: Loss:     0.339016   Batch Accuracy:    0.859 
Iteration:    952: Loss:     0.268756   Batch Accuracy:    0.922 
Iteration:    953: Loss:     0.399173   Batch Accuracy:    0.883 
Iteration:    954: Loss:     0.418171   Batch Accuracy:    0.891 
Iteration:    955: Loss:     0.433503   Batch Accuracy:    0.891 
Iteration:    956: Loss:     0.436903   Batch Accuracy:    0.875 
Iteration:    957: Loss:     0.380356   Batch Accuracy:    0.906 
Iteration:    958: Loss:     0.335316   Batch Accuracy:    0.922 
Iteration:    959: Loss:     0.399846   Batch Accuracy:    0.867 
Iteration:    960: Loss:     0.256379   Batch Accuracy:    0.930 
Iteration:    961: Loss:     0.364320   Batch Accuracy:    0.914 
Iteration:    962: Loss:     0.321338   Batch Accuracy:    0.930 
Iteration:    963: Loss:     0.371247   Batch Accuracy:    0.891 
Iteration:    964: Loss:     0.253206   Batch Accuracy:    0.914 
Iteration:    965: Loss:     0.306873   Batch Accuracy:    0.914 
Iteration:    966: Loss:     0.387005   Batch Accuracy:    0.930 
Iteration:    967: Loss:     0.328121   Batch Accuracy:    0.922 
Iteration:    968: Loss:     0.518431   Batch Accuracy:    0.852 
Iteration:    969: Loss:     0.519646   Batch Accuracy:    0.883 
Iteration:    970: Loss:     0.310218   Batch Accuracy:    0.922 
Iteration:    971: Loss:     0.398567   Batch Accuracy:    0.883 
Iteration:    972: Loss:     0.417189   Batch Accuracy:    0.891 
Iteration:    973: Loss:     0.349917   Batch Accuracy:    0.914 
Iteration:    974: Loss:     0.380678   Batch Accuracy:    0.875 
Iteration:    975: Loss:     0.431579   Batch Accuracy:    0.836 
Iteration:    976: Loss:     0.326729   Batch Accuracy:    0.914 
Iteration:    977: Loss:     0.412203   Batch Accuracy:    0.898 
Iteration:    978: Loss:     0.352298   Batch Accuracy:    0.906 
Iteration:    979: Loss:     0.276101   Batch Accuracy:    0.914 
Iteration:    980: Loss:     0.377170   Batch Accuracy:    0.883 
Iteration:    981: Loss:     0.347658   Batch Accuracy:    0.891 
Iteration:    982: Loss:     0.271116   Batch Accuracy:    0.914 
Iteration:    983: Loss:     0.454987   Batch Accuracy:    0.844 
Iteration:    984: Loss:     0.279685   Batch Accuracy:    0.938 
Iteration:    985: Loss:     0.406539   Batch Accuracy:    0.891 
Iteration:    986: Loss:     0.305702   Batch Accuracy:    0.922 
Iteration:    987: Loss:     0.313746   Batch Accuracy:    0.930 
Iteration:    988: Loss:     0.371857   Batch Accuracy:    0.914 
Iteration:    989: Loss:     0.383920   Batch Accuracy:    0.914 
Iteration:    990: Loss:     0.400939   Batch Accuracy:    0.859 
Iteration:    991: Loss:     0.379283   Batch Accuracy:    0.898 
Iteration:    992: Loss:     0.343831   Batch Accuracy:    0.875 
Iteration:    993: Loss:     0.369462   Batch Accuracy:    0.883 
Iteration:    994: Loss:     0.334970   Batch Accuracy:    0.922 
Iteration:    995: Loss:     0.294903   Batch Accuracy:    0.938 
Iteration:    996: Loss:     0.374814   Batch Accuracy:    0.914 
Iteration:    997: Loss:     0.225465   Batch Accuracy:    0.938 
Iteration:    998: Loss:     0.303127   Batch Accuracy:    0.922 
Iteration:    999: Loss:     0.392895   Batch Accuracy:    0.867 
evaluating model...
training accuracy: 0.901600
test accuracy:     0.909300
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./compile.sh 
-- Configuring done
CMake Warning (dev):
  Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run "cmake
  --help-policy CMP0042" for policy details.  Use the cmake_policy command to
  set the policy and suppress this warning.

  MACOSX_RPATH is not specified for the following targets:

   nn

This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /Users/jasonhoffman/repos/cv576/cse576_sp20_hw3/build
[ 55%] Built target nn
Scanning dependencies of target train
[ 77%] Built target test
[ 88%] Building CXX object CMakeFiles/train.dir/src/train.cpp.o
[100%] Linking CXX executable ../train
[100%] Built target train
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./train
Loading dataset
Parameters: Rate=0.010000
Training model...
Iteration:      0: Loss:     2.305447   Batch Accuracy:    0.094 
Iteration:      1: Loss:     2.312885   Batch Accuracy:    0.047 
Iteration:      2: Loss:     2.288629   Batch Accuracy:    0.117 
Iteration:      3: Loss:     2.277914   Batch Accuracy:    0.109 
Iteration:      4: Loss:     2.205979   Batch Accuracy:    0.156 
Iteration:      5: Loss:     2.181271   Batch Accuracy:    0.195 
Iteration:      6: Loss:     2.132293   Batch Accuracy:    0.297 
Iteration:      7: Loss:     2.083115   Batch Accuracy:    0.367 
Iteration:      8: Loss:     2.022332   Batch Accuracy:    0.383 
Iteration:      9: Loss:     1.986233   Batch Accuracy:    0.430 
Iteration:     10: Loss:     1.929137   Batch Accuracy:    0.422 
Iteration:     11: Loss:     1.865869   Batch Accuracy:    0.453 
Iteration:     12: Loss:     1.825265   Batch Accuracy:    0.555 
Iteration:     13: Loss:     1.801974   Batch Accuracy:    0.492 
Iteration:     14: Loss:     1.715767   Batch Accuracy:    0.578 
Iteration:     15: Loss:     1.598987   Batch Accuracy:    0.711 
Iteration:     16: Loss:     1.533111   Batch Accuracy:    0.742 
Iteration:     17: Loss:     1.578413   Batch Accuracy:    0.680 
Iteration:     18: Loss:     1.548540   Batch Accuracy:    0.680 
Iteration:     19: Loss:     1.500443   Batch Accuracy:    0.719 
Iteration:     20: Loss:     1.398893   Batch Accuracy:    0.797 
Iteration:     21: Loss:     1.313986   Batch Accuracy:    0.727 
Iteration:     22: Loss:     1.228117   Batch Accuracy:    0.766 
Iteration:     23: Loss:     1.336982   Batch Accuracy:    0.766 
Iteration:     24: Loss:     1.306732   Batch Accuracy:    0.734 
Iteration:     25: Loss:     1.268805   Batch Accuracy:    0.727 
Iteration:     26: Loss:     1.114982   Batch Accuracy:    0.781 
Iteration:     27: Loss:     1.214090   Batch Accuracy:    0.750 
Iteration:     28: Loss:     1.081687   Batch Accuracy:    0.781 
Iteration:     29: Loss:     1.065684   Batch Accuracy:    0.766 
Iteration:     30: Loss:     1.073326   Batch Accuracy:    0.742 
Iteration:     31: Loss:     1.012687   Batch Accuracy:    0.789 
Iteration:     32: Loss:     1.021062   Batch Accuracy:    0.781 
Iteration:     33: Loss:     0.916445   Batch Accuracy:    0.828 
Iteration:     34: Loss:     0.977361   Batch Accuracy:    0.742 
Iteration:     35: Loss:     0.926220   Batch Accuracy:    0.820 
Iteration:     36: Loss:     0.946078   Batch Accuracy:    0.781 
Iteration:     37: Loss:     0.949531   Batch Accuracy:    0.797 
Iteration:     38: Loss:     0.842609   Batch Accuracy:    0.844 
Iteration:     39: Loss:     0.890660   Batch Accuracy:    0.812 
Iteration:     40: Loss:     0.946475   Batch Accuracy:    0.805 
Iteration:     41: Loss:     0.872257   Batch Accuracy:    0.797 
Iteration:     42: Loss:     0.933221   Batch Accuracy:    0.734 
Iteration:     43: Loss:     0.791373   Batch Accuracy:    0.859 
Iteration:     44: Loss:     0.975238   Batch Accuracy:    0.773 
Iteration:     45: Loss:     0.820331   Batch Accuracy:    0.836 
Iteration:     46: Loss:     0.783941   Batch Accuracy:    0.812 
Iteration:     47: Loss:     0.854890   Batch Accuracy:    0.797 
Iteration:     48: Loss:     0.862059   Batch Accuracy:    0.773 
Iteration:     49: Loss:     0.900260   Batch Accuracy:    0.773 
Iteration:     50: Loss:     0.896435   Batch Accuracy:    0.766 
Iteration:     51: Loss:     0.751762   Batch Accuracy:    0.820 
Iteration:     52: Loss:     0.761615   Batch Accuracy:    0.836 
Iteration:     53: Loss:     0.788631   Batch Accuracy:    0.820 
Iteration:     54: Loss:     0.762458   Batch Accuracy:    0.805 
Iteration:     55: Loss:     0.761292   Batch Accuracy:    0.852 
Iteration:     56: Loss:     0.766755   Batch Accuracy:    0.812 
Iteration:     57: Loss:     0.706284   Batch Accuracy:    0.836 
Iteration:     58: Loss:     0.697706   Batch Accuracy:    0.875 
Iteration:     59: Loss:     0.708254   Batch Accuracy:    0.844 
Iteration:     60: Loss:     0.884744   Batch Accuracy:    0.805 
Iteration:     61: Loss:     0.677417   Batch Accuracy:    0.867 
Iteration:     62: Loss:     0.873406   Batch Accuracy:    0.766 
Iteration:     63: Loss:     0.732811   Batch Accuracy:    0.844 
Iteration:     64: Loss:     0.717891   Batch Accuracy:    0.859 
Iteration:     65: Loss:     0.850188   Batch Accuracy:    0.812 
Iteration:     66: Loss:     0.720047   Batch Accuracy:    0.852 
Iteration:     67: Loss:     0.665109   Batch Accuracy:    0.883 
Iteration:     68: Loss:     0.726727   Batch Accuracy:    0.812 
Iteration:     69: Loss:     0.782462   Batch Accuracy:    0.820 
Iteration:     70: Loss:     0.798580   Batch Accuracy:    0.805 
Iteration:     71: Loss:     0.706837   Batch Accuracy:    0.805 
Iteration:     72: Loss:     0.825092   Batch Accuracy:    0.773 
Iteration:     73: Loss:     0.637983   Batch Accuracy:    0.797 
Iteration:     74: Loss:     0.599104   Batch Accuracy:    0.867 
Iteration:     75: Loss:     0.595619   Batch Accuracy:    0.898 
Iteration:     76: Loss:     0.697830   Batch Accuracy:    0.836 
Iteration:     77: Loss:     0.636599   Batch Accuracy:    0.875 
Iteration:     78: Loss:     0.625662   Batch Accuracy:    0.852 
Iteration:     79: Loss:     0.714174   Batch Accuracy:    0.820 
Iteration:     80: Loss:     0.637682   Batch Accuracy:    0.852 
Iteration:     81: Loss:     0.662699   Batch Accuracy:    0.844 
Iteration:     82: Loss:     0.593937   Batch Accuracy:    0.914 
Iteration:     83: Loss:     0.630150   Batch Accuracy:    0.844 
Iteration:     84: Loss:     0.626952   Batch Accuracy:    0.844 
Iteration:     85: Loss:     0.560647   Batch Accuracy:    0.867 
Iteration:     86: Loss:     0.678083   Batch Accuracy:    0.812 
Iteration:     87: Loss:     0.594675   Batch Accuracy:    0.852 
Iteration:     88: Loss:     0.685303   Batch Accuracy:    0.828 
Iteration:     89: Loss:     0.549566   Batch Accuracy:    0.883 
Iteration:     90: Loss:     0.632413   Batch Accuracy:    0.859 
Iteration:     91: Loss:     0.736367   Batch Accuracy:    0.789 
Iteration:     92: Loss:     0.514290   Batch Accuracy:    0.883 
Iteration:     93: Loss:     0.733145   Batch Accuracy:    0.789 
Iteration:     94: Loss:     0.699182   Batch Accuracy:    0.820 
Iteration:     95: Loss:     0.519610   Batch Accuracy:    0.906 
Iteration:     96: Loss:     0.670903   Batch Accuracy:    0.852 
Iteration:     97: Loss:     0.607403   Batch Accuracy:    0.852 
Iteration:     98: Loss:     0.657640   Batch Accuracy:    0.773 
Iteration:     99: Loss:     0.513714   Batch Accuracy:    0.867 
Iteration:    100: Loss:     0.528230   Batch Accuracy:    0.859 
Iteration:    101: Loss:     0.635868   Batch Accuracy:    0.852 
Iteration:    102: Loss:     0.512873   Batch Accuracy:    0.875 
Iteration:    103: Loss:     0.615968   Batch Accuracy:    0.852 
Iteration:    104: Loss:     0.557722   Batch Accuracy:    0.867 
Iteration:    105: Loss:     0.591128   Batch Accuracy:    0.805 
Iteration:    106: Loss:     0.644620   Batch Accuracy:    0.820 
Iteration:    107: Loss:     0.656488   Batch Accuracy:    0.836 
Iteration:    108: Loss:     0.668268   Batch Accuracy:    0.789 
Iteration:    109: Loss:     0.577840   Batch Accuracy:    0.859 
Iteration:    110: Loss:     0.632731   Batch Accuracy:    0.836 
Iteration:    111: Loss:     0.548849   Batch Accuracy:    0.859 
Iteration:    112: Loss:     0.669541   Batch Accuracy:    0.820 
Iteration:    113: Loss:     0.591102   Batch Accuracy:    0.852 
Iteration:    114: Loss:     0.522295   Batch Accuracy:    0.891 
Iteration:    115: Loss:     0.577880   Batch Accuracy:    0.883 
Iteration:    116: Loss:     0.546453   Batch Accuracy:    0.867 
Iteration:    117: Loss:     0.535340   Batch Accuracy:    0.852 
Iteration:    118: Loss:     0.578386   Batch Accuracy:    0.828 
Iteration:    119: Loss:     0.567301   Batch Accuracy:    0.844 
Iteration:    120: Loss:     0.605654   Batch Accuracy:    0.828 
Iteration:    121: Loss:     0.612160   Batch Accuracy:    0.859 
Iteration:    122: Loss:     0.528236   Batch Accuracy:    0.844 
Iteration:    123: Loss:     0.576620   Batch Accuracy:    0.844 
Iteration:    124: Loss:     0.706692   Batch Accuracy:    0.789 
Iteration:    125: Loss:     0.532307   Batch Accuracy:    0.906 
Iteration:    126: Loss:     0.493185   Batch Accuracy:    0.891 
Iteration:    127: Loss:     0.569636   Batch Accuracy:    0.859 
Iteration:    128: Loss:     0.511471   Batch Accuracy:    0.914 
Iteration:    129: Loss:     0.500992   Batch Accuracy:    0.891 
Iteration:    130: Loss:     0.593138   Batch Accuracy:    0.852 
Iteration:    131: Loss:     0.587722   Batch Accuracy:    0.820 
Iteration:    132: Loss:     0.503703   Batch Accuracy:    0.891 
Iteration:    133: Loss:     0.522661   Batch Accuracy:    0.898 
Iteration:    134: Loss:     0.632600   Batch Accuracy:    0.812 
Iteration:    135: Loss:     0.457085   Batch Accuracy:    0.883 
Iteration:    136: Loss:     0.593033   Batch Accuracy:    0.859 
Iteration:    137: Loss:     0.654840   Batch Accuracy:    0.797 
Iteration:    138: Loss:     0.573796   Batch Accuracy:    0.844 
Iteration:    139: Loss:     0.614316   Batch Accuracy:    0.828 
Iteration:    140: Loss:     0.541797   Batch Accuracy:    0.883 
Iteration:    141: Loss:     0.541498   Batch Accuracy:    0.875 
Iteration:    142: Loss:     0.497511   Batch Accuracy:    0.922 
Iteration:    143: Loss:     0.508338   Batch Accuracy:    0.875 
Iteration:    144: Loss:     0.543020   Batch Accuracy:    0.891 
Iteration:    145: Loss:     0.544659   Batch Accuracy:    0.883 
Iteration:    146: Loss:     0.580920   Batch Accuracy:    0.836 
Iteration:    147: Loss:     0.511924   Batch Accuracy:    0.867 
Iteration:    148: Loss:     0.544021   Batch Accuracy:    0.852 
Iteration:    149: Loss:     0.524089   Batch Accuracy:    0.867 
Iteration:    150: Loss:     0.626664   Batch Accuracy:    0.836 
Iteration:    151: Loss:     0.533428   Batch Accuracy:    0.883 
Iteration:    152: Loss:     0.484948   Batch Accuracy:    0.875 
Iteration:    153: Loss:     0.561455   Batch Accuracy:    0.836 
Iteration:    154: Loss:     0.498616   Batch Accuracy:    0.875 
Iteration:    155: Loss:     0.610498   Batch Accuracy:    0.852 
Iteration:    156: Loss:     0.447903   Batch Accuracy:    0.930 
Iteration:    157: Loss:     0.420174   Batch Accuracy:    0.914 
Iteration:    158: Loss:     0.500811   Batch Accuracy:    0.852 
Iteration:    159: Loss:     0.536904   Batch Accuracy:    0.859 
Iteration:    160: Loss:     0.491264   Batch Accuracy:    0.906 
Iteration:    161: Loss:     0.595553   Batch Accuracy:    0.828 
Iteration:    162: Loss:     0.612130   Batch Accuracy:    0.844 
Iteration:    163: Loss:     0.525592   Batch Accuracy:    0.852 
Iteration:    164: Loss:     0.467993   Batch Accuracy:    0.891 
Iteration:    165: Loss:     0.503241   Batch Accuracy:    0.852 
Iteration:    166: Loss:     0.543267   Batch Accuracy:    0.859 
Iteration:    167: Loss:     0.542572   Batch Accuracy:    0.844 
Iteration:    168: Loss:     0.497353   Batch Accuracy:    0.875 
Iteration:    169: Loss:     0.455275   Batch Accuracy:    0.906 
Iteration:    170: Loss:     0.461122   Batch Accuracy:    0.891 
Iteration:    171: Loss:     0.588328   Batch Accuracy:    0.828 
Iteration:    172: Loss:     0.637441   Batch Accuracy:    0.844 
Iteration:    173: Loss:     0.595052   Batch Accuracy:    0.852 
Iteration:    174: Loss:     0.584508   Batch Accuracy:    0.836 
Iteration:    175: Loss:     0.453014   Batch Accuracy:    0.906 
Iteration:    176: Loss:     0.499164   Batch Accuracy:    0.875 
Iteration:    177: Loss:     0.554013   Batch Accuracy:    0.859 
Iteration:    178: Loss:     0.425104   Batch Accuracy:    0.898 
Iteration:    179: Loss:     0.512024   Batch Accuracy:    0.867 
Iteration:    180: Loss:     0.419407   Batch Accuracy:    0.875 
Iteration:    181: Loss:     0.520151   Batch Accuracy:    0.898 
Iteration:    182: Loss:     0.507504   Batch Accuracy:    0.906 
Iteration:    183: Loss:     0.406010   Batch Accuracy:    0.906 
Iteration:    184: Loss:     0.578882   Batch Accuracy:    0.805 
Iteration:    185: Loss:     0.420160   Batch Accuracy:    0.867 
Iteration:    186: Loss:     0.535590   Batch Accuracy:    0.875 
Iteration:    187: Loss:     0.546675   Batch Accuracy:    0.852 
Iteration:    188: Loss:     0.481977   Batch Accuracy:    0.883 
Iteration:    189: Loss:     0.441713   Batch Accuracy:    0.891 
Iteration:    190: Loss:     0.544515   Batch Accuracy:    0.859 
Iteration:    191: Loss:     0.377247   Batch Accuracy:    0.883 
Iteration:    192: Loss:     0.433610   Batch Accuracy:    0.898 
Iteration:    193: Loss:     0.529263   Batch Accuracy:    0.883 
Iteration:    194: Loss:     0.462038   Batch Accuracy:    0.867 
Iteration:    195: Loss:     0.456403   Batch Accuracy:    0.883 
Iteration:    196: Loss:     0.441631   Batch Accuracy:    0.883 
Iteration:    197: Loss:     0.422717   Batch Accuracy:    0.922 
Iteration:    198: Loss:     0.470748   Batch Accuracy:    0.867 
Iteration:    199: Loss:     0.618792   Batch Accuracy:    0.812 
Iteration:    200: Loss:     0.442768   Batch Accuracy:    0.914 
Iteration:    201: Loss:     0.536858   Batch Accuracy:    0.852 
Iteration:    202: Loss:     0.548781   Batch Accuracy:    0.859 
Iteration:    203: Loss:     0.515046   Batch Accuracy:    0.844 
Iteration:    204: Loss:     0.599522   Batch Accuracy:    0.844 
Iteration:    205: Loss:     0.435575   Batch Accuracy:    0.891 
Iteration:    206: Loss:     0.376387   Batch Accuracy:    0.914 
Iteration:    207: Loss:     0.364812   Batch Accuracy:    0.930 
Iteration:    208: Loss:     0.507405   Batch Accuracy:    0.859 
Iteration:    209: Loss:     0.367927   Batch Accuracy:    0.891 
Iteration:    210: Loss:     0.513912   Batch Accuracy:    0.859 
Iteration:    211: Loss:     0.466493   Batch Accuracy:    0.875 
Iteration:    212: Loss:     0.448635   Batch Accuracy:    0.883 
Iteration:    213: Loss:     0.485384   Batch Accuracy:    0.875 
Iteration:    214: Loss:     0.501184   Batch Accuracy:    0.859 
Iteration:    215: Loss:     0.464958   Batch Accuracy:    0.891 
Iteration:    216: Loss:     0.535641   Batch Accuracy:    0.875 
Iteration:    217: Loss:     0.389930   Batch Accuracy:    0.922 
Iteration:    218: Loss:     0.465661   Batch Accuracy:    0.875 
Iteration:    219: Loss:     0.505671   Batch Accuracy:    0.875 
Iteration:    220: Loss:     0.511498   Batch Accuracy:    0.883 
Iteration:    221: Loss:     0.355503   Batch Accuracy:    0.961 
Iteration:    222: Loss:     0.429105   Batch Accuracy:    0.898 
Iteration:    223: Loss:     0.648741   Batch Accuracy:    0.859 
Iteration:    224: Loss:     0.579164   Batch Accuracy:    0.828 
Iteration:    225: Loss:     0.466482   Batch Accuracy:    0.875 
Iteration:    226: Loss:     0.648917   Batch Accuracy:    0.797 
Iteration:    227: Loss:     0.574844   Batch Accuracy:    0.867 
Iteration:    228: Loss:     0.454141   Batch Accuracy:    0.875 
Iteration:    229: Loss:     0.416591   Batch Accuracy:    0.906 
Iteration:    230: Loss:     0.424970   Batch Accuracy:    0.891 
Iteration:    231: Loss:     0.404584   Batch Accuracy:    0.922 
Iteration:    232: Loss:     0.372842   Batch Accuracy:    0.906 
Iteration:    233: Loss:     0.518569   Batch Accuracy:    0.875 
Iteration:    234: Loss:     0.281161   Batch Accuracy:    0.961 
Iteration:    235: Loss:     0.491916   Batch Accuracy:    0.883 
Iteration:    236: Loss:     0.368737   Batch Accuracy:    0.906 
Iteration:    237: Loss:     0.431375   Batch Accuracy:    0.883 
Iteration:    238: Loss:     0.545423   Batch Accuracy:    0.859 
Iteration:    239: Loss:     0.542440   Batch Accuracy:    0.867 
Iteration:    240: Loss:     0.427345   Batch Accuracy:    0.906 
Iteration:    241: Loss:     0.427842   Batch Accuracy:    0.898 
Iteration:    242: Loss:     0.371293   Batch Accuracy:    0.906 
Iteration:    243: Loss:     0.392303   Batch Accuracy:    0.891 
Iteration:    244: Loss:     0.469950   Batch Accuracy:    0.891 
Iteration:    245: Loss:     0.474238   Batch Accuracy:    0.875 
Iteration:    246: Loss:     0.471805   Batch Accuracy:    0.906 
Iteration:    247: Loss:     0.420157   Batch Accuracy:    0.898 
Iteration:    248: Loss:     0.467152   Batch Accuracy:    0.891 
Iteration:    249: Loss:     0.368297   Batch Accuracy:    0.898 
Iteration:    250: Loss:     0.444158   Batch Accuracy:    0.867 
Iteration:    251: Loss:     0.462444   Batch Accuracy:    0.883 
Iteration:    252: Loss:     0.577724   Batch Accuracy:    0.852 
Iteration:    253: Loss:     0.477602   Batch Accuracy:    0.883 
Iteration:    254: Loss:     0.529226   Batch Accuracy:    0.836 
Iteration:    255: Loss:     0.476641   Batch Accuracy:    0.875 
Iteration:    256: Loss:     0.447708   Batch Accuracy:    0.922 
Iteration:    257: Loss:     0.439873   Batch Accuracy:    0.883 
Iteration:    258: Loss:     0.499774   Batch Accuracy:    0.867 
Iteration:    259: Loss:     0.418692   Batch Accuracy:    0.914 
Iteration:    260: Loss:     0.504439   Batch Accuracy:    0.859 
Iteration:    261: Loss:     0.522274   Batch Accuracy:    0.883 
Iteration:    262: Loss:     0.512696   Batch Accuracy:    0.867 
Iteration:    263: Loss:     0.442473   Batch Accuracy:    0.891 
Iteration:    264: Loss:     0.555867   Batch Accuracy:    0.859 
Iteration:    265: Loss:     0.565542   Batch Accuracy:    0.852 
Iteration:    266: Loss:     0.434612   Batch Accuracy:    0.875 
Iteration:    267: Loss:     0.401264   Batch Accuracy:    0.891 
Iteration:    268: Loss:     0.407107   Batch Accuracy:    0.914 
Iteration:    269: Loss:     0.368468   Batch Accuracy:    0.906 
Iteration:    270: Loss:     0.463016   Batch Accuracy:    0.883 
Iteration:    271: Loss:     0.454066   Batch Accuracy:    0.859 
Iteration:    272: Loss:     0.431391   Batch Accuracy:    0.898 
Iteration:    273: Loss:     0.433900   Batch Accuracy:    0.914 
Iteration:    274: Loss:     0.523524   Batch Accuracy:    0.844 
Iteration:    275: Loss:     0.509503   Batch Accuracy:    0.859 
Iteration:    276: Loss:     0.501362   Batch Accuracy:    0.883 
Iteration:    277: Loss:     0.631232   Batch Accuracy:    0.828 
Iteration:    278: Loss:     0.444968   Batch Accuracy:    0.883 
Iteration:    279: Loss:     0.427986   Batch Accuracy:    0.930 
Iteration:    280: Loss:     0.546301   Batch Accuracy:    0.859 
Iteration:    281: Loss:     0.418403   Batch Accuracy:    0.906 
Iteration:    282: Loss:     0.497979   Batch Accuracy:    0.836 
Iteration:    283: Loss:     0.527462   Batch Accuracy:    0.859 
Iteration:    284: Loss:     0.507076   Batch Accuracy:    0.859 
Iteration:    285: Loss:     0.368265   Batch Accuracy:    0.898 
Iteration:    286: Loss:     0.444366   Batch Accuracy:    0.891 
Iteration:    287: Loss:     0.474471   Batch Accuracy:    0.875 
Iteration:    288: Loss:     0.468952   Batch Accuracy:    0.883 
Iteration:    289: Loss:     0.621141   Batch Accuracy:    0.828 
Iteration:    290: Loss:     0.393593   Batch Accuracy:    0.914 
Iteration:    291: Loss:     0.514137   Batch Accuracy:    0.867 
Iteration:    292: Loss:     0.386429   Batch Accuracy:    0.898 
Iteration:    293: Loss:     0.376326   Batch Accuracy:    0.906 
Iteration:    294: Loss:     0.549033   Batch Accuracy:    0.828 
Iteration:    295: Loss:     0.490666   Batch Accuracy:    0.867 
Iteration:    296: Loss:     0.432731   Batch Accuracy:    0.891 
Iteration:    297: Loss:     0.437082   Batch Accuracy:    0.883 
Iteration:    298: Loss:     0.434241   Batch Accuracy:    0.883 
Iteration:    299: Loss:     0.484833   Batch Accuracy:    0.859 
Iteration:    300: Loss:     0.428255   Batch Accuracy:    0.875 
Iteration:    301: Loss:     0.422688   Batch Accuracy:    0.906 
Iteration:    302: Loss:     0.361354   Batch Accuracy:    0.859 
Iteration:    303: Loss:     0.494511   Batch Accuracy:    0.883 
Iteration:    304: Loss:     0.478630   Batch Accuracy:    0.859 
Iteration:    305: Loss:     0.398940   Batch Accuracy:    0.914 
Iteration:    306: Loss:     0.261292   Batch Accuracy:    0.938 
Iteration:    307: Loss:     0.409957   Batch Accuracy:    0.875 
Iteration:    308: Loss:     0.529424   Batch Accuracy:    0.836 
Iteration:    309: Loss:     0.417469   Batch Accuracy:    0.859 
Iteration:    310: Loss:     0.525010   Batch Accuracy:    0.844 
Iteration:    311: Loss:     0.392678   Batch Accuracy:    0.859 
Iteration:    312: Loss:     0.374691   Batch Accuracy:    0.922 
Iteration:    313: Loss:     0.380268   Batch Accuracy:    0.906 
Iteration:    314: Loss:     0.484288   Batch Accuracy:    0.859 
Iteration:    315: Loss:     0.444255   Batch Accuracy:    0.875 
Iteration:    316: Loss:     0.379808   Batch Accuracy:    0.914 
Iteration:    317: Loss:     0.429718   Batch Accuracy:    0.883 
Iteration:    318: Loss:     0.559161   Batch Accuracy:    0.844 
Iteration:    319: Loss:     0.456838   Batch Accuracy:    0.891 
Iteration:    320: Loss:     0.506246   Batch Accuracy:    0.906 
Iteration:    321: Loss:     0.624437   Batch Accuracy:    0.812 
Iteration:    322: Loss:     0.367374   Batch Accuracy:    0.914 
Iteration:    323: Loss:     0.322857   Batch Accuracy:    0.930 
Iteration:    324: Loss:     0.452610   Batch Accuracy:    0.891 
Iteration:    325: Loss:     0.359155   Batch Accuracy:    0.938 
Iteration:    326: Loss:     0.467001   Batch Accuracy:    0.883 
Iteration:    327: Loss:     0.417854   Batch Accuracy:    0.914 
Iteration:    328: Loss:     0.382474   Batch Accuracy:    0.891 
Iteration:    329: Loss:     0.574933   Batch Accuracy:    0.836 
Iteration:    330: Loss:     0.250477   Batch Accuracy:    0.977 
Iteration:    331: Loss:     0.311368   Batch Accuracy:    0.938 
Iteration:    332: Loss:     0.489835   Batch Accuracy:    0.859 
Iteration:    333: Loss:     0.381057   Batch Accuracy:    0.891 
Iteration:    334: Loss:     0.604630   Batch Accuracy:    0.828 
Iteration:    335: Loss:     0.324734   Batch Accuracy:    0.922 
Iteration:    336: Loss:     0.306905   Batch Accuracy:    0.930 
Iteration:    337: Loss:     0.420106   Batch Accuracy:    0.875 
Iteration:    338: Loss:     0.422659   Batch Accuracy:    0.875 
Iteration:    339: Loss:     0.493360   Batch Accuracy:    0.891 
Iteration:    340: Loss:     0.389631   Batch Accuracy:    0.898 
Iteration:    341: Loss:     0.416336   Batch Accuracy:    0.898 
Iteration:    342: Loss:     0.404890   Batch Accuracy:    0.883 
Iteration:    343: Loss:     0.400645   Batch Accuracy:    0.922 
Iteration:    344: Loss:     0.425441   Batch Accuracy:    0.891 
Iteration:    345: Loss:     0.493806   Batch Accuracy:    0.867 
Iteration:    346: Loss:     0.364000   Batch Accuracy:    0.930 
Iteration:    347: Loss:     0.408929   Batch Accuracy:    0.883 
Iteration:    348: Loss:     0.550505   Batch Accuracy:    0.836 
Iteration:    349: Loss:     0.523485   Batch Accuracy:    0.852 
Iteration:    350: Loss:     0.336766   Batch Accuracy:    0.945 
Iteration:    351: Loss:     0.389589   Batch Accuracy:    0.914 
Iteration:    352: Loss:     0.371387   Batch Accuracy:    0.922 
Iteration:    353: Loss:     0.552347   Batch Accuracy:    0.859 
Iteration:    354: Loss:     0.420086   Batch Accuracy:    0.898 
Iteration:    355: Loss:     0.470715   Batch Accuracy:    0.891 
Iteration:    356: Loss:     0.386730   Batch Accuracy:    0.883 
Iteration:    357: Loss:     0.470594   Batch Accuracy:    0.859 
Iteration:    358: Loss:     0.354329   Batch Accuracy:    0.906 
Iteration:    359: Loss:     0.337543   Batch Accuracy:    0.898 
Iteration:    360: Loss:     0.479242   Batch Accuracy:    0.859 
Iteration:    361: Loss:     0.444089   Batch Accuracy:    0.914 
Iteration:    362: Loss:     0.453748   Batch Accuracy:    0.906 
Iteration:    363: Loss:     0.501534   Batch Accuracy:    0.852 
Iteration:    364: Loss:     0.378886   Batch Accuracy:    0.883 
Iteration:    365: Loss:     0.504257   Batch Accuracy:    0.836 
Iteration:    366: Loss:     0.570586   Batch Accuracy:    0.836 
Iteration:    367: Loss:     0.390758   Batch Accuracy:    0.914 
Iteration:    368: Loss:     0.432406   Batch Accuracy:    0.891 
Iteration:    369: Loss:     0.596586   Batch Accuracy:    0.836 
Iteration:    370: Loss:     0.356182   Batch Accuracy:    0.945 
Iteration:    371: Loss:     0.417208   Batch Accuracy:    0.906 
Iteration:    372: Loss:     0.461770   Batch Accuracy:    0.891 
Iteration:    373: Loss:     0.346094   Batch Accuracy:    0.930 
Iteration:    374: Loss:     0.390608   Batch Accuracy:    0.891 
Iteration:    375: Loss:     0.388453   Batch Accuracy:    0.898 
Iteration:    376: Loss:     0.288627   Batch Accuracy:    0.930 
Iteration:    377: Loss:     0.443506   Batch Accuracy:    0.875 
Iteration:    378: Loss:     0.385408   Batch Accuracy:    0.906 
Iteration:    379: Loss:     0.418361   Batch Accuracy:    0.875 
Iteration:    380: Loss:     0.453506   Batch Accuracy:    0.891 
Iteration:    381: Loss:     0.448533   Batch Accuracy:    0.875 
Iteration:    382: Loss:     0.450114   Batch Accuracy:    0.891 
Iteration:    383: Loss:     0.374253   Batch Accuracy:    0.898 
Iteration:    384: Loss:     0.442948   Batch Accuracy:    0.852 
Iteration:    385: Loss:     0.338929   Batch Accuracy:    0.891 
Iteration:    386: Loss:     0.441165   Batch Accuracy:    0.859 
Iteration:    387: Loss:     0.362196   Batch Accuracy:    0.930 
Iteration:    388: Loss:     0.511401   Batch Accuracy:    0.859 
Iteration:    389: Loss:     0.453249   Batch Accuracy:    0.867 
Iteration:    390: Loss:     0.472833   Batch Accuracy:    0.883 
Iteration:    391: Loss:     0.379854   Batch Accuracy:    0.922 
Iteration:    392: Loss:     0.383607   Batch Accuracy:    0.906 
Iteration:    393: Loss:     0.404985   Batch Accuracy:    0.906 
Iteration:    394: Loss:     0.513293   Batch Accuracy:    0.844 
Iteration:    395: Loss:     0.445056   Batch Accuracy:    0.875 
Iteration:    396: Loss:     0.323555   Batch Accuracy:    0.914 
Iteration:    397: Loss:     0.527300   Batch Accuracy:    0.828 
Iteration:    398: Loss:     0.498609   Batch Accuracy:    0.867 
Iteration:    399: Loss:     0.592816   Batch Accuracy:    0.883 
Iteration:    400: Loss:     0.343450   Batch Accuracy:    0.930 
Iteration:    401: Loss:     0.386673   Batch Accuracy:    0.875 
Iteration:    402: Loss:     0.403462   Batch Accuracy:    0.914 
Iteration:    403: Loss:     0.391295   Batch Accuracy:    0.898 
Iteration:    404: Loss:     0.366281   Batch Accuracy:    0.898 
Iteration:    405: Loss:     0.383287   Batch Accuracy:    0.883 
Iteration:    406: Loss:     0.496410   Batch Accuracy:    0.883 
Iteration:    407: Loss:     0.343155   Batch Accuracy:    0.898 
Iteration:    408: Loss:     0.529590   Batch Accuracy:    0.820 
Iteration:    409: Loss:     0.355243   Batch Accuracy:    0.898 
Iteration:    410: Loss:     0.435519   Batch Accuracy:    0.891 
Iteration:    411: Loss:     0.325379   Batch Accuracy:    0.945 
Iteration:    412: Loss:     0.417715   Batch Accuracy:    0.891 
Iteration:    413: Loss:     0.417629   Batch Accuracy:    0.867 
Iteration:    414: Loss:     0.339720   Batch Accuracy:    0.906 
Iteration:    415: Loss:     0.400634   Batch Accuracy:    0.852 
Iteration:    416: Loss:     0.442645   Batch Accuracy:    0.883 
Iteration:    417: Loss:     0.501739   Batch Accuracy:    0.836 
Iteration:    418: Loss:     0.584194   Batch Accuracy:    0.859 
Iteration:    419: Loss:     0.487259   Batch Accuracy:    0.852 
Iteration:    420: Loss:     0.521628   Batch Accuracy:    0.867 
Iteration:    421: Loss:     0.363840   Batch Accuracy:    0.914 
Iteration:    422: Loss:     0.418943   Batch Accuracy:    0.867 
Iteration:    423: Loss:     0.366681   Batch Accuracy:    0.914 
Iteration:    424: Loss:     0.469792   Batch Accuracy:    0.883 
Iteration:    425: Loss:     0.371807   Batch Accuracy:    0.883 
Iteration:    426: Loss:     0.449421   Batch Accuracy:    0.875 
Iteration:    427: Loss:     0.465096   Batch Accuracy:    0.875 
Iteration:    428: Loss:     0.332516   Batch Accuracy:    0.922 
Iteration:    429: Loss:     0.319779   Batch Accuracy:    0.930 
Iteration:    430: Loss:     0.397537   Batch Accuracy:    0.883 
Iteration:    431: Loss:     0.431903   Batch Accuracy:    0.906 
Iteration:    432: Loss:     0.438330   Batch Accuracy:    0.859 
Iteration:    433: Loss:     0.433387   Batch Accuracy:    0.852 
Iteration:    434: Loss:     0.364806   Batch Accuracy:    0.922 
Iteration:    435: Loss:     0.345529   Batch Accuracy:    0.930 
Iteration:    436: Loss:     0.330215   Batch Accuracy:    0.945 
Iteration:    437: Loss:     0.337646   Batch Accuracy:    0.938 
Iteration:    438: Loss:     0.541040   Batch Accuracy:    0.836 
Iteration:    439: Loss:     0.317721   Batch Accuracy:    0.891 
Iteration:    440: Loss:     0.354601   Batch Accuracy:    0.906 
Iteration:    441: Loss:     0.407952   Batch Accuracy:    0.891 
Iteration:    442: Loss:     0.412960   Batch Accuracy:    0.891 
Iteration:    443: Loss:     0.428552   Batch Accuracy:    0.891 
Iteration:    444: Loss:     0.306417   Batch Accuracy:    0.953 
Iteration:    445: Loss:     0.322944   Batch Accuracy:    0.930 
Iteration:    446: Loss:     0.391676   Batch Accuracy:    0.906 
Iteration:    447: Loss:     0.418712   Batch Accuracy:    0.867 
Iteration:    448: Loss:     0.314459   Batch Accuracy:    0.898 
Iteration:    449: Loss:     0.370413   Batch Accuracy:    0.922 
Iteration:    450: Loss:     0.456601   Batch Accuracy:    0.852 
Iteration:    451: Loss:     0.390302   Batch Accuracy:    0.883 
Iteration:    452: Loss:     0.427939   Batch Accuracy:    0.844 
Iteration:    453: Loss:     0.329154   Batch Accuracy:    0.875 
Iteration:    454: Loss:     0.431875   Batch Accuracy:    0.867 
Iteration:    455: Loss:     0.507278   Batch Accuracy:    0.883 
Iteration:    456: Loss:     0.328438   Batch Accuracy:    0.930 
Iteration:    457: Loss:     0.272952   Batch Accuracy:    0.938 
Iteration:    458: Loss:     0.497761   Batch Accuracy:    0.867 
Iteration:    459: Loss:     0.355386   Batch Accuracy:    0.914 
Iteration:    460: Loss:     0.282151   Batch Accuracy:    0.922 
Iteration:    461: Loss:     0.538264   Batch Accuracy:    0.898 
Iteration:    462: Loss:     0.481548   Batch Accuracy:    0.875 
Iteration:    463: Loss:     0.424776   Batch Accuracy:    0.867 
Iteration:    464: Loss:     0.342989   Batch Accuracy:    0.906 
Iteration:    465: Loss:     0.467152   Batch Accuracy:    0.844 
Iteration:    466: Loss:     0.319740   Batch Accuracy:    0.914 
Iteration:    467: Loss:     0.457925   Batch Accuracy:    0.875 
Iteration:    468: Loss:     0.528016   Batch Accuracy:    0.812 
Iteration:    469: Loss:     0.328056   Batch Accuracy:    0.906 
Iteration:    470: Loss:     0.506689   Batch Accuracy:    0.844 
Iteration:    471: Loss:     0.425715   Batch Accuracy:    0.867 
Iteration:    472: Loss:     0.358345   Batch Accuracy:    0.914 
Iteration:    473: Loss:     0.363238   Batch Accuracy:    0.891 
Iteration:    474: Loss:     0.439708   Batch Accuracy:    0.898 
Iteration:    475: Loss:     0.365994   Batch Accuracy:    0.922 
Iteration:    476: Loss:     0.404501   Batch Accuracy:    0.898 
Iteration:    477: Loss:     0.427614   Batch Accuracy:    0.891 
Iteration:    478: Loss:     0.449986   Batch Accuracy:    0.875 
Iteration:    479: Loss:     0.449666   Batch Accuracy:    0.891 
Iteration:    480: Loss:     0.373573   Batch Accuracy:    0.844 
Iteration:    481: Loss:     0.485593   Batch Accuracy:    0.891 
Iteration:    482: Loss:     0.373417   Batch Accuracy:    0.898 
Iteration:    483: Loss:     0.342592   Batch Accuracy:    0.891 
Iteration:    484: Loss:     0.383825   Batch Accuracy:    0.898 
Iteration:    485: Loss:     0.360983   Batch Accuracy:    0.883 
Iteration:    486: Loss:     0.351889   Batch Accuracy:    0.914 
Iteration:    487: Loss:     0.402777   Batch Accuracy:    0.867 
Iteration:    488: Loss:     0.356768   Batch Accuracy:    0.898 
Iteration:    489: Loss:     0.402799   Batch Accuracy:    0.883 
Iteration:    490: Loss:     0.333276   Batch Accuracy:    0.914 
Iteration:    491: Loss:     0.393941   Batch Accuracy:    0.898 
Iteration:    492: Loss:     0.422897   Batch Accuracy:    0.883 
Iteration:    493: Loss:     0.378815   Batch Accuracy:    0.883 
Iteration:    494: Loss:     0.300898   Batch Accuracy:    0.922 
Iteration:    495: Loss:     0.447626   Batch Accuracy:    0.867 
Iteration:    496: Loss:     0.561502   Batch Accuracy:    0.836 
Iteration:    497: Loss:     0.348290   Batch Accuracy:    0.922 
Iteration:    498: Loss:     0.262665   Batch Accuracy:    0.938 
Iteration:    499: Loss:     0.360753   Batch Accuracy:    0.914 
Iteration:    500: Loss:     0.390631   Batch Accuracy:    0.906 
Iteration:    501: Loss:     0.391616   Batch Accuracy:    0.891 
Iteration:    502: Loss:     0.414089   Batch Accuracy:    0.898 
Iteration:    503: Loss:     0.580460   Batch Accuracy:    0.844 
Iteration:    504: Loss:     0.332088   Batch Accuracy:    0.906 
Iteration:    505: Loss:     0.496952   Batch Accuracy:    0.883 
Iteration:    506: Loss:     0.456194   Batch Accuracy:    0.836 
Iteration:    507: Loss:     0.336740   Batch Accuracy:    0.914 
Iteration:    508: Loss:     0.264760   Batch Accuracy:    0.914 
Iteration:    509: Loss:     0.437060   Batch Accuracy:    0.891 
Iteration:    510: Loss:     0.473900   Batch Accuracy:    0.844 
Iteration:    511: Loss:     0.531245   Batch Accuracy:    0.812 
Iteration:    512: Loss:     0.299844   Batch Accuracy:    0.914 
Iteration:    513: Loss:     0.377202   Batch Accuracy:    0.891 
Iteration:    514: Loss:     0.316664   Batch Accuracy:    0.914 
Iteration:    515: Loss:     0.350527   Batch Accuracy:    0.898 
Iteration:    516: Loss:     0.355218   Batch Accuracy:    0.898 
Iteration:    517: Loss:     0.293412   Batch Accuracy:    0.930 
Iteration:    518: Loss:     0.388101   Batch Accuracy:    0.906 
Iteration:    519: Loss:     0.341142   Batch Accuracy:    0.906 
Iteration:    520: Loss:     0.307858   Batch Accuracy:    0.922 
Iteration:    521: Loss:     0.471863   Batch Accuracy:    0.852 
Iteration:    522: Loss:     0.445472   Batch Accuracy:    0.883 
Iteration:    523: Loss:     0.337767   Batch Accuracy:    0.906 
Iteration:    524: Loss:     0.597499   Batch Accuracy:    0.859 
Iteration:    525: Loss:     0.381465   Batch Accuracy:    0.906 
Iteration:    526: Loss:     0.329315   Batch Accuracy:    0.922 
Iteration:    527: Loss:     0.415533   Batch Accuracy:    0.867 
Iteration:    528: Loss:     0.352520   Batch Accuracy:    0.898 
Iteration:    529: Loss:     0.324087   Batch Accuracy:    0.914 
Iteration:    530: Loss:     0.385485   Batch Accuracy:    0.891 
Iteration:    531: Loss:     0.426385   Batch Accuracy:    0.898 
Iteration:    532: Loss:     0.368926   Batch Accuracy:    0.891 
Iteration:    533: Loss:     0.367735   Batch Accuracy:    0.891 
Iteration:    534: Loss:     0.462204   Batch Accuracy:    0.891 
Iteration:    535: Loss:     0.321396   Batch Accuracy:    0.914 
Iteration:    536: Loss:     0.397098   Batch Accuracy:    0.883 
Iteration:    537: Loss:     0.362429   Batch Accuracy:    0.930 
Iteration:    538: Loss:     0.543901   Batch Accuracy:    0.844 
Iteration:    539: Loss:     0.455475   Batch Accuracy:    0.859 
Iteration:    540: Loss:     0.459274   Batch Accuracy:    0.867 
Iteration:    541: Loss:     0.319098   Batch Accuracy:    0.914 
Iteration:    542: Loss:     0.582328   Batch Accuracy:    0.852 
Iteration:    543: Loss:     0.402890   Batch Accuracy:    0.891 
Iteration:    544: Loss:     0.294443   Batch Accuracy:    0.930 
Iteration:    545: Loss:     0.318242   Batch Accuracy:    0.906 
Iteration:    546: Loss:     0.440746   Batch Accuracy:    0.875 
Iteration:    547: Loss:     0.369792   Batch Accuracy:    0.914 
Iteration:    548: Loss:     0.432765   Batch Accuracy:    0.883 
Iteration:    549: Loss:     0.397095   Batch Accuracy:    0.914 
Iteration:    550: Loss:     0.315981   Batch Accuracy:    0.930 
Iteration:    551: Loss:     0.461758   Batch Accuracy:    0.875 
Iteration:    552: Loss:     0.257353   Batch Accuracy:    0.945 
Iteration:    553: Loss:     0.371088   Batch Accuracy:    0.906 
Iteration:    554: Loss:     0.557176   Batch Accuracy:    0.844 
Iteration:    555: Loss:     0.389740   Batch Accuracy:    0.875 
Iteration:    556: Loss:     0.470853   Batch Accuracy:    0.875 
Iteration:    557: Loss:     0.330360   Batch Accuracy:    0.922 
Iteration:    558: Loss:     0.582198   Batch Accuracy:    0.867 
Iteration:    559: Loss:     0.335293   Batch Accuracy:    0.906 
Iteration:    560: Loss:     0.296896   Batch Accuracy:    0.930 
Iteration:    561: Loss:     0.338169   Batch Accuracy:    0.898 
Iteration:    562: Loss:     0.479064   Batch Accuracy:    0.859 
Iteration:    563: Loss:     0.504331   Batch Accuracy:    0.859 
Iteration:    564: Loss:     0.419814   Batch Accuracy:    0.891 
Iteration:    565: Loss:     0.293500   Batch Accuracy:    0.930 
Iteration:    566: Loss:     0.470310   Batch Accuracy:    0.906 
Iteration:    567: Loss:     0.334136   Batch Accuracy:    0.891 
Iteration:    568: Loss:     0.399672   Batch Accuracy:    0.891 
Iteration:    569: Loss:     0.502209   Batch Accuracy:    0.875 
Iteration:    570: Loss:     0.372919   Batch Accuracy:    0.922 
Iteration:    571: Loss:     0.362000   Batch Accuracy:    0.906 
Iteration:    572: Loss:     0.337997   Batch Accuracy:    0.898 
Iteration:    573: Loss:     0.284037   Batch Accuracy:    0.922 
Iteration:    574: Loss:     0.497732   Batch Accuracy:    0.875 
Iteration:    575: Loss:     0.340270   Batch Accuracy:    0.875 
Iteration:    576: Loss:     0.454364   Batch Accuracy:    0.875 
Iteration:    577: Loss:     0.413920   Batch Accuracy:    0.859 
Iteration:    578: Loss:     0.464234   Batch Accuracy:    0.859 
Iteration:    579: Loss:     0.285036   Batch Accuracy:    0.945 
Iteration:    580: Loss:     0.402503   Batch Accuracy:    0.867 
Iteration:    581: Loss:     0.320946   Batch Accuracy:    0.938 
Iteration:    582: Loss:     0.355737   Batch Accuracy:    0.891 
Iteration:    583: Loss:     0.310344   Batch Accuracy:    0.906 
Iteration:    584: Loss:     0.439525   Batch Accuracy:    0.891 
Iteration:    585: Loss:     0.304983   Batch Accuracy:    0.891 
Iteration:    586: Loss:     0.292302   Batch Accuracy:    0.930 
Iteration:    587: Loss:     0.347864   Batch Accuracy:    0.906 
Iteration:    588: Loss:     0.325390   Batch Accuracy:    0.898 
Iteration:    589: Loss:     0.293465   Batch Accuracy:    0.938 
Iteration:    590: Loss:     0.531691   Batch Accuracy:    0.852 
Iteration:    591: Loss:     0.276765   Batch Accuracy:    0.922 
Iteration:    592: Loss:     0.327714   Batch Accuracy:    0.906 
Iteration:    593: Loss:     0.321674   Batch Accuracy:    0.930 
Iteration:    594: Loss:     0.518504   Batch Accuracy:    0.859 
Iteration:    595: Loss:     0.366143   Batch Accuracy:    0.906 
Iteration:    596: Loss:     0.341672   Batch Accuracy:    0.906 
Iteration:    597: Loss:     0.575659   Batch Accuracy:    0.867 
Iteration:    598: Loss:     0.388107   Batch Accuracy:    0.891 
Iteration:    599: Loss:     0.445308   Batch Accuracy:    0.875 
Iteration:    600: Loss:     0.312110   Batch Accuracy:    0.906 
Iteration:    601: Loss:     0.328329   Batch Accuracy:    0.906 
Iteration:    602: Loss:     0.450848   Batch Accuracy:    0.875 
Iteration:    603: Loss:     0.426800   Batch Accuracy:    0.891 
Iteration:    604: Loss:     0.335683   Batch Accuracy:    0.930 
Iteration:    605: Loss:     0.355627   Batch Accuracy:    0.891 
Iteration:    606: Loss:     0.413394   Batch Accuracy:    0.898 
Iteration:    607: Loss:     0.352425   Batch Accuracy:    0.883 
Iteration:    608: Loss:     0.451824   Batch Accuracy:    0.875 
Iteration:    609: Loss:     0.415575   Batch Accuracy:    0.883 
Iteration:    610: Loss:     0.339212   Batch Accuracy:    0.930 
Iteration:    611: Loss:     0.417845   Batch Accuracy:    0.891 
Iteration:    612: Loss:     0.436977   Batch Accuracy:    0.867 
Iteration:    613: Loss:     0.445532   Batch Accuracy:    0.930 
Iteration:    614: Loss:     0.280000   Batch Accuracy:    0.906 
Iteration:    615: Loss:     0.371532   Batch Accuracy:    0.914 
Iteration:    616: Loss:     0.373811   Batch Accuracy:    0.906 
Iteration:    617: Loss:     0.498582   Batch Accuracy:    0.852 
Iteration:    618: Loss:     0.316563   Batch Accuracy:    0.938 
Iteration:    619: Loss:     0.383869   Batch Accuracy:    0.898 
Iteration:    620: Loss:     0.404344   Batch Accuracy:    0.898 
Iteration:    621: Loss:     0.233048   Batch Accuracy:    0.953 
Iteration:    622: Loss:     0.441314   Batch Accuracy:    0.875 
Iteration:    623: Loss:     0.345424   Batch Accuracy:    0.914 
Iteration:    624: Loss:     0.587654   Batch Accuracy:    0.859 
Iteration:    625: Loss:     0.371259   Batch Accuracy:    0.891 
Iteration:    626: Loss:     0.499665   Batch Accuracy:    0.859 
Iteration:    627: Loss:     0.350758   Batch Accuracy:    0.891 
Iteration:    628: Loss:     0.362072   Batch Accuracy:    0.867 
Iteration:    629: Loss:     0.258532   Batch Accuracy:    0.922 
Iteration:    630: Loss:     0.338951   Batch Accuracy:    0.914 
Iteration:    631: Loss:     0.299611   Batch Accuracy:    0.906 
Iteration:    632: Loss:     0.480208   Batch Accuracy:    0.922 
Iteration:    633: Loss:     0.329571   Batch Accuracy:    0.906 
Iteration:    634: Loss:     0.386569   Batch Accuracy:    0.898 
Iteration:    635: Loss:     0.369526   Batch Accuracy:    0.883 
Iteration:    636: Loss:     0.328250   Batch Accuracy:    0.922 
Iteration:    637: Loss:     0.312807   Batch Accuracy:    0.930 
Iteration:    638: Loss:     0.315456   Batch Accuracy:    0.922 
Iteration:    639: Loss:     0.269111   Batch Accuracy:    0.930 
Iteration:    640: Loss:     0.379702   Batch Accuracy:    0.891 
Iteration:    641: Loss:     0.335326   Batch Accuracy:    0.914 
Iteration:    642: Loss:     0.333835   Batch Accuracy:    0.914 
Iteration:    643: Loss:     0.416706   Batch Accuracy:    0.898 
Iteration:    644: Loss:     0.308289   Batch Accuracy:    0.883 
Iteration:    645: Loss:     0.416799   Batch Accuracy:    0.914 
Iteration:    646: Loss:     0.330721   Batch Accuracy:    0.898 
Iteration:    647: Loss:     0.391069   Batch Accuracy:    0.914 
Iteration:    648: Loss:     0.320818   Batch Accuracy:    0.914 
Iteration:    649: Loss:     0.410078   Batch Accuracy:    0.906 
Iteration:    650: Loss:     0.392455   Batch Accuracy:    0.875 
Iteration:    651: Loss:     0.429666   Batch Accuracy:    0.883 
Iteration:    652: Loss:     0.383013   Batch Accuracy:    0.891 
Iteration:    653: Loss:     0.478912   Batch Accuracy:    0.867 
Iteration:    654: Loss:     0.356385   Batch Accuracy:    0.906 
Iteration:    655: Loss:     0.337419   Batch Accuracy:    0.898 
Iteration:    656: Loss:     0.420440   Batch Accuracy:    0.906 
Iteration:    657: Loss:     0.428118   Batch Accuracy:    0.875 
Iteration:    658: Loss:     0.304524   Batch Accuracy:    0.906 
Iteration:    659: Loss:     0.371699   Batch Accuracy:    0.852 
Iteration:    660: Loss:     0.297880   Batch Accuracy:    0.930 
Iteration:    661: Loss:     0.352082   Batch Accuracy:    0.883 
Iteration:    662: Loss:     0.338227   Batch Accuracy:    0.938 
Iteration:    663: Loss:     0.302954   Batch Accuracy:    0.922 
Iteration:    664: Loss:     0.403358   Batch Accuracy:    0.906 
Iteration:    665: Loss:     0.422952   Batch Accuracy:    0.898 
Iteration:    666: Loss:     0.440092   Batch Accuracy:    0.859 
Iteration:    667: Loss:     0.347507   Batch Accuracy:    0.891 
Iteration:    668: Loss:     0.383716   Batch Accuracy:    0.859 
Iteration:    669: Loss:     0.366992   Batch Accuracy:    0.914 
Iteration:    670: Loss:     0.488309   Batch Accuracy:    0.844 
Iteration:    671: Loss:     0.277605   Batch Accuracy:    0.938 
Iteration:    672: Loss:     0.526160   Batch Accuracy:    0.859 
Iteration:    673: Loss:     0.318592   Batch Accuracy:    0.922 
Iteration:    674: Loss:     0.384729   Batch Accuracy:    0.875 
Iteration:    675: Loss:     0.264135   Batch Accuracy:    0.945 
Iteration:    676: Loss:     0.313470   Batch Accuracy:    0.930 
Iteration:    677: Loss:     0.333246   Batch Accuracy:    0.898 
Iteration:    678: Loss:     0.294485   Batch Accuracy:    0.891 
Iteration:    679: Loss:     0.263490   Batch Accuracy:    0.938 
Iteration:    680: Loss:     0.361682   Batch Accuracy:    0.883 
Iteration:    681: Loss:     0.305051   Batch Accuracy:    0.922 
Iteration:    682: Loss:     0.458942   Batch Accuracy:    0.906 
Iteration:    683: Loss:     0.346164   Batch Accuracy:    0.914 
Iteration:    684: Loss:     0.379042   Batch Accuracy:    0.906 
Iteration:    685: Loss:     0.348750   Batch Accuracy:    0.898 
Iteration:    686: Loss:     0.498244   Batch Accuracy:    0.859 
Iteration:    687: Loss:     0.395027   Batch Accuracy:    0.883 
Iteration:    688: Loss:     0.466862   Batch Accuracy:    0.844 
Iteration:    689: Loss:     0.419472   Batch Accuracy:    0.883 
Iteration:    690: Loss:     0.407113   Batch Accuracy:    0.867 
Iteration:    691: Loss:     0.483979   Batch Accuracy:    0.883 
Iteration:    692: Loss:     0.309820   Batch Accuracy:    0.938 
Iteration:    693: Loss:     0.491413   Batch Accuracy:    0.859 
Iteration:    694: Loss:     0.422625   Batch Accuracy:    0.914 
Iteration:    695: Loss:     0.447709   Batch Accuracy:    0.844 
Iteration:    696: Loss:     0.362695   Batch Accuracy:    0.906 
Iteration:    697: Loss:     0.336617   Batch Accuracy:    0.891 
Iteration:    698: Loss:     0.424452   Batch Accuracy:    0.883 
Iteration:    699: Loss:     0.425017   Batch Accuracy:    0.852 
Iteration:    700: Loss:     0.377697   Batch Accuracy:    0.906 
Iteration:    701: Loss:     0.275755   Batch Accuracy:    0.945 
Iteration:    702: Loss:     0.476837   Batch Accuracy:    0.875 
Iteration:    703: Loss:     0.356751   Batch Accuracy:    0.930 
Iteration:    704: Loss:     0.360967   Batch Accuracy:    0.906 
Iteration:    705: Loss:     0.385162   Batch Accuracy:    0.875 
Iteration:    706: Loss:     0.581332   Batch Accuracy:    0.844 
Iteration:    707: Loss:     0.265275   Batch Accuracy:    0.930 
Iteration:    708: Loss:     0.454681   Batch Accuracy:    0.875 
Iteration:    709: Loss:     0.350711   Batch Accuracy:    0.898 
Iteration:    710: Loss:     0.371138   Batch Accuracy:    0.898 
Iteration:    711: Loss:     0.361809   Batch Accuracy:    0.898 
Iteration:    712: Loss:     0.451085   Batch Accuracy:    0.844 
Iteration:    713: Loss:     0.400430   Batch Accuracy:    0.891 
Iteration:    714: Loss:     0.327217   Batch Accuracy:    0.883 
Iteration:    715: Loss:     0.286774   Batch Accuracy:    0.930 
Iteration:    716: Loss:     0.463224   Batch Accuracy:    0.844 
Iteration:    717: Loss:     0.306618   Batch Accuracy:    0.930 
Iteration:    718: Loss:     0.349831   Batch Accuracy:    0.891 
Iteration:    719: Loss:     0.322356   Batch Accuracy:    0.922 
Iteration:    720: Loss:     0.397861   Batch Accuracy:    0.898 
Iteration:    721: Loss:     0.340549   Batch Accuracy:    0.922 
Iteration:    722: Loss:     0.357233   Batch Accuracy:    0.906 
Iteration:    723: Loss:     0.309965   Batch Accuracy:    0.922 
Iteration:    724: Loss:     0.403308   Batch Accuracy:    0.898 
Iteration:    725: Loss:     0.362539   Batch Accuracy:    0.906 
Iteration:    726: Loss:     0.367617   Batch Accuracy:    0.914 
Iteration:    727: Loss:     0.288226   Batch Accuracy:    0.945 
Iteration:    728: Loss:     0.340942   Batch Accuracy:    0.914 
Iteration:    729: Loss:     0.444805   Batch Accuracy:    0.836 
Iteration:    730: Loss:     0.494097   Batch Accuracy:    0.859 
Iteration:    731: Loss:     0.219038   Batch Accuracy:    0.930 
Iteration:    732: Loss:     0.272031   Batch Accuracy:    0.945 
Iteration:    733: Loss:     0.501997   Batch Accuracy:    0.891 
Iteration:    734: Loss:     0.360497   Batch Accuracy:    0.883 
Iteration:    735: Loss:     0.390328   Batch Accuracy:    0.906 
Iteration:    736: Loss:     0.341534   Batch Accuracy:    0.945 
Iteration:    737: Loss:     0.238690   Batch Accuracy:    0.945 
Iteration:    738: Loss:     0.335538   Batch Accuracy:    0.914 
Iteration:    739: Loss:     0.387672   Batch Accuracy:    0.852 
Iteration:    740: Loss:     0.312414   Batch Accuracy:    0.891 
Iteration:    741: Loss:     0.422670   Batch Accuracy:    0.867 
Iteration:    742: Loss:     0.283531   Batch Accuracy:    0.930 
Iteration:    743: Loss:     0.232910   Batch Accuracy:    0.938 
Iteration:    744: Loss:     0.268432   Batch Accuracy:    0.922 
Iteration:    745: Loss:     0.388027   Batch Accuracy:    0.891 
Iteration:    746: Loss:     0.278178   Batch Accuracy:    0.930 
Iteration:    747: Loss:     0.328621   Batch Accuracy:    0.914 
Iteration:    748: Loss:     0.251766   Batch Accuracy:    0.930 
Iteration:    749: Loss:     0.307786   Batch Accuracy:    0.945 
Iteration:    750: Loss:     0.376179   Batch Accuracy:    0.883 
Iteration:    751: Loss:     0.279908   Batch Accuracy:    0.945 
Iteration:    752: Loss:     0.306181   Batch Accuracy:    0.922 
Iteration:    753: Loss:     0.393577   Batch Accuracy:    0.898 
Iteration:    754: Loss:     0.377751   Batch Accuracy:    0.859 
Iteration:    755: Loss:     0.360834   Batch Accuracy:    0.906 
Iteration:    756: Loss:     0.422935   Batch Accuracy:    0.898 
Iteration:    757: Loss:     0.314400   Batch Accuracy:    0.930 
Iteration:    758: Loss:     0.303213   Batch Accuracy:    0.914 
Iteration:    759: Loss:     0.469613   Batch Accuracy:    0.867 
Iteration:    760: Loss:     0.304108   Batch Accuracy:    0.930 
Iteration:    761: Loss:     0.319075   Batch Accuracy:    0.914 
Iteration:    762: Loss:     0.326864   Batch Accuracy:    0.891 
Iteration:    763: Loss:     0.373571   Batch Accuracy:    0.883 
Iteration:    764: Loss:     0.494507   Batch Accuracy:    0.828 
Iteration:    765: Loss:     0.433171   Batch Accuracy:    0.859 
Iteration:    766: Loss:     0.385793   Batch Accuracy:    0.914 
Iteration:    767: Loss:     0.252671   Batch Accuracy:    0.914 
Iteration:    768: Loss:     0.429849   Batch Accuracy:    0.891 
Iteration:    769: Loss:     0.395804   Batch Accuracy:    0.914 
Iteration:    770: Loss:     0.429237   Batch Accuracy:    0.867 
Iteration:    771: Loss:     0.290368   Batch Accuracy:    0.898 
Iteration:    772: Loss:     0.426820   Batch Accuracy:    0.875 
Iteration:    773: Loss:     0.454687   Batch Accuracy:    0.844 
Iteration:    774: Loss:     0.452279   Batch Accuracy:    0.891 
Iteration:    775: Loss:     0.359936   Batch Accuracy:    0.875 
Iteration:    776: Loss:     0.529445   Batch Accuracy:    0.891 
Iteration:    777: Loss:     0.304740   Batch Accuracy:    0.914 
Iteration:    778: Loss:     0.300732   Batch Accuracy:    0.938 
Iteration:    779: Loss:     0.332251   Batch Accuracy:    0.922 
Iteration:    780: Loss:     0.434604   Batch Accuracy:    0.859 
Iteration:    781: Loss:     0.350312   Batch Accuracy:    0.914 
Iteration:    782: Loss:     0.403649   Batch Accuracy:    0.891 
Iteration:    783: Loss:     0.365434   Batch Accuracy:    0.906 
Iteration:    784: Loss:     0.241223   Batch Accuracy:    0.953 
Iteration:    785: Loss:     0.321185   Batch Accuracy:    0.922 
Iteration:    786: Loss:     0.349262   Batch Accuracy:    0.930 
Iteration:    787: Loss:     0.362914   Batch Accuracy:    0.922 
Iteration:    788: Loss:     0.343015   Batch Accuracy:    0.898 
Iteration:    789: Loss:     0.336425   Batch Accuracy:    0.922 
Iteration:    790: Loss:     0.417011   Batch Accuracy:    0.875 
Iteration:    791: Loss:     0.352929   Batch Accuracy:    0.898 
Iteration:    792: Loss:     0.407191   Batch Accuracy:    0.891 
Iteration:    793: Loss:     0.415239   Batch Accuracy:    0.875 
Iteration:    794: Loss:     0.429187   Batch Accuracy:    0.906 
Iteration:    795: Loss:     0.205432   Batch Accuracy:    0.945 
Iteration:    796: Loss:     0.319903   Batch Accuracy:    0.922 
Iteration:    797: Loss:     0.411169   Batch Accuracy:    0.914 
Iteration:    798: Loss:     0.431748   Batch Accuracy:    0.875 
Iteration:    799: Loss:     0.368540   Batch Accuracy:    0.867 
Iteration:    800: Loss:     0.290893   Batch Accuracy:    0.922 
Iteration:    801: Loss:     0.370394   Batch Accuracy:    0.875 
Iteration:    802: Loss:     0.374519   Batch Accuracy:    0.898 
Iteration:    803: Loss:     0.334019   Batch Accuracy:    0.883 
Iteration:    804: Loss:     0.328348   Batch Accuracy:    0.898 
Iteration:    805: Loss:     0.410538   Batch Accuracy:    0.859 
Iteration:    806: Loss:     0.377476   Batch Accuracy:    0.891 
Iteration:    807: Loss:     0.562880   Batch Accuracy:    0.836 
Iteration:    808: Loss:     0.277795   Batch Accuracy:    0.938 
Iteration:    809: Loss:     0.326848   Batch Accuracy:    0.914 
Iteration:    810: Loss:     0.301949   Batch Accuracy:    0.938 
Iteration:    811: Loss:     0.337080   Batch Accuracy:    0.898 
Iteration:    812: Loss:     0.394033   Batch Accuracy:    0.867 
Iteration:    813: Loss:     0.292227   Batch Accuracy:    0.930 
Iteration:    814: Loss:     0.419697   Batch Accuracy:    0.891 
Iteration:    815: Loss:     0.454315   Batch Accuracy:    0.875 
Iteration:    816: Loss:     0.413876   Batch Accuracy:    0.898 
Iteration:    817: Loss:     0.398775   Batch Accuracy:    0.875 
Iteration:    818: Loss:     0.370078   Batch Accuracy:    0.883 
Iteration:    819: Loss:     0.309788   Batch Accuracy:    0.906 
Iteration:    820: Loss:     0.333256   Batch Accuracy:    0.906 
Iteration:    821: Loss:     0.370549   Batch Accuracy:    0.906 
Iteration:    822: Loss:     0.319457   Batch Accuracy:    0.922 
Iteration:    823: Loss:     0.313699   Batch Accuracy:    0.898 
Iteration:    824: Loss:     0.465247   Batch Accuracy:    0.867 
Iteration:    825: Loss:     0.425739   Batch Accuracy:    0.898 
Iteration:    826: Loss:     0.367663   Batch Accuracy:    0.906 
Iteration:    827: Loss:     0.345544   Batch Accuracy:    0.914 
Iteration:    828: Loss:     0.492827   Batch Accuracy:    0.891 
Iteration:    829: Loss:     0.427203   Batch Accuracy:    0.867 
Iteration:    830: Loss:     0.406676   Batch Accuracy:    0.898 
Iteration:    831: Loss:     0.361861   Batch Accuracy:    0.898 
Iteration:    832: Loss:     0.407250   Batch Accuracy:    0.914 
Iteration:    833: Loss:     0.398459   Batch Accuracy:    0.867 
Iteration:    834: Loss:     0.385429   Batch Accuracy:    0.898 
Iteration:    835: Loss:     0.373481   Batch Accuracy:    0.914 
Iteration:    836: Loss:     0.418859   Batch Accuracy:    0.844 
Iteration:    837: Loss:     0.293223   Batch Accuracy:    0.922 
Iteration:    838: Loss:     0.404125   Batch Accuracy:    0.891 
Iteration:    839: Loss:     0.332049   Batch Accuracy:    0.898 
Iteration:    840: Loss:     0.322215   Batch Accuracy:    0.906 
Iteration:    841: Loss:     0.365631   Batch Accuracy:    0.883 
Iteration:    842: Loss:     0.433686   Batch Accuracy:    0.875 
Iteration:    843: Loss:     0.412582   Batch Accuracy:    0.875 
Iteration:    844: Loss:     0.405115   Batch Accuracy:    0.883 
Iteration:    845: Loss:     0.281641   Batch Accuracy:    0.922 
Iteration:    846: Loss:     0.301170   Batch Accuracy:    0.914 
Iteration:    847: Loss:     0.307440   Batch Accuracy:    0.922 
Iteration:    848: Loss:     0.409262   Batch Accuracy:    0.914 
Iteration:    849: Loss:     0.344289   Batch Accuracy:    0.898 
Iteration:    850: Loss:     0.374685   Batch Accuracy:    0.898 
Iteration:    851: Loss:     0.250297   Batch Accuracy:    0.938 
Iteration:    852: Loss:     0.302433   Batch Accuracy:    0.906 
Iteration:    853: Loss:     0.363844   Batch Accuracy:    0.883 
Iteration:    854: Loss:     0.388880   Batch Accuracy:    0.898 
Iteration:    855: Loss:     0.469848   Batch Accuracy:    0.883 
Iteration:    856: Loss:     0.428826   Batch Accuracy:    0.875 
Iteration:    857: Loss:     0.392508   Batch Accuracy:    0.883 
Iteration:    858: Loss:     0.379322   Batch Accuracy:    0.875 
Iteration:    859: Loss:     0.431310   Batch Accuracy:    0.891 
Iteration:    860: Loss:     0.385293   Batch Accuracy:    0.891 
Iteration:    861: Loss:     0.260652   Batch Accuracy:    0.922 
Iteration:    862: Loss:     0.377405   Batch Accuracy:    0.914 
Iteration:    863: Loss:     0.392624   Batch Accuracy:    0.898 
Iteration:    864: Loss:     0.333920   Batch Accuracy:    0.922 
Iteration:    865: Loss:     0.325460   Batch Accuracy:    0.930 
Iteration:    866: Loss:     0.339001   Batch Accuracy:    0.906 
Iteration:    867: Loss:     0.325698   Batch Accuracy:    0.875 
Iteration:    868: Loss:     0.353953   Batch Accuracy:    0.930 
Iteration:    869: Loss:     0.407865   Batch Accuracy:    0.852 
Iteration:    870: Loss:     0.259689   Batch Accuracy:    0.938 
Iteration:    871: Loss:     0.324945   Batch Accuracy:    0.906 
Iteration:    872: Loss:     0.380992   Batch Accuracy:    0.891 
Iteration:    873: Loss:     0.337022   Batch Accuracy:    0.906 
Iteration:    874: Loss:     0.339206   Batch Accuracy:    0.883 
Iteration:    875: Loss:     0.242284   Batch Accuracy:    0.922 
Iteration:    876: Loss:     0.263724   Batch Accuracy:    0.891 
Iteration:    877: Loss:     0.484128   Batch Accuracy:    0.867 
Iteration:    878: Loss:     0.265200   Batch Accuracy:    0.930 
Iteration:    879: Loss:     0.451455   Batch Accuracy:    0.867 
Iteration:    880: Loss:     0.422722   Batch Accuracy:    0.883 
Iteration:    881: Loss:     0.491040   Batch Accuracy:    0.852 
Iteration:    882: Loss:     0.312216   Batch Accuracy:    0.922 
Iteration:    883: Loss:     0.376956   Batch Accuracy:    0.898 
Iteration:    884: Loss:     0.381487   Batch Accuracy:    0.891 
Iteration:    885: Loss:     0.330552   Batch Accuracy:    0.938 
Iteration:    886: Loss:     0.383750   Batch Accuracy:    0.906 
Iteration:    887: Loss:     0.246547   Batch Accuracy:    0.930 
Iteration:    888: Loss:     0.369880   Batch Accuracy:    0.906 
Iteration:    889: Loss:     0.302812   Batch Accuracy:    0.930 
Iteration:    890: Loss:     0.319167   Batch Accuracy:    0.906 
Iteration:    891: Loss:     0.278530   Batch Accuracy:    0.945 
Iteration:    892: Loss:     0.375567   Batch Accuracy:    0.898 
Iteration:    893: Loss:     0.330187   Batch Accuracy:    0.914 
Iteration:    894: Loss:     0.387545   Batch Accuracy:    0.883 
Iteration:    895: Loss:     0.298321   Batch Accuracy:    0.906 
Iteration:    896: Loss:     0.395480   Batch Accuracy:    0.883 
Iteration:    897: Loss:     0.283886   Batch Accuracy:    0.922 
Iteration:    898: Loss:     0.427138   Batch Accuracy:    0.898 
Iteration:    899: Loss:     0.329607   Batch Accuracy:    0.930 
Iteration:    900: Loss:     0.347261   Batch Accuracy:    0.875 
Iteration:    901: Loss:     0.282901   Batch Accuracy:    0.938 
Iteration:    902: Loss:     0.338555   Batch Accuracy:    0.898 
Iteration:    903: Loss:     0.368080   Batch Accuracy:    0.859 
Iteration:    904: Loss:     0.322456   Batch Accuracy:    0.922 
Iteration:    905: Loss:     0.275027   Batch Accuracy:    0.930 
Iteration:    906: Loss:     0.288421   Batch Accuracy:    0.906 
Iteration:    907: Loss:     0.359738   Batch Accuracy:    0.898 
Iteration:    908: Loss:     0.300485   Batch Accuracy:    0.922 
Iteration:    909: Loss:     0.268303   Batch Accuracy:    0.945 
Iteration:    910: Loss:     0.214718   Batch Accuracy:    0.961 
Iteration:    911: Loss:     0.228236   Batch Accuracy:    0.961 
Iteration:    912: Loss:     0.379049   Batch Accuracy:    0.898 
Iteration:    913: Loss:     0.471458   Batch Accuracy:    0.844 
Iteration:    914: Loss:     0.432014   Batch Accuracy:    0.859 
Iteration:    915: Loss:     0.460453   Batch Accuracy:    0.867 
Iteration:    916: Loss:     0.366449   Batch Accuracy:    0.867 
Iteration:    917: Loss:     0.326911   Batch Accuracy:    0.906 
Iteration:    918: Loss:     0.311876   Batch Accuracy:    0.922 
Iteration:    919: Loss:     0.238375   Batch Accuracy:    0.938 
Iteration:    920: Loss:     0.414822   Batch Accuracy:    0.844 
Iteration:    921: Loss:     0.276267   Batch Accuracy:    0.922 
Iteration:    922: Loss:     0.277650   Batch Accuracy:    0.898 
Iteration:    923: Loss:     0.382052   Batch Accuracy:    0.883 
Iteration:    924: Loss:     0.420448   Batch Accuracy:    0.875 
Iteration:    925: Loss:     0.342428   Batch Accuracy:    0.898 
Iteration:    926: Loss:     0.370776   Batch Accuracy:    0.898 
Iteration:    927: Loss:     0.423051   Batch Accuracy:    0.875 
Iteration:    928: Loss:     0.508753   Batch Accuracy:    0.812 
Iteration:    929: Loss:     0.398675   Batch Accuracy:    0.891 
Iteration:    930: Loss:     0.344417   Batch Accuracy:    0.898 
Iteration:    931: Loss:     0.444863   Batch Accuracy:    0.852 
Iteration:    932: Loss:     0.355592   Batch Accuracy:    0.930 
Iteration:    933: Loss:     0.277985   Batch Accuracy:    0.938 
Iteration:    934: Loss:     0.411699   Batch Accuracy:    0.859 
Iteration:    935: Loss:     0.221485   Batch Accuracy:    0.961 
Iteration:    936: Loss:     0.413918   Batch Accuracy:    0.906 
Iteration:    937: Loss:     0.381108   Batch Accuracy:    0.859 
Iteration:    938: Loss:     0.501662   Batch Accuracy:    0.875 
Iteration:    939: Loss:     0.390364   Batch Accuracy:    0.891 
Iteration:    940: Loss:     0.398470   Batch Accuracy:    0.883 
Iteration:    941: Loss:     0.271938   Batch Accuracy:    0.914 
Iteration:    942: Loss:     0.358311   Batch Accuracy:    0.914 
Iteration:    943: Loss:     0.347592   Batch Accuracy:    0.891 
Iteration:    944: Loss:     0.320289   Batch Accuracy:    0.898 
Iteration:    945: Loss:     0.401647   Batch Accuracy:    0.891 
Iteration:    946: Loss:     0.430705   Batch Accuracy:    0.859 
Iteration:    947: Loss:     0.255156   Batch Accuracy:    0.945 
Iteration:    948: Loss:     0.357314   Batch Accuracy:    0.906 
Iteration:    949: Loss:     0.476093   Batch Accuracy:    0.891 
Iteration:    950: Loss:     0.408043   Batch Accuracy:    0.883 
Iteration:    951: Loss:     0.339016   Batch Accuracy:    0.859 
Iteration:    952: Loss:     0.268756   Batch Accuracy:    0.922 
Iteration:    953: Loss:     0.399173   Batch Accuracy:    0.883 
Iteration:    954: Loss:     0.418171   Batch Accuracy:    0.891 
Iteration:    955: Loss:     0.433503   Batch Accuracy:    0.891 
Iteration:    956: Loss:     0.436903   Batch Accuracy:    0.875 
Iteration:    957: Loss:     0.380356   Batch Accuracy:    0.906 
Iteration:    958: Loss:     0.335316   Batch Accuracy:    0.922 
Iteration:    959: Loss:     0.399846   Batch Accuracy:    0.867 
Iteration:    960: Loss:     0.256379   Batch Accuracy:    0.930 
Iteration:    961: Loss:     0.364320   Batch Accuracy:    0.914 
Iteration:    962: Loss:     0.321338   Batch Accuracy:    0.930 
Iteration:    963: Loss:     0.371247   Batch Accuracy:    0.891 
Iteration:    964: Loss:     0.253206   Batch Accuracy:    0.914 
Iteration:    965: Loss:     0.306873   Batch Accuracy:    0.914 
Iteration:    966: Loss:     0.387005   Batch Accuracy:    0.930 
Iteration:    967: Loss:     0.328121   Batch Accuracy:    0.922 
Iteration:    968: Loss:     0.518431   Batch Accuracy:    0.852 
Iteration:    969: Loss:     0.519646   Batch Accuracy:    0.883 
Iteration:    970: Loss:     0.310218   Batch Accuracy:    0.922 
Iteration:    971: Loss:     0.398567   Batch Accuracy:    0.883 
Iteration:    972: Loss:     0.417189   Batch Accuracy:    0.891 
Iteration:    973: Loss:     0.349917   Batch Accuracy:    0.914 
Iteration:    974: Loss:     0.380678   Batch Accuracy:    0.875 
Iteration:    975: Loss:     0.431579   Batch Accuracy:    0.836 
Iteration:    976: Loss:     0.326729   Batch Accuracy:    0.914 
Iteration:    977: Loss:     0.412203   Batch Accuracy:    0.898 
Iteration:    978: Loss:     0.352298   Batch Accuracy:    0.906 
Iteration:    979: Loss:     0.276101   Batch Accuracy:    0.914 
Iteration:    980: Loss:     0.377170   Batch Accuracy:    0.883 
Iteration:    981: Loss:     0.347658   Batch Accuracy:    0.891 
Iteration:    982: Loss:     0.271116   Batch Accuracy:    0.914 
Iteration:    983: Loss:     0.454987   Batch Accuracy:    0.844 
Iteration:    984: Loss:     0.279685   Batch Accuracy:    0.938 
Iteration:    985: Loss:     0.406539   Batch Accuracy:    0.891 
Iteration:    986: Loss:     0.305702   Batch Accuracy:    0.922 
Iteration:    987: Loss:     0.313746   Batch Accuracy:    0.930 
Iteration:    988: Loss:     0.371857   Batch Accuracy:    0.914 
Iteration:    989: Loss:     0.383920   Batch Accuracy:    0.914 
Iteration:    990: Loss:     0.400939   Batch Accuracy:    0.859 
Iteration:    991: Loss:     0.379283   Batch Accuracy:    0.898 
Iteration:    992: Loss:     0.343831   Batch Accuracy:    0.875 
Iteration:    993: Loss:     0.369462   Batch Accuracy:    0.883 
Iteration:    994: Loss:     0.334970   Batch Accuracy:    0.922 
Iteration:    995: Loss:     0.294903   Batch Accuracy:    0.938 
Iteration:    996: Loss:     0.374814   Batch Accuracy:    0.914 
Iteration:    997: Loss:     0.225465   Batch Accuracy:    0.938 
Iteration:    998: Loss:     0.303127   Batch Accuracy:    0.922 
Iteration:    999: Loss:     0.392895   Batch Accuracy:    0.867 
evaluating model...
training accuracy: 0.901600
test accuracy:     0.909300
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./compile.sh 
-- Configuring done
CMake Warning (dev):
  Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run "cmake
  --help-policy CMP0042" for policy details.  Use the cmake_policy command to
  set the policy and suppress this warning.

  MACOSX_RPATH is not specified for the following targets:

   nn

This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /Users/jasonhoffman/repos/cv576/cse576_sp20_hw3/build
[ 55%] Built target nn
Scanning dependencies of target train
[ 77%] Built target test
[ 88%] Building CXX object CMakeFiles/train.dir/src/train.cpp.o
[100%] Linking CXX executable ../train
[100%] Built target train
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./train
Loading dataset
Parameters: Rate=10.000000
Training model...
Iteration:      0: Loss:     2.305447   Batch Accuracy:    0.094 
Iteration:      1: Loss:    18.423673   Batch Accuracy:    0.242 
Iteration:      2: Loss:    39.787344   Batch Accuracy:    0.305 
Iteration:      3: Loss:    62.504136   Batch Accuracy:    0.352 
Iteration:      4: Loss:          nan   Batch Accuracy:    0.305 
Iteration:      5: Loss:          nan   Batch Accuracy:    0.094 
Iteration:      6: Loss:          nan   Batch Accuracy:    0.133 
Iteration:      7: Loss:          nan   Batch Accuracy:    0.102 
Iteration:      8: Loss:          nan   Batch Accuracy:    0.102 
Iteration:      9: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     10: Loss:          nan   Batch Accuracy:    0.109 
Iteration:     11: Loss:          nan   Batch Accuracy:    0.062 
Iteration:     12: Loss:          nan   Batch Accuracy:    0.125 
Iteration:     13: Loss:          nan   Batch Accuracy:    0.062 
Iteration:     14: Loss:          nan   Batch Accuracy:    0.125 
Iteration:     15: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     16: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     17: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     18: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     19: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     20: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     21: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     22: Loss:          nan   Batch Accuracy:    0.188 
Iteration:     23: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     24: Loss:          nan   Batch Accuracy:    0.070 
Iteration:     25: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     26: Loss:          nan   Batch Accuracy:    0.141 
Iteration:     27: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     28: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     29: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     30: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     31: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     32: Loss:          nan   Batch Accuracy:    0.125 
Iteration:     33: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     34: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     35: Loss:          nan   Batch Accuracy:    0.086 
Iteration:     36: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     37: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     38: Loss:          nan   Batch Accuracy:    0.148 
Iteration:     39: Loss:          nan   Batch Accuracy:    0.109 
Iteration:     40: Loss:          nan   Batch Accuracy:    0.070 
Iteration:     41: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     42: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     43: Loss:          nan   Batch Accuracy:    0.070 
Iteration:     44: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     45: Loss:          nan   Batch Accuracy:    0.148 
Iteration:     46: Loss:          nan   Batch Accuracy:    0.109 
Iteration:     47: Loss:          nan   Batch Accuracy:    0.141 
Iteration:     48: Loss:          nan   Batch Accuracy:    0.070 
Iteration:     49: Loss:          nan   Batch Accuracy:    0.133 
Iteration:     50: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     51: Loss:          nan   Batch Accuracy:    0.125 
Iteration:     52: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     53: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     54: Loss:          nan   Batch Accuracy:    0.086 
Iteration:     55: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     56: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     57: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     58: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     59: Loss:          nan   Batch Accuracy:    0.070 
Iteration:     60: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     61: Loss:          nan   Batch Accuracy:    0.180 
Iteration:     62: Loss:          nan   Batch Accuracy:    0.070 
Iteration:     63: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     64: Loss:          nan   Batch Accuracy:    0.047 
Iteration:     65: Loss:          nan   Batch Accuracy:    0.125 
Iteration:     66: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     67: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     68: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     69: Loss:          nan   Batch Accuracy:    0.062 
Iteration:     70: Loss:          nan   Batch Accuracy:    0.086 
Iteration:     71: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     72: Loss:          nan   Batch Accuracy:    0.086 
Iteration:     73: Loss:          nan   Batch Accuracy:    0.148 
Iteration:     74: Loss:          nan   Batch Accuracy:    0.133 
Iteration:     75: Loss:          nan   Batch Accuracy:    0.141 
Iteration:     76: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     77: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     78: Loss:          nan   Batch Accuracy:    0.141 
Iteration:     79: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     80: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     81: Loss:          nan   Batch Accuracy:    0.070 
Iteration:     82: Loss:          nan   Batch Accuracy:    0.102 
Iteration:     83: Loss:          nan   Batch Accuracy:    0.109 
Iteration:     84: Loss:          nan   Batch Accuracy:    0.086 
Iteration:     85: Loss:          nan   Batch Accuracy:    0.133 
Iteration:     86: Loss:          nan   Batch Accuracy:    0.141 
Iteration:     87: Loss:          nan   Batch Accuracy:    0.094 
Iteration:     88: Loss:          nan   Batch Accuracy:    0.086 
Iteration:     89: Loss:          nan   Batch Accuracy:    0.148 
Iteration:     90: Loss:          nan   Batch Accuracy:    0.078 
Iteration:     91: Loss:          nan   Batch Accuracy:    0.133 
Iteration:     92: Loss:          nan   Batch Accuracy:    0.148 
Iteration:     93: Loss:          nan   Batch Accuracy:    0.055 
Iteration:     94: Loss:          nan   Batch Accuracy:    0.070 
Iteration:     95: Loss:          nan   Batch Accuracy:    0.117 
Iteration:     96: Loss:          nan   Batch Accuracy:    0.055 
Iteration:     97: Loss:          nan   Batch Accuracy:    0.039 
Iteration:     98: Loss:          nan   Batch Accuracy:    0.141 
Iteration:     99: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    100: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    101: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    102: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    103: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    104: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    105: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    106: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    107: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    108: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    109: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    110: Loss:          nan   Batch Accuracy:    0.180 
Iteration:    111: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    112: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    113: Loss:          nan   Batch Accuracy:    0.156 
Iteration:    114: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    115: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    116: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    117: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    118: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    119: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    120: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    121: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    122: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    123: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    124: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    125: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    126: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    127: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    128: Loss:          nan   Batch Accuracy:    0.039 
Iteration:    129: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    130: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    131: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    132: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    133: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    134: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    135: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    136: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    137: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    138: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    139: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    140: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    141: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    142: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    143: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    144: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    145: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    146: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    147: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    148: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    149: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    150: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    151: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    152: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    153: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    154: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    155: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    156: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    157: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    158: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    159: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    160: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    161: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    162: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    163: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    164: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    165: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    166: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    167: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    168: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    169: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    170: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    171: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    172: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    173: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    174: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    175: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    176: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    177: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    178: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    179: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    180: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    181: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    182: Loss:          nan   Batch Accuracy:    0.039 
Iteration:    183: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    184: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    185: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    186: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    187: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    188: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    189: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    190: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    191: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    192: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    193: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    194: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    195: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    196: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    197: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    198: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    199: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    200: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    201: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    202: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    203: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    204: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    205: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    206: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    207: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    208: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    209: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    210: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    211: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    212: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    213: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    214: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    215: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    216: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    217: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    218: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    219: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    220: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    221: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    222: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    223: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    224: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    225: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    226: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    227: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    228: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    229: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    230: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    231: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    232: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    233: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    234: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    235: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    236: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    237: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    238: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    239: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    240: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    241: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    242: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    243: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    244: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    245: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    246: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    247: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    248: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    249: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    250: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    251: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    252: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    253: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    254: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    255: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    256: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    257: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    258: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    259: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    260: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    261: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    262: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    263: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    264: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    265: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    266: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    267: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    268: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    269: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    270: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    271: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    272: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    273: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    274: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    275: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    276: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    277: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    278: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    279: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    280: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    281: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    282: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    283: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    284: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    285: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    286: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    287: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    288: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    289: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    290: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    291: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    292: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    293: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    294: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    295: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    296: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    297: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    298: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    299: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    300: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    301: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    302: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    303: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    304: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    305: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    306: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    307: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    308: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    309: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    310: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    311: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    312: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    313: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    314: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    315: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    316: Loss:          nan   Batch Accuracy:    0.156 
Iteration:    317: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    318: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    319: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    320: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    321: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    322: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    323: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    324: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    325: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    326: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    327: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    328: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    329: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    330: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    331: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    332: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    333: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    334: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    335: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    336: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    337: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    338: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    339: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    340: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    341: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    342: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    343: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    344: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    345: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    346: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    347: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    348: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    349: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    350: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    351: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    352: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    353: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    354: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    355: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    356: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    357: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    358: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    359: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    360: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    361: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    362: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    363: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    364: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    365: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    366: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    367: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    368: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    369: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    370: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    371: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    372: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    373: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    374: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    375: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    376: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    377: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    378: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    379: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    380: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    381: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    382: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    383: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    384: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    385: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    386: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    387: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    388: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    389: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    390: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    391: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    392: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    393: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    394: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    395: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    396: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    397: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    398: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    399: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    400: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    401: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    402: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    403: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    404: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    405: Loss:          nan   Batch Accuracy:    0.172 
Iteration:    406: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    407: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    408: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    409: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    410: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    411: Loss:          nan   Batch Accuracy:    0.156 
Iteration:    412: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    413: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    414: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    415: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    416: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    417: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    418: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    419: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    420: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    421: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    422: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    423: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    424: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    425: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    426: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    427: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    428: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    429: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    430: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    431: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    432: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    433: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    434: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    435: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    436: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    437: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    438: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    439: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    440: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    441: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    442: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    443: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    444: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    445: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    446: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    447: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    448: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    449: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    450: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    451: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    452: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    453: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    454: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    455: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    456: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    457: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    458: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    459: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    460: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    461: Loss:          nan   Batch Accuracy:    0.164 
Iteration:    462: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    463: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    464: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    465: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    466: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    467: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    468: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    469: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    470: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    471: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    472: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    473: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    474: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    475: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    476: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    477: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    478: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    479: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    480: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    481: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    482: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    483: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    484: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    485: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    486: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    487: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    488: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    489: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    490: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    491: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    492: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    493: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    494: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    495: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    496: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    497: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    498: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    499: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    500: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    501: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    502: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    503: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    504: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    505: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    506: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    507: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    508: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    509: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    510: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    511: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    512: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    513: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    514: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    515: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    516: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    517: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    518: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    519: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    520: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    521: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    522: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    523: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    524: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    525: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    526: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    527: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    528: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    529: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    530: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    531: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    532: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    533: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    534: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    535: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    536: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    537: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    538: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    539: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    540: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    541: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    542: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    543: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    544: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    545: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    546: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    547: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    548: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    549: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    550: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    551: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    552: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    553: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    554: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    555: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    556: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    557: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    558: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    559: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    560: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    561: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    562: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    563: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    564: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    565: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    566: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    567: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    568: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    569: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    570: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    571: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    572: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    573: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    574: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    575: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    576: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    577: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    578: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    579: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    580: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    581: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    582: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    583: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    584: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    585: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    586: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    587: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    588: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    589: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    590: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    591: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    592: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    593: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    594: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    595: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    596: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    597: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    598: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    599: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    600: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    601: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    602: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    603: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    604: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    605: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    606: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    607: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    608: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    609: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    610: Loss:          nan   Batch Accuracy:    0.156 
Iteration:    611: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    612: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    613: Loss:          nan   Batch Accuracy:    0.156 
Iteration:    614: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    615: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    616: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    617: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    618: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    619: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    620: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    621: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    622: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    623: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    624: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    625: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    626: Loss:          nan   Batch Accuracy:    0.039 
Iteration:    627: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    628: Loss:          nan   Batch Accuracy:    0.156 
Iteration:    629: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    630: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    631: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    632: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    633: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    634: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    635: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    636: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    637: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    638: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    639: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    640: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    641: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    642: Loss:          nan   Batch Accuracy:    0.164 
Iteration:    643: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    644: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    645: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    646: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    647: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    648: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    649: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    650: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    651: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    652: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    653: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    654: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    655: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    656: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    657: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    658: Loss:          nan   Batch Accuracy:    0.180 
Iteration:    659: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    660: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    661: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    662: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    663: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    664: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    665: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    666: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    667: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    668: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    669: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    670: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    671: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    672: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    673: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    674: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    675: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    676: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    677: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    678: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    679: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    680: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    681: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    682: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    683: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    684: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    685: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    686: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    687: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    688: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    689: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    690: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    691: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    692: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    693: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    694: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    695: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    696: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    697: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    698: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    699: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    700: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    701: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    702: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    703: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    704: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    705: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    706: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    707: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    708: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    709: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    710: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    711: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    712: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    713: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    714: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    715: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    716: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    717: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    718: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    719: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    720: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    721: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    722: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    723: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    724: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    725: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    726: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    727: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    728: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    729: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    730: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    731: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    732: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    733: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    734: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    735: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    736: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    737: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    738: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    739: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    740: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    741: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    742: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    743: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    744: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    745: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    746: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    747: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    748: Loss:          nan   Batch Accuracy:    0.164 
Iteration:    749: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    750: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    751: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    752: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    753: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    754: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    755: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    756: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    757: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    758: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    759: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    760: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    761: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    762: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    763: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    764: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    765: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    766: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    767: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    768: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    769: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    770: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    771: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    772: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    773: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    774: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    775: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    776: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    777: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    778: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    779: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    780: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    781: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    782: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    783: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    784: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    785: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    786: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    787: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    788: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    789: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    790: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    791: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    792: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    793: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    794: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    795: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    796: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    797: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    798: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    799: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    800: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    801: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    802: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    803: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    804: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    805: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    806: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    807: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    808: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    809: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    810: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    811: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    812: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    813: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    814: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    815: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    816: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    817: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    818: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    819: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    820: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    821: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    822: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    823: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    824: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    825: Loss:          nan   Batch Accuracy:    0.039 
Iteration:    826: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    827: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    828: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    829: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    830: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    831: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    832: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    833: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    834: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    835: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    836: Loss:          nan   Batch Accuracy:    0.156 
Iteration:    837: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    838: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    839: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    840: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    841: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    842: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    843: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    844: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    845: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    846: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    847: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    848: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    849: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    850: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    851: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    852: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    853: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    854: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    855: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    856: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    857: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    858: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    859: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    860: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    861: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    862: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    863: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    864: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    865: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    866: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    867: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    868: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    869: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    870: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    871: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    872: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    873: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    874: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    875: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    876: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    877: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    878: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    879: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    880: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    881: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    882: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    883: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    884: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    885: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    886: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    887: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    888: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    889: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    890: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    891: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    892: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    893: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    894: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    895: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    896: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    897: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    898: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    899: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    900: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    901: Loss:          nan   Batch Accuracy:    0.172 
Iteration:    902: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    903: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    904: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    905: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    906: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    907: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    908: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    909: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    910: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    911: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    912: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    913: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    914: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    915: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    916: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    917: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    918: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    919: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    920: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    921: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    922: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    923: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    924: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    925: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    926: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    927: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    928: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    929: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    930: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    931: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    932: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    933: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    934: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    935: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    936: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    937: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    938: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    939: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    940: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    941: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    942: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    943: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    944: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    945: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    946: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    947: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    948: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    949: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    950: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    951: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    952: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    953: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    954: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    955: Loss:          nan   Batch Accuracy:    0.055 
Iteration:    956: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    957: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    958: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    959: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    960: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    961: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    962: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    963: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    964: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    965: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    966: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    967: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    968: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    969: Loss:          nan   Batch Accuracy:    0.047 
Iteration:    970: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    971: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    972: Loss:          nan   Batch Accuracy:    0.062 
Iteration:    973: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    974: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    975: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    976: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    977: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    978: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    979: Loss:          nan   Batch Accuracy:    0.070 
Iteration:    980: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    981: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    982: Loss:          nan   Batch Accuracy:    0.102 
Iteration:    983: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    984: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    985: Loss:          nan   Batch Accuracy:    0.125 
Iteration:    986: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    987: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    988: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    989: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    990: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    991: Loss:          nan   Batch Accuracy:    0.141 
Iteration:    992: Loss:          nan   Batch Accuracy:    0.148 
Iteration:    993: Loss:          nan   Batch Accuracy:    0.078 
Iteration:    994: Loss:          nan   Batch Accuracy:    0.109 
Iteration:    995: Loss:          nan   Batch Accuracy:    0.133 
Iteration:    996: Loss:          nan   Batch Accuracy:    0.086 
Iteration:    997: Loss:          nan   Batch Accuracy:    0.094 
Iteration:    998: Loss:          nan   Batch Accuracy:    0.117 
Iteration:    999: Loss:          nan   Batch Accuracy:    0.094 
evaluating model...
training accuracy: 0.098717
test accuracy:     0.098000
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./compile.sh 
-- Configuring done
CMake Warning (dev):
  Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run "cmake
  --help-policy CMP0042" for policy details.  Use the cmake_policy command to
  set the policy and suppress this warning.

  MACOSX_RPATH is not specified for the following targets:

   nn

This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /Users/jasonhoffman/repos/cv576/cse576_sp20_hw3/build
[ 55%] Built target nn
Scanning dependencies of target train
[ 88%] Building CXX object CMakeFiles/train.dir/src/train.cpp.o
[ 88%] Built target test
[100%] Linking CXX executable ../train
[100%] Built target train
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./train
Loading dataset
Parameters: Rate=1.000000
Training model...
Iteration:      0: Loss:     2.305447   Batch Accuracy:    0.094 
Iteration:      1: Loss:     2.474816   Batch Accuracy:    0.258 
Iteration:      2: Loss:     2.406484   Batch Accuracy:    0.438 
Iteration:      3: Loss:     2.164911   Batch Accuracy:    0.477 
Iteration:      4: Loss:     2.049936   Batch Accuracy:    0.586 
Iteration:      5: Loss:     2.582750   Batch Accuracy:    0.508 
Iteration:      6: Loss:     0.962276   Batch Accuracy:    0.789 
Iteration:      7: Loss:     0.990556   Batch Accuracy:    0.766 
Iteration:      8: Loss:     1.845490   Batch Accuracy:    0.734 
Iteration:      9: Loss:     1.876065   Batch Accuracy:    0.781 
Iteration:     10: Loss:     1.438210   Batch Accuracy:    0.836 
Iteration:     11: Loss:     1.031278   Batch Accuracy:    0.789 
Iteration:     12: Loss:     1.346277   Batch Accuracy:    0.781 
Iteration:     13: Loss:     1.482717   Batch Accuracy:    0.758 
Iteration:     14: Loss:     1.340406   Batch Accuracy:    0.781 
Iteration:     15: Loss:     1.232268   Batch Accuracy:    0.820 
Iteration:     16: Loss:     2.025333   Batch Accuracy:    0.734 
Iteration:     17: Loss:     1.885680   Batch Accuracy:    0.805 
Iteration:     18: Loss:     1.351390   Batch Accuracy:    0.789 
Iteration:     19: Loss:     1.478277   Batch Accuracy:    0.828 
Iteration:     20: Loss:     0.690309   Batch Accuracy:    0.898 
Iteration:     21: Loss:     1.130818   Batch Accuracy:    0.836 
Iteration:     22: Loss:     0.990610   Batch Accuracy:    0.883 
Iteration:     23: Loss:     1.289583   Batch Accuracy:    0.844 
Iteration:     24: Loss:     0.911468   Batch Accuracy:    0.836 
Iteration:     25: Loss:     1.282773   Batch Accuracy:    0.836 
Iteration:     26: Loss:     1.507629   Batch Accuracy:    0.852 
Iteration:     27: Loss:     2.594818   Batch Accuracy:    0.742 
Iteration:     28: Loss:     0.797744   Batch Accuracy:    0.867 
Iteration:     29: Loss:     0.916202   Batch Accuracy:    0.898 
Iteration:     30: Loss:     1.084417   Batch Accuracy:    0.812 
Iteration:     31: Loss:     1.562394   Batch Accuracy:    0.789 
Iteration:     32: Loss:     1.341712   Batch Accuracy:    0.859 
Iteration:     33: Loss:     0.381784   Batch Accuracy:    0.898 
Iteration:     34: Loss:     1.495443   Batch Accuracy:    0.852 
Iteration:     35: Loss:     0.475928   Batch Accuracy:    0.859 
Iteration:     36: Loss:     0.935364   Batch Accuracy:    0.883 
Iteration:     37: Loss:     1.734510   Batch Accuracy:    0.836 
Iteration:     38: Loss:     0.993315   Batch Accuracy:    0.867 
Iteration:     39: Loss:     0.332347   Batch Accuracy:    0.906 
Iteration:     40: Loss:     1.128871   Batch Accuracy:    0.883 
Iteration:     41: Loss:     0.991024   Batch Accuracy:    0.883 
Iteration:     42: Loss:     1.430393   Batch Accuracy:    0.805 
Iteration:     43: Loss:     0.710554   Batch Accuracy:    0.844 
Iteration:     44: Loss:     1.524545   Batch Accuracy:    0.805 
Iteration:     45: Loss:     0.770524   Batch Accuracy:    0.875 
Iteration:     46: Loss:     0.626369   Batch Accuracy:    0.906 
Iteration:     47: Loss:     1.182325   Batch Accuracy:    0.867 
Iteration:     48: Loss:     1.495535   Batch Accuracy:    0.812 
Iteration:     49: Loss:     1.500874   Batch Accuracy:    0.789 
Iteration:     50: Loss:     1.269000   Batch Accuracy:    0.820 
Iteration:     51: Loss:     1.915392   Batch Accuracy:    0.773 
Iteration:     52: Loss:     1.606382   Batch Accuracy:    0.812 
Iteration:     53: Loss:     0.807382   Batch Accuracy:    0.867 
Iteration:     54: Loss:     0.705290   Batch Accuracy:    0.883 
Iteration:     55: Loss:     1.237312   Batch Accuracy:    0.828 
Iteration:     56: Loss:     1.459635   Batch Accuracy:    0.844 
Iteration:     57: Loss:     0.502455   Batch Accuracy:    0.922 
Iteration:     58: Loss:     0.758788   Batch Accuracy:    0.875 
Iteration:     59: Loss:     0.843112   Batch Accuracy:    0.891 
Iteration:     60: Loss:     1.191628   Batch Accuracy:    0.797 
Iteration:     61: Loss:     0.922430   Batch Accuracy:    0.883 
Iteration:     62: Loss:     1.466035   Batch Accuracy:    0.844 
Iteration:     63: Loss:     0.968764   Batch Accuracy:    0.883 
Iteration:     64: Loss:     0.642455   Batch Accuracy:    0.891 
Iteration:     65: Loss:     0.985840   Batch Accuracy:    0.875 
Iteration:     66: Loss:     0.736364   Batch Accuracy:    0.875 
Iteration:     67: Loss:     0.583671   Batch Accuracy:    0.891 
Iteration:     68: Loss:     1.158689   Batch Accuracy:    0.836 
Iteration:     69: Loss:     1.049920   Batch Accuracy:    0.867 
Iteration:     70: Loss:     0.982482   Batch Accuracy:    0.836 
Iteration:     71: Loss:     0.779578   Batch Accuracy:    0.867 
Iteration:     72: Loss:     1.210998   Batch Accuracy:    0.805 
Iteration:     73: Loss:     0.804293   Batch Accuracy:    0.852 
Iteration:     74: Loss:     0.699279   Batch Accuracy:    0.867 
Iteration:     75: Loss:     0.544927   Batch Accuracy:    0.898 
Iteration:     76: Loss:     1.209646   Batch Accuracy:    0.859 
Iteration:     77: Loss:     0.619741   Batch Accuracy:    0.922 
Iteration:     78: Loss:     0.656618   Batch Accuracy:    0.891 
Iteration:     79: Loss:     1.539228   Batch Accuracy:    0.852 
Iteration:     80: Loss:     0.814490   Batch Accuracy:    0.836 
Iteration:     81: Loss:     0.648818   Batch Accuracy:    0.891 
Iteration:     82: Loss:     0.354540   Batch Accuracy:    0.930 
Iteration:     83: Loss:     0.700888   Batch Accuracy:    0.812 
Iteration:     84: Loss:     1.137233   Batch Accuracy:    0.867 
Iteration:     85: Loss:     0.768062   Batch Accuracy:    0.859 
Iteration:     86: Loss:     0.986121   Batch Accuracy:    0.859 
Iteration:     87: Loss:     0.485132   Batch Accuracy:    0.891 
Iteration:     88: Loss:     0.889437   Batch Accuracy:    0.867 
Iteration:     89: Loss:     0.596370   Batch Accuracy:    0.938 
Iteration:     90: Loss:     0.636329   Batch Accuracy:    0.875 
Iteration:     91: Loss:     1.022907   Batch Accuracy:    0.812 
Iteration:     92: Loss:     0.565256   Batch Accuracy:    0.883 
Iteration:     93: Loss:     1.016696   Batch Accuracy:    0.836 
Iteration:     94: Loss:     0.766963   Batch Accuracy:    0.836 
Iteration:     95: Loss:     0.444088   Batch Accuracy:    0.914 
Iteration:     96: Loss:     0.565498   Batch Accuracy:    0.906 
Iteration:     97: Loss:     0.628563   Batch Accuracy:    0.891 
Iteration:     98: Loss:     0.782376   Batch Accuracy:    0.844 
Iteration:     99: Loss:     0.196750   Batch Accuracy:    0.930 
Iteration:    100: Loss:     0.733510   Batch Accuracy:    0.891 
Iteration:    101: Loss:     0.868234   Batch Accuracy:    0.852 
Iteration:    102: Loss:     0.503221   Batch Accuracy:    0.898 
Iteration:    103: Loss:     0.834299   Batch Accuracy:    0.875 
Iteration:    104: Loss:     0.642898   Batch Accuracy:    0.883 
Iteration:    105: Loss:     0.682430   Batch Accuracy:    0.883 
Iteration:    106: Loss:     0.876835   Batch Accuracy:    0.812 
Iteration:    107: Loss:     0.446150   Batch Accuracy:    0.891 
Iteration:    108: Loss:     0.900560   Batch Accuracy:    0.812 
Iteration:    109: Loss:     0.602076   Batch Accuracy:    0.914 
Iteration:    110: Loss:     0.908804   Batch Accuracy:    0.836 
Iteration:    111: Loss:     0.764039   Batch Accuracy:    0.867 
Iteration:    112: Loss:     0.795263   Batch Accuracy:    0.867 
Iteration:    113: Loss:     0.626685   Batch Accuracy:    0.891 
Iteration:    114: Loss:     0.558877   Batch Accuracy:    0.938 
Iteration:    115: Loss:     0.739077   Batch Accuracy:    0.875 
Iteration:    116: Loss:     0.858064   Batch Accuracy:    0.859 
Iteration:    117: Loss:     0.565958   Batch Accuracy:    0.875 
Iteration:    118: Loss:     0.395367   Batch Accuracy:    0.891 
Iteration:    119: Loss:     0.703580   Batch Accuracy:    0.852 
Iteration:    120: Loss:     0.916353   Batch Accuracy:    0.844 
Iteration:    121: Loss:     1.112876   Batch Accuracy:    0.828 
Iteration:    122: Loss:     0.557544   Batch Accuracy:    0.859 
Iteration:    123: Loss:     0.746440   Batch Accuracy:    0.883 
Iteration:    124: Loss:     0.840875   Batch Accuracy:    0.836 
Iteration:    125: Loss:     0.616912   Batch Accuracy:    0.930 
Iteration:    126: Loss:     0.732510   Batch Accuracy:    0.844 
Iteration:    127: Loss:     0.594260   Batch Accuracy:    0.828 
Iteration:    128: Loss:     0.736430   Batch Accuracy:    0.859 
Iteration:    129: Loss:     0.546120   Batch Accuracy:    0.859 
Iteration:    130: Loss:     0.636624   Batch Accuracy:    0.875 
Iteration:    131: Loss:     1.259357   Batch Accuracy:    0.805 
Iteration:    132: Loss:     0.661724   Batch Accuracy:    0.930 
Iteration:    133: Loss:     0.978386   Batch Accuracy:    0.859 
Iteration:    134: Loss:     0.695467   Batch Accuracy:    0.867 
Iteration:    135: Loss:     0.434940   Batch Accuracy:    0.914 
Iteration:    136: Loss:     0.772447   Batch Accuracy:    0.859 
Iteration:    137: Loss:     1.069680   Batch Accuracy:    0.836 
Iteration:    138: Loss:     0.550726   Batch Accuracy:    0.891 
Iteration:    139: Loss:     0.609284   Batch Accuracy:    0.867 
Iteration:    140: Loss:     0.644026   Batch Accuracy:    0.852 
Iteration:    141: Loss:     0.774236   Batch Accuracy:    0.852 
Iteration:    142: Loss:     0.803310   Batch Accuracy:    0.906 
Iteration:    143: Loss:     0.622695   Batch Accuracy:    0.906 
Iteration:    144: Loss:     0.924523   Batch Accuracy:    0.852 
Iteration:    145: Loss:     0.798088   Batch Accuracy:    0.859 
Iteration:    146: Loss:     1.140451   Batch Accuracy:    0.836 
Iteration:    147: Loss:     0.933495   Batch Accuracy:    0.828 
Iteration:    148: Loss:     0.650813   Batch Accuracy:    0.859 
Iteration:    149: Loss:     0.620914   Batch Accuracy:    0.828 
Iteration:    150: Loss:     1.306591   Batch Accuracy:    0.789 
Iteration:    151: Loss:     0.516136   Batch Accuracy:    0.867 
Iteration:    152: Loss:     0.723160   Batch Accuracy:    0.844 
Iteration:    153: Loss:     0.564390   Batch Accuracy:    0.852 
Iteration:    154: Loss:     0.858340   Batch Accuracy:    0.883 
Iteration:    155: Loss:     0.867303   Batch Accuracy:    0.844 
Iteration:    156: Loss:     0.296947   Batch Accuracy:    0.922 
Iteration:    157: Loss:     0.595046   Batch Accuracy:    0.844 
Iteration:    158: Loss:     0.850760   Batch Accuracy:    0.812 
Iteration:    159: Loss:     0.839141   Batch Accuracy:    0.883 
Iteration:    160: Loss:     0.763717   Batch Accuracy:    0.859 
Iteration:    161: Loss:     0.751077   Batch Accuracy:    0.836 
Iteration:    162: Loss:     1.056628   Batch Accuracy:    0.828 
Iteration:    163: Loss:     0.623236   Batch Accuracy:    0.891 
Iteration:    164: Loss:     0.594554   Batch Accuracy:    0.859 
Iteration:    165: Loss:     0.850110   Batch Accuracy:    0.852 
Iteration:    166: Loss:     0.655016   Batch Accuracy:    0.906 
Iteration:    167: Loss:     0.711406   Batch Accuracy:    0.883 
Iteration:    168: Loss:     1.268002   Batch Accuracy:    0.836 
Iteration:    169: Loss:     0.470303   Batch Accuracy:    0.891 
Iteration:    170: Loss:     0.930305   Batch Accuracy:    0.883 
Iteration:    171: Loss:     1.151489   Batch Accuracy:    0.836 
Iteration:    172: Loss:     1.248726   Batch Accuracy:    0.852 
Iteration:    173: Loss:     0.927497   Batch Accuracy:    0.836 
Iteration:    174: Loss:     0.960991   Batch Accuracy:    0.883 
Iteration:    175: Loss:     0.644608   Batch Accuracy:    0.852 
Iteration:    176: Loss:     0.564442   Batch Accuracy:    0.906 
Iteration:    177: Loss:     0.590951   Batch Accuracy:    0.859 
Iteration:    178: Loss:     0.764646   Batch Accuracy:    0.891 
Iteration:    179: Loss:     0.841868   Batch Accuracy:    0.812 
Iteration:    180: Loss:     0.518616   Batch Accuracy:    0.914 
Iteration:    181: Loss:     0.763074   Batch Accuracy:    0.891 
Iteration:    182: Loss:     0.959596   Batch Accuracy:    0.867 
Iteration:    183: Loss:     0.492652   Batch Accuracy:    0.875 
Iteration:    184: Loss:     0.715374   Batch Accuracy:    0.852 
Iteration:    185: Loss:     0.545283   Batch Accuracy:    0.906 
Iteration:    186: Loss:     0.663932   Batch Accuracy:    0.914 
Iteration:    187: Loss:     0.746393   Batch Accuracy:    0.836 
Iteration:    188: Loss:     0.915468   Batch Accuracy:    0.875 
Iteration:    189: Loss:     0.619212   Batch Accuracy:    0.891 
Iteration:    190: Loss:     1.231593   Batch Accuracy:    0.844 
Iteration:    191: Loss:     0.341978   Batch Accuracy:    0.883 
Iteration:    192: Loss:     0.905542   Batch Accuracy:    0.906 
Iteration:    193: Loss:     0.867538   Batch Accuracy:    0.852 
Iteration:    194: Loss:     0.897512   Batch Accuracy:    0.836 
Iteration:    195: Loss:     0.339129   Batch Accuracy:    0.914 
Iteration:    196: Loss:     0.760433   Batch Accuracy:    0.875 
Iteration:    197: Loss:     0.980413   Batch Accuracy:    0.859 
Iteration:    198: Loss:     0.619999   Batch Accuracy:    0.875 
Iteration:    199: Loss:     0.970211   Batch Accuracy:    0.836 
Iteration:    200: Loss:     0.505160   Batch Accuracy:    0.906 
Iteration:    201: Loss:     0.812841   Batch Accuracy:    0.844 
Iteration:    202: Loss:     1.070473   Batch Accuracy:    0.812 
Iteration:    203: Loss:     1.135071   Batch Accuracy:    0.836 
Iteration:    204: Loss:     1.205259   Batch Accuracy:    0.781 
Iteration:    205: Loss:     0.974393   Batch Accuracy:    0.844 
Iteration:    206: Loss:     0.586095   Batch Accuracy:    0.891 
Iteration:    207: Loss:     1.066986   Batch Accuracy:    0.812 
Iteration:    208: Loss:     1.091016   Batch Accuracy:    0.859 
Iteration:    209: Loss:     0.625211   Batch Accuracy:    0.898 
Iteration:    210: Loss:     1.437534   Batch Accuracy:    0.805 
Iteration:    211: Loss:     0.440305   Batch Accuracy:    0.891 
Iteration:    212: Loss:     0.804911   Batch Accuracy:    0.859 
Iteration:    213: Loss:     1.184505   Batch Accuracy:    0.805 
Iteration:    214: Loss:     0.949880   Batch Accuracy:    0.859 
Iteration:    215: Loss:     1.226068   Batch Accuracy:    0.820 
Iteration:    216: Loss:     1.037333   Batch Accuracy:    0.812 
Iteration:    217: Loss:     0.971612   Batch Accuracy:    0.883 
Iteration:    218: Loss:     0.977086   Batch Accuracy:    0.844 
Iteration:    219: Loss:     1.028147   Batch Accuracy:    0.875 
Iteration:    220: Loss:     1.050616   Batch Accuracy:    0.867 
Iteration:    221: Loss:     0.480792   Batch Accuracy:    0.898 
Iteration:    222: Loss:     0.786537   Batch Accuracy:    0.859 
Iteration:    223: Loss:     1.977056   Batch Accuracy:    0.828 
Iteration:    224: Loss:     1.142731   Batch Accuracy:    0.836 
Iteration:    225: Loss:     1.040705   Batch Accuracy:    0.852 
Iteration:    226: Loss:     1.371472   Batch Accuracy:    0.781 
Iteration:    227: Loss:     1.182202   Batch Accuracy:    0.852 
Iteration:    228: Loss:     1.128856   Batch Accuracy:    0.836 
Iteration:    229: Loss:     0.842164   Batch Accuracy:    0.812 
Iteration:    230: Loss:     0.966466   Batch Accuracy:    0.797 
Iteration:    231: Loss:     0.890042   Batch Accuracy:    0.883 
Iteration:    232: Loss:     0.584497   Batch Accuracy:    0.883 
Iteration:    233: Loss:     1.300412   Batch Accuracy:    0.805 
Iteration:    234: Loss:     0.117936   Batch Accuracy:    0.953 
Iteration:    235: Loss:     1.026523   Batch Accuracy:    0.820 
Iteration:    236: Loss:     0.673889   Batch Accuracy:    0.922 
Iteration:    237: Loss:     0.789222   Batch Accuracy:    0.898 
Iteration:    238: Loss:     1.050867   Batch Accuracy:    0.820 
Iteration:    239: Loss:     1.200329   Batch Accuracy:    0.828 
Iteration:    240: Loss:     0.784838   Batch Accuracy:    0.859 
Iteration:    241: Loss:     0.576361   Batch Accuracy:    0.898 
Iteration:    242: Loss:     0.567427   Batch Accuracy:    0.906 
Iteration:    243: Loss:     0.547050   Batch Accuracy:    0.906 
Iteration:    244: Loss:     1.336666   Batch Accuracy:    0.859 
Iteration:    245: Loss:     1.092474   Batch Accuracy:    0.859 
Iteration:    246: Loss:     0.678900   Batch Accuracy:    0.891 
Iteration:    247: Loss:     1.144229   Batch Accuracy:    0.891 
Iteration:    248: Loss:     0.835066   Batch Accuracy:    0.875 
Iteration:    249: Loss:     0.480968   Batch Accuracy:    0.891 
Iteration:    250: Loss:     0.705609   Batch Accuracy:    0.852 
Iteration:    251: Loss:     0.971959   Batch Accuracy:    0.898 
Iteration:    252: Loss:     1.343673   Batch Accuracy:    0.852 
Iteration:    253: Loss:     0.835598   Batch Accuracy:    0.891 
Iteration:    254: Loss:     0.747731   Batch Accuracy:    0.883 
Iteration:    255: Loss:     0.683235   Batch Accuracy:    0.898 
Iteration:    256: Loss:     0.689143   Batch Accuracy:    0.906 
Iteration:    257: Loss:     0.738918   Batch Accuracy:    0.891 
Iteration:    258: Loss:     0.767437   Batch Accuracy:    0.867 
Iteration:    259: Loss:     0.858024   Batch Accuracy:    0.867 
Iteration:    260: Loss:     1.524562   Batch Accuracy:    0.875 
Iteration:    261: Loss:     1.274029   Batch Accuracy:    0.844 
Iteration:    262: Loss:     1.320319   Batch Accuracy:    0.844 
Iteration:    263: Loss:     0.696405   Batch Accuracy:    0.906 
Iteration:    264: Loss:     1.100530   Batch Accuracy:    0.852 
Iteration:    265: Loss:     1.045035   Batch Accuracy:    0.836 
Iteration:    266: Loss:     0.715387   Batch Accuracy:    0.875 
Iteration:    267: Loss:     0.629620   Batch Accuracy:    0.922 
Iteration:    268: Loss:     0.269766   Batch Accuracy:    0.891 
Iteration:    269: Loss:     0.313118   Batch Accuracy:    0.898 
Iteration:    270: Loss:     1.062824   Batch Accuracy:    0.852 
Iteration:    271: Loss:     0.714292   Batch Accuracy:    0.898 
Iteration:    272: Loss:     0.595888   Batch Accuracy:    0.898 
Iteration:    273: Loss:     0.819545   Batch Accuracy:    0.891 
Iteration:    274: Loss:     1.328460   Batch Accuracy:    0.828 
Iteration:    275: Loss:     0.630002   Batch Accuracy:    0.867 
Iteration:    276: Loss:     1.223088   Batch Accuracy:    0.820 
Iteration:    277: Loss:     1.404899   Batch Accuracy:    0.797 
Iteration:    278: Loss:     0.807348   Batch Accuracy:    0.891 
Iteration:    279: Loss:     0.829095   Batch Accuracy:    0.891 
Iteration:    280: Loss:     1.098796   Batch Accuracy:    0.859 
Iteration:    281: Loss:     0.793791   Batch Accuracy:    0.883 
Iteration:    282: Loss:     0.631693   Batch Accuracy:    0.859 
Iteration:    283: Loss:     0.740220   Batch Accuracy:    0.852 
Iteration:    284: Loss:     0.635191   Batch Accuracy:    0.859 
Iteration:    285: Loss:     0.600142   Batch Accuracy:    0.898 
Iteration:    286: Loss:     1.038445   Batch Accuracy:    0.867 
Iteration:    287: Loss:     1.145447   Batch Accuracy:    0.867 
Iteration:    288: Loss:     0.438230   Batch Accuracy:    0.891 
Iteration:    289: Loss:     1.149327   Batch Accuracy:    0.844 
Iteration:    290: Loss:     0.506144   Batch Accuracy:    0.859 
Iteration:    291: Loss:     1.051341   Batch Accuracy:    0.867 
Iteration:    292: Loss:     0.559438   Batch Accuracy:    0.891 
Iteration:    293: Loss:     0.884874   Batch Accuracy:    0.859 
Iteration:    294: Loss:     1.623126   Batch Accuracy:    0.789 
Iteration:    295: Loss:     0.701082   Batch Accuracy:    0.883 
Iteration:    296: Loss:     0.643336   Batch Accuracy:    0.891 
Iteration:    297: Loss:     0.905660   Batch Accuracy:    0.883 
Iteration:    298: Loss:     0.705656   Batch Accuracy:    0.891 
Iteration:    299: Loss:     0.771601   Batch Accuracy:    0.867 
Iteration:    300: Loss:     0.620273   Batch Accuracy:    0.914 
Iteration:    301: Loss:     0.626848   Batch Accuracy:    0.883 
Iteration:    302: Loss:     0.726668   Batch Accuracy:    0.898 
Iteration:    303: Loss:     0.705717   Batch Accuracy:    0.844 
Iteration:    304: Loss:     0.637987   Batch Accuracy:    0.898 
Iteration:    305: Loss:     0.510611   Batch Accuracy:    0.914 
Iteration:    306: Loss:     0.315207   Batch Accuracy:    0.914 
Iteration:    307: Loss:     0.498415   Batch Accuracy:    0.891 
Iteration:    308: Loss:     0.914598   Batch Accuracy:    0.891 
Iteration:    309: Loss:     1.381028   Batch Accuracy:    0.820 
Iteration:    310: Loss:     1.105830   Batch Accuracy:    0.812 
Iteration:    311: Loss:     0.222256   Batch Accuracy:    0.945 
Iteration:    312: Loss:     0.825276   Batch Accuracy:    0.875 
Iteration:    313: Loss:     0.406829   Batch Accuracy:    0.898 
Iteration:    314: Loss:     0.889521   Batch Accuracy:    0.914 
Iteration:    315: Loss:     0.499478   Batch Accuracy:    0.906 
Iteration:    316: Loss:     0.480380   Batch Accuracy:    0.914 
Iteration:    317: Loss:     1.064061   Batch Accuracy:    0.836 
Iteration:    318: Loss:     0.991631   Batch Accuracy:    0.859 
Iteration:    319: Loss:     0.748879   Batch Accuracy:    0.891 
Iteration:    320: Loss:     1.057123   Batch Accuracy:    0.852 
Iteration:    321: Loss:     0.938712   Batch Accuracy:    0.852 
Iteration:    322: Loss:     0.443072   Batch Accuracy:    0.906 
Iteration:    323: Loss:     0.307624   Batch Accuracy:    0.930 
Iteration:    324: Loss:     0.575979   Batch Accuracy:    0.875 
Iteration:    325: Loss:     0.555908   Batch Accuracy:    0.891 
Iteration:    326: Loss:     0.922115   Batch Accuracy:    0.875 
Iteration:    327: Loss:     0.772679   Batch Accuracy:    0.898 
Iteration:    328: Loss:     0.723067   Batch Accuracy:    0.891 
Iteration:    329: Loss:     0.792421   Batch Accuracy:    0.852 
Iteration:    330: Loss:     0.250595   Batch Accuracy:    0.953 
Iteration:    331: Loss:     0.267994   Batch Accuracy:    0.953 
Iteration:    332: Loss:     1.310803   Batch Accuracy:    0.867 
Iteration:    333: Loss:     0.477396   Batch Accuracy:    0.898 
Iteration:    334: Loss:     0.755389   Batch Accuracy:    0.867 
Iteration:    335: Loss:     0.490808   Batch Accuracy:    0.922 
Iteration:    336: Loss:     0.509585   Batch Accuracy:    0.938 
Iteration:    337: Loss:     0.726429   Batch Accuracy:    0.883 
Iteration:    338: Loss:     0.655656   Batch Accuracy:    0.891 
Iteration:    339: Loss:     0.510277   Batch Accuracy:    0.898 
Iteration:    340: Loss:     0.812664   Batch Accuracy:    0.852 
Iteration:    341: Loss:     0.638335   Batch Accuracy:    0.914 
Iteration:    342: Loss:     0.754535   Batch Accuracy:    0.852 
Iteration:    343: Loss:     0.611126   Batch Accuracy:    0.867 
Iteration:    344: Loss:     0.805513   Batch Accuracy:    0.867 
Iteration:    345: Loss:     0.906712   Batch Accuracy:    0.875 
Iteration:    346: Loss:     0.374012   Batch Accuracy:    0.914 
Iteration:    347: Loss:     0.415424   Batch Accuracy:    0.930 
Iteration:    348: Loss:     1.069097   Batch Accuracy:    0.867 
Iteration:    349: Loss:     0.831662   Batch Accuracy:    0.875 
Iteration:    350: Loss:     0.337063   Batch Accuracy:    0.930 
Iteration:    351: Loss:     0.902972   Batch Accuracy:    0.836 
Iteration:    352: Loss:     0.605497   Batch Accuracy:    0.922 
Iteration:    353: Loss:     1.059248   Batch Accuracy:    0.875 
Iteration:    354: Loss:     0.684287   Batch Accuracy:    0.898 
Iteration:    355: Loss:     0.686193   Batch Accuracy:    0.883 
Iteration:    356: Loss:     0.705464   Batch Accuracy:    0.852 
Iteration:    357: Loss:     0.877093   Batch Accuracy:    0.875 
Iteration:    358: Loss:     0.606024   Batch Accuracy:    0.906 
Iteration:    359: Loss:     0.391695   Batch Accuracy:    0.914 
Iteration:    360: Loss:     0.571424   Batch Accuracy:    0.891 
Iteration:    361: Loss:     0.727281   Batch Accuracy:    0.852 
Iteration:    362: Loss:     0.791674   Batch Accuracy:    0.883 
Iteration:    363: Loss:     0.944120   Batch Accuracy:    0.867 
Iteration:    364: Loss:     0.419921   Batch Accuracy:    0.898 
Iteration:    365: Loss:     0.454514   Batch Accuracy:    0.883 
Iteration:    366: Loss:     1.211563   Batch Accuracy:    0.812 
Iteration:    367: Loss:     0.491995   Batch Accuracy:    0.898 
Iteration:    368: Loss:     0.608379   Batch Accuracy:    0.906 
Iteration:    369: Loss:     0.961631   Batch Accuracy:    0.859 
Iteration:    370: Loss:     0.414358   Batch Accuracy:    0.938 
Iteration:    371: Loss:     0.553172   Batch Accuracy:    0.891 
Iteration:    372: Loss:     1.034209   Batch Accuracy:    0.812 
Iteration:    373: Loss:     0.537518   Batch Accuracy:    0.883 
Iteration:    374: Loss:     0.484852   Batch Accuracy:    0.906 
Iteration:    375: Loss:     0.408839   Batch Accuracy:    0.922 
Iteration:    376: Loss:     0.318348   Batch Accuracy:    0.953 
Iteration:    377: Loss:     0.613428   Batch Accuracy:    0.867 
Iteration:    378: Loss:     0.436491   Batch Accuracy:    0.922 
Iteration:    379: Loss:     0.512104   Batch Accuracy:    0.906 
Iteration:    380: Loss:     0.705151   Batch Accuracy:    0.836 
Iteration:    381: Loss:     0.991320   Batch Accuracy:    0.852 
Iteration:    382: Loss:     0.568539   Batch Accuracy:    0.906 
Iteration:    383: Loss:     0.621443   Batch Accuracy:    0.867 
Iteration:    384: Loss:     0.736575   Batch Accuracy:    0.867 
Iteration:    385: Loss:     0.397821   Batch Accuracy:    0.914 
Iteration:    386: Loss:     0.604740   Batch Accuracy:    0.883 
Iteration:    387: Loss:     0.652845   Batch Accuracy:    0.891 
Iteration:    388: Loss:     1.193186   Batch Accuracy:    0.820 
Iteration:    389: Loss:     0.820937   Batch Accuracy:    0.867 
Iteration:    390: Loss:     0.638635   Batch Accuracy:    0.922 
Iteration:    391: Loss:     0.502335   Batch Accuracy:    0.891 
Iteration:    392: Loss:     1.436883   Batch Accuracy:    0.820 
Iteration:    393: Loss:     0.869113   Batch Accuracy:    0.797 
Iteration:    394: Loss:     0.719353   Batch Accuracy:    0.898 
Iteration:    395: Loss:     0.718923   Batch Accuracy:    0.867 
Iteration:    396: Loss:     0.530993   Batch Accuracy:    0.883 
Iteration:    397: Loss:     0.751559   Batch Accuracy:    0.867 
Iteration:    398: Loss:     0.994291   Batch Accuracy:    0.859 
Iteration:    399: Loss:     1.133355   Batch Accuracy:    0.836 
Iteration:    400: Loss:     0.795085   Batch Accuracy:    0.852 
Iteration:    401: Loss:     0.718375   Batch Accuracy:    0.867 
Iteration:    402: Loss:     0.713358   Batch Accuracy:    0.875 
Iteration:    403: Loss:     0.540722   Batch Accuracy:    0.906 
Iteration:    404: Loss:     0.594280   Batch Accuracy:    0.875 
Iteration:    405: Loss:     0.436925   Batch Accuracy:    0.930 
Iteration:    406: Loss:     0.974018   Batch Accuracy:    0.875 
Iteration:    407: Loss:     0.268286   Batch Accuracy:    0.922 
Iteration:    408: Loss:     0.782601   Batch Accuracy:    0.867 
Iteration:    409: Loss:     0.343112   Batch Accuracy:    0.938 
Iteration:    410: Loss:     0.534027   Batch Accuracy:    0.906 
Iteration:    411: Loss:     0.752350   Batch Accuracy:    0.891 
Iteration:    412: Loss:     0.703459   Batch Accuracy:    0.938 
Iteration:    413: Loss:     0.636444   Batch Accuracy:    0.875 
Iteration:    414: Loss:     0.283536   Batch Accuracy:    0.938 
Iteration:    415: Loss:     0.720782   Batch Accuracy:    0.867 
Iteration:    416: Loss:     0.672710   Batch Accuracy:    0.898 
Iteration:    417: Loss:     1.074647   Batch Accuracy:    0.805 
Iteration:    418: Loss:     1.224081   Batch Accuracy:    0.852 
Iteration:    419: Loss:     1.080249   Batch Accuracy:    0.859 
Iteration:    420: Loss:     1.245988   Batch Accuracy:    0.867 
Iteration:    421: Loss:     0.775575   Batch Accuracy:    0.828 
Iteration:    422: Loss:     0.632408   Batch Accuracy:    0.875 
Iteration:    423: Loss:     0.658131   Batch Accuracy:    0.891 
Iteration:    424: Loss:     1.026944   Batch Accuracy:    0.852 
Iteration:    425: Loss:     0.321672   Batch Accuracy:    0.914 
Iteration:    426: Loss:     0.919192   Batch Accuracy:    0.852 
Iteration:    427: Loss:     0.508989   Batch Accuracy:    0.906 
Iteration:    428: Loss:     0.632053   Batch Accuracy:    0.922 
Iteration:    429: Loss:     0.594639   Batch Accuracy:    0.914 
Iteration:    430: Loss:     0.594714   Batch Accuracy:    0.891 
Iteration:    431: Loss:     0.749077   Batch Accuracy:    0.898 
Iteration:    432: Loss:     0.950157   Batch Accuracy:    0.859 
Iteration:    433: Loss:     0.373704   Batch Accuracy:    0.898 
Iteration:    434: Loss:     0.808318   Batch Accuracy:    0.867 
Iteration:    435: Loss:     0.511210   Batch Accuracy:    0.906 
Iteration:    436: Loss:     0.399060   Batch Accuracy:    0.930 
Iteration:    437: Loss:     0.577481   Batch Accuracy:    0.891 
Iteration:    438: Loss:     0.870672   Batch Accuracy:    0.828 
Iteration:    439: Loss:     0.598865   Batch Accuracy:    0.883 
Iteration:    440: Loss:     0.453586   Batch Accuracy:    0.914 
Iteration:    441: Loss:     0.713883   Batch Accuracy:    0.883 
Iteration:    442: Loss:     0.491126   Batch Accuracy:    0.906 
Iteration:    443: Loss:     0.677675   Batch Accuracy:    0.906 
Iteration:    444: Loss:     0.473903   Batch Accuracy:    0.898 
Iteration:    445: Loss:     0.445167   Batch Accuracy:    0.906 
Iteration:    446: Loss:     0.563379   Batch Accuracy:    0.898 
Iteration:    447: Loss:     0.575184   Batch Accuracy:    0.898 
Iteration:    448: Loss:     0.353875   Batch Accuracy:    0.930 
Iteration:    449: Loss:     0.629780   Batch Accuracy:    0.859 
Iteration:    450: Loss:     0.612303   Batch Accuracy:    0.867 
Iteration:    451: Loss:     0.336055   Batch Accuracy:    0.938 
Iteration:    452: Loss:     0.656883   Batch Accuracy:    0.875 
Iteration:    453: Loss:     0.486701   Batch Accuracy:    0.914 
Iteration:    454: Loss:     0.809509   Batch Accuracy:    0.844 
Iteration:    455: Loss:     0.853123   Batch Accuracy:    0.891 
Iteration:    456: Loss:     0.562576   Batch Accuracy:    0.898 
Iteration:    457: Loss:     0.240995   Batch Accuracy:    0.922 
Iteration:    458: Loss:     0.982963   Batch Accuracy:    0.867 
Iteration:    459: Loss:     0.644226   Batch Accuracy:    0.859 
Iteration:    460: Loss:     0.439531   Batch Accuracy:    0.906 
Iteration:    461: Loss:     1.482084   Batch Accuracy:    0.852 
Iteration:    462: Loss:     0.990298   Batch Accuracy:    0.867 
Iteration:    463: Loss:     0.785932   Batch Accuracy:    0.867 
Iteration:    464: Loss:     0.349804   Batch Accuracy:    0.891 
Iteration:    465: Loss:     0.821427   Batch Accuracy:    0.828 
Iteration:    466: Loss:     0.728897   Batch Accuracy:    0.805 
Iteration:    467: Loss:     0.720383   Batch Accuracy:    0.852 
Iteration:    468: Loss:     0.874126   Batch Accuracy:    0.859 
Iteration:    469: Loss:     0.499258   Batch Accuracy:    0.867 
Iteration:    470: Loss:     0.916287   Batch Accuracy:    0.867 
Iteration:    471: Loss:     0.580772   Batch Accuracy:    0.852 
Iteration:    472: Loss:     0.650261   Batch Accuracy:    0.883 
Iteration:    473: Loss:     0.581430   Batch Accuracy:    0.883 
Iteration:    474: Loss:     1.397464   Batch Accuracy:    0.852 
Iteration:    475: Loss:     0.542043   Batch Accuracy:    0.891 
Iteration:    476: Loss:     0.927788   Batch Accuracy:    0.867 
Iteration:    477: Loss:     1.082042   Batch Accuracy:    0.867 
Iteration:    478: Loss:     1.103728   Batch Accuracy:    0.773 
Iteration:    479: Loss:     0.915164   Batch Accuracy:    0.836 
Iteration:    480: Loss:     0.930367   Batch Accuracy:    0.875 
Iteration:    481: Loss:     1.135762   Batch Accuracy:    0.891 
Iteration:    482: Loss:     0.663766   Batch Accuracy:    0.898 
Iteration:    483: Loss:     0.553613   Batch Accuracy:    0.875 
Iteration:    484: Loss:     0.843446   Batch Accuracy:    0.852 
Iteration:    485: Loss:     0.642565   Batch Accuracy:    0.891 
Iteration:    486: Loss:     0.561929   Batch Accuracy:    0.906 
Iteration:    487: Loss:     0.863069   Batch Accuracy:    0.859 
Iteration:    488: Loss:     0.846813   Batch Accuracy:    0.883 
Iteration:    489: Loss:     0.833336   Batch Accuracy:    0.875 
Iteration:    490: Loss:     1.131145   Batch Accuracy:    0.867 
Iteration:    491: Loss:     1.190951   Batch Accuracy:    0.805 
Iteration:    492: Loss:     0.753352   Batch Accuracy:    0.852 
Iteration:    493: Loss:     0.662573   Batch Accuracy:    0.898 
Iteration:    494: Loss:     0.672772   Batch Accuracy:    0.922 
Iteration:    495: Loss:     1.252755   Batch Accuracy:    0.781 
Iteration:    496: Loss:     1.141414   Batch Accuracy:    0.844 
Iteration:    497: Loss:     0.607276   Batch Accuracy:    0.906 
Iteration:    498: Loss:     0.369693   Batch Accuracy:    0.930 
Iteration:    499: Loss:     0.494507   Batch Accuracy:    0.867 
Iteration:    500: Loss:     0.752458   Batch Accuracy:    0.891 
Iteration:    501: Loss:     0.825284   Batch Accuracy:    0.883 
Iteration:    502: Loss:     0.681771   Batch Accuracy:    0.883 
Iteration:    503: Loss:     1.733358   Batch Accuracy:    0.828 
Iteration:    504: Loss:     0.511491   Batch Accuracy:    0.883 
Iteration:    505: Loss:     1.119277   Batch Accuracy:    0.875 
Iteration:    506: Loss:     1.045199   Batch Accuracy:    0.836 
Iteration:    507: Loss:     0.507854   Batch Accuracy:    0.914 
Iteration:    508: Loss:     0.388979   Batch Accuracy:    0.922 
Iteration:    509: Loss:     0.944659   Batch Accuracy:    0.891 
Iteration:    510: Loss:     1.169427   Batch Accuracy:    0.812 
Iteration:    511: Loss:     0.646721   Batch Accuracy:    0.836 
Iteration:    512: Loss:     0.451719   Batch Accuracy:    0.930 
Iteration:    513: Loss:     0.694166   Batch Accuracy:    0.836 
Iteration:    514: Loss:     0.439673   Batch Accuracy:    0.914 
Iteration:    515: Loss:     0.366171   Batch Accuracy:    0.891 
Iteration:    516: Loss:     0.612213   Batch Accuracy:    0.906 
Iteration:    517: Loss:     0.440008   Batch Accuracy:    0.883 
Iteration:    518: Loss:     0.617455   Batch Accuracy:    0.906 
Iteration:    519: Loss:     0.484756   Batch Accuracy:    0.930 
Iteration:    520: Loss:     0.498470   Batch Accuracy:    0.891 
Iteration:    521: Loss:     0.835847   Batch Accuracy:    0.891 
Iteration:    522: Loss:     0.542710   Batch Accuracy:    0.883 
Iteration:    523: Loss:     0.447853   Batch Accuracy:    0.914 
Iteration:    524: Loss:     1.144092   Batch Accuracy:    0.852 
Iteration:    525: Loss:     0.457603   Batch Accuracy:    0.859 
Iteration:    526: Loss:     0.466272   Batch Accuracy:    0.883 
Iteration:    527: Loss:     0.642736   Batch Accuracy:    0.859 
Iteration:    528: Loss:     0.634109   Batch Accuracy:    0.836 
Iteration:    529: Loss:     0.546987   Batch Accuracy:    0.898 
Iteration:    530: Loss:     0.728559   Batch Accuracy:    0.844 
Iteration:    531: Loss:     0.566056   Batch Accuracy:    0.875 
Iteration:    532: Loss:     0.412684   Batch Accuracy:    0.914 
Iteration:    533: Loss:     0.548048   Batch Accuracy:    0.914 
Iteration:    534: Loss:     0.720105   Batch Accuracy:    0.906 
Iteration:    535: Loss:     0.299248   Batch Accuracy:    0.930 
Iteration:    536: Loss:     0.746986   Batch Accuracy:    0.867 
Iteration:    537: Loss:     0.898098   Batch Accuracy:    0.852 
Iteration:    538: Loss:     1.515476   Batch Accuracy:    0.836 
Iteration:    539: Loss:     0.845721   Batch Accuracy:    0.883 
Iteration:    540: Loss:     0.824908   Batch Accuracy:    0.852 
Iteration:    541: Loss:     0.652963   Batch Accuracy:    0.844 
Iteration:    542: Loss:     1.196579   Batch Accuracy:    0.836 
Iteration:    543: Loss:     0.561781   Batch Accuracy:    0.898 
Iteration:    544: Loss:     0.536685   Batch Accuracy:    0.891 
Iteration:    545: Loss:     0.757156   Batch Accuracy:    0.898 
Iteration:    546: Loss:     0.936401   Batch Accuracy:    0.867 
Iteration:    547: Loss:     0.547087   Batch Accuracy:    0.875 
Iteration:    548: Loss:     1.248717   Batch Accuracy:    0.797 
Iteration:    549: Loss:     0.629943   Batch Accuracy:    0.875 
Iteration:    550: Loss:     0.861610   Batch Accuracy:    0.852 
Iteration:    551: Loss:     0.848403   Batch Accuracy:    0.891 
Iteration:    552: Loss:     0.819903   Batch Accuracy:    0.898 
Iteration:    553: Loss:     0.894933   Batch Accuracy:    0.852 
Iteration:    554: Loss:     1.347384   Batch Accuracy:    0.891 
Iteration:    555: Loss:     1.002146   Batch Accuracy:    0.891 
Iteration:    556: Loss:     0.842203   Batch Accuracy:    0.914 
Iteration:    557: Loss:     0.639133   Batch Accuracy:    0.898 
Iteration:    558: Loss:     1.659876   Batch Accuracy:    0.852 
Iteration:    559: Loss:     0.640360   Batch Accuracy:    0.875 
Iteration:    560: Loss:     0.505530   Batch Accuracy:    0.875 
Iteration:    561: Loss:     0.435251   Batch Accuracy:    0.898 
Iteration:    562: Loss:     0.525624   Batch Accuracy:    0.891 
Iteration:    563: Loss:     1.172619   Batch Accuracy:    0.820 
Iteration:    564: Loss:     0.868785   Batch Accuracy:    0.891 
Iteration:    565: Loss:     0.471107   Batch Accuracy:    0.898 
Iteration:    566: Loss:     0.882765   Batch Accuracy:    0.867 
Iteration:    567: Loss:     0.876071   Batch Accuracy:    0.859 
Iteration:    568: Loss:     1.234701   Batch Accuracy:    0.867 
Iteration:    569: Loss:     1.027661   Batch Accuracy:    0.898 
Iteration:    570: Loss:     0.807676   Batch Accuracy:    0.875 
Iteration:    571: Loss:     0.678607   Batch Accuracy:    0.875 
Iteration:    572: Loss:     0.608002   Batch Accuracy:    0.891 
Iteration:    573: Loss:     0.500116   Batch Accuracy:    0.891 
Iteration:    574: Loss:     0.926513   Batch Accuracy:    0.859 
Iteration:    575: Loss:     0.659869   Batch Accuracy:    0.867 
Iteration:    576: Loss:     1.326308   Batch Accuracy:    0.867 
Iteration:    577: Loss:     0.852242   Batch Accuracy:    0.867 
Iteration:    578: Loss:     1.178869   Batch Accuracy:    0.797 
Iteration:    579: Loss:     0.606482   Batch Accuracy:    0.906 
Iteration:    580: Loss:     0.750753   Batch Accuracy:    0.891 
Iteration:    581: Loss:     0.321885   Batch Accuracy:    0.922 
Iteration:    582: Loss:     0.620541   Batch Accuracy:    0.891 
Iteration:    583: Loss:     0.344398   Batch Accuracy:    0.930 
Iteration:    584: Loss:     1.031114   Batch Accuracy:    0.898 
Iteration:    585: Loss:     0.540048   Batch Accuracy:    0.867 
Iteration:    586: Loss:     0.473444   Batch Accuracy:    0.914 
Iteration:    587: Loss:     0.511176   Batch Accuracy:    0.914 
Iteration:    588: Loss:     0.524731   Batch Accuracy:    0.883 
Iteration:    589: Loss:     0.633396   Batch Accuracy:    0.898 
Iteration:    590: Loss:     0.884269   Batch Accuracy:    0.898 
Iteration:    591: Loss:     0.468725   Batch Accuracy:    0.898 
Iteration:    592: Loss:     0.423564   Batch Accuracy:    0.891 
Iteration:    593: Loss:     0.812687   Batch Accuracy:    0.789 
Iteration:    594: Loss:     1.134159   Batch Accuracy:    0.867 
Iteration:    595: Loss:     0.596436   Batch Accuracy:    0.883 
Iteration:    596: Loss:     0.875735   Batch Accuracy:    0.875 
Iteration:    597: Loss:     1.646684   Batch Accuracy:    0.781 
Iteration:    598: Loss:     0.417031   Batch Accuracy:    0.922 
Iteration:    599: Loss:     0.719530   Batch Accuracy:    0.891 
Iteration:    600: Loss:     0.424789   Batch Accuracy:    0.930 
Iteration:    601: Loss:     0.499357   Batch Accuracy:    0.898 
Iteration:    602: Loss:     1.071816   Batch Accuracy:    0.820 
Iteration:    603: Loss:     0.804765   Batch Accuracy:    0.875 
Iteration:    604: Loss:     0.322062   Batch Accuracy:    0.930 
Iteration:    605: Loss:     1.091756   Batch Accuracy:    0.812 
Iteration:    606: Loss:     0.713503   Batch Accuracy:    0.836 
Iteration:    607: Loss:     0.384517   Batch Accuracy:    0.875 
Iteration:    608: Loss:     0.745461   Batch Accuracy:    0.844 
Iteration:    609: Loss:     0.668491   Batch Accuracy:    0.867 
Iteration:    610: Loss:     0.557189   Batch Accuracy:    0.828 
Iteration:    611: Loss:     0.698831   Batch Accuracy:    0.883 
Iteration:    612: Loss:     0.600221   Batch Accuracy:    0.914 
Iteration:    613: Loss:     0.890689   Batch Accuracy:    0.867 
Iteration:    614: Loss:     0.525741   Batch Accuracy:    0.898 
Iteration:    615: Loss:     0.563615   Batch Accuracy:    0.844 
Iteration:    616: Loss:     0.893481   Batch Accuracy:    0.906 
Iteration:    617: Loss:     0.883584   Batch Accuracy:    0.883 
Iteration:    618: Loss:     0.605428   Batch Accuracy:    0.906 
Iteration:    619: Loss:     1.005463   Batch Accuracy:    0.852 
Iteration:    620: Loss:     0.581935   Batch Accuracy:    0.867 
Iteration:    621: Loss:     0.537335   Batch Accuracy:    0.914 
Iteration:    622: Loss:     0.696761   Batch Accuracy:    0.906 
Iteration:    623: Loss:     1.031764   Batch Accuracy:    0.805 
Iteration:    624: Loss:     1.057811   Batch Accuracy:    0.859 
Iteration:    625: Loss:     0.453882   Batch Accuracy:    0.898 
Iteration:    626: Loss:     1.123422   Batch Accuracy:    0.836 
Iteration:    627: Loss:     0.618003   Batch Accuracy:    0.922 
Iteration:    628: Loss:     0.767898   Batch Accuracy:    0.859 
Iteration:    629: Loss:     0.265609   Batch Accuracy:    0.930 
Iteration:    630: Loss:     0.703143   Batch Accuracy:    0.883 
Iteration:    631: Loss:     0.524126   Batch Accuracy:    0.867 
Iteration:    632: Loss:     0.952488   Batch Accuracy:    0.891 
Iteration:    633: Loss:     0.598753   Batch Accuracy:    0.914 
Iteration:    634: Loss:     0.796068   Batch Accuracy:    0.930 
Iteration:    635: Loss:     0.749298   Batch Accuracy:    0.844 
Iteration:    636: Loss:     0.340039   Batch Accuracy:    0.930 
Iteration:    637: Loss:     0.631732   Batch Accuracy:    0.859 
Iteration:    638: Loss:     0.620303   Batch Accuracy:    0.875 
Iteration:    639: Loss:     0.436595   Batch Accuracy:    0.914 
Iteration:    640: Loss:     0.660453   Batch Accuracy:    0.914 
Iteration:    641: Loss:     0.774417   Batch Accuracy:    0.852 
Iteration:    642: Loss:     0.763814   Batch Accuracy:    0.844 
Iteration:    643: Loss:     0.607686   Batch Accuracy:    0.875 
Iteration:    644: Loss:     0.262223   Batch Accuracy:    0.922 
Iteration:    645: Loss:     0.655851   Batch Accuracy:    0.836 
Iteration:    646: Loss:     0.647256   Batch Accuracy:    0.891 
Iteration:    647: Loss:     0.976040   Batch Accuracy:    0.883 
Iteration:    648: Loss:     0.778182   Batch Accuracy:    0.883 
Iteration:    649: Loss:     0.779311   Batch Accuracy:    0.898 
Iteration:    650: Loss:     0.700365   Batch Accuracy:    0.914 
Iteration:    651: Loss:     0.700518   Batch Accuracy:    0.844 
Iteration:    652: Loss:     0.919876   Batch Accuracy:    0.836 
Iteration:    653: Loss:     1.062055   Batch Accuracy:    0.844 
Iteration:    654: Loss:     1.092215   Batch Accuracy:    0.852 
Iteration:    655: Loss:     0.538975   Batch Accuracy:    0.883 
Iteration:    656: Loss:     0.862296   Batch Accuracy:    0.859 
Iteration:    657: Loss:     0.952661   Batch Accuracy:    0.820 
Iteration:    658: Loss:     0.603784   Batch Accuracy:    0.867 
Iteration:    659: Loss:     0.822274   Batch Accuracy:    0.883 
Iteration:    660: Loss:     0.628928   Batch Accuracy:    0.875 
Iteration:    661: Loss:     0.548505   Batch Accuracy:    0.898 
Iteration:    662: Loss:     0.614958   Batch Accuracy:    0.922 
Iteration:    663: Loss:     0.643113   Batch Accuracy:    0.875 
Iteration:    664: Loss:     0.927837   Batch Accuracy:    0.867 
Iteration:    665: Loss:     0.916142   Batch Accuracy:    0.867 
Iteration:    666: Loss:     0.779462   Batch Accuracy:    0.891 
Iteration:    667: Loss:     0.850882   Batch Accuracy:    0.836 
Iteration:    668: Loss:     0.436483   Batch Accuracy:    0.914 
Iteration:    669: Loss:     0.955592   Batch Accuracy:    0.883 
Iteration:    670: Loss:     0.824729   Batch Accuracy:    0.883 
Iteration:    671: Loss:     0.481490   Batch Accuracy:    0.930 
Iteration:    672: Loss:     1.364235   Batch Accuracy:    0.867 
Iteration:    673: Loss:     0.621892   Batch Accuracy:    0.891 
Iteration:    674: Loss:     0.811287   Batch Accuracy:    0.891 
Iteration:    675: Loss:     0.401828   Batch Accuracy:    0.898 
Iteration:    676: Loss:     0.601428   Batch Accuracy:    0.914 
Iteration:    677: Loss:     0.783403   Batch Accuracy:    0.875 
Iteration:    678: Loss:     0.258978   Batch Accuracy:    0.945 
Iteration:    679: Loss:     0.544828   Batch Accuracy:    0.891 
Iteration:    680: Loss:     0.509862   Batch Accuracy:    0.914 
Iteration:    681: Loss:     0.592131   Batch Accuracy:    0.891 
Iteration:    682: Loss:     0.922715   Batch Accuracy:    0.891 
Iteration:    683: Loss:     0.449159   Batch Accuracy:    0.906 
Iteration:    684: Loss:     0.792622   Batch Accuracy:    0.906 
Iteration:    685: Loss:     0.831421   Batch Accuracy:    0.891 
Iteration:    686: Loss:     1.045101   Batch Accuracy:    0.859 
Iteration:    687: Loss:     0.672253   Batch Accuracy:    0.906 
Iteration:    688: Loss:     0.932005   Batch Accuracy:    0.844 
Iteration:    689: Loss:     1.001029   Batch Accuracy:    0.867 
Iteration:    690: Loss:     0.883522   Batch Accuracy:    0.906 
Iteration:    691: Loss:     1.340554   Batch Accuracy:    0.836 
Iteration:    692: Loss:     0.692498   Batch Accuracy:    0.906 
Iteration:    693: Loss:     1.219583   Batch Accuracy:    0.781 
Iteration:    694: Loss:     0.627997   Batch Accuracy:    0.891 
Iteration:    695: Loss:     0.610448   Batch Accuracy:    0.859 
Iteration:    696: Loss:     0.465360   Batch Accuracy:    0.914 
Iteration:    697: Loss:     0.414208   Batch Accuracy:    0.906 
Iteration:    698: Loss:     0.532792   Batch Accuracy:    0.906 
Iteration:    699: Loss:     0.855259   Batch Accuracy:    0.836 
Iteration:    700: Loss:     0.594296   Batch Accuracy:    0.906 
Iteration:    701: Loss:     0.398794   Batch Accuracy:    0.930 
Iteration:    702: Loss:     1.123914   Batch Accuracy:    0.875 
Iteration:    703: Loss:     0.637423   Batch Accuracy:    0.883 
Iteration:    704: Loss:     0.622646   Batch Accuracy:    0.844 
Iteration:    705: Loss:     0.595236   Batch Accuracy:    0.891 
Iteration:    706: Loss:     1.236969   Batch Accuracy:    0.828 
Iteration:    707: Loss:     0.597957   Batch Accuracy:    0.906 
Iteration:    708: Loss:     0.682733   Batch Accuracy:    0.898 
Iteration:    709: Loss:     0.354568   Batch Accuracy:    0.914 
Iteration:    710: Loss:     0.580410   Batch Accuracy:    0.883 
Iteration:    711: Loss:     0.655656   Batch Accuracy:    0.906 
Iteration:    712: Loss:     0.644613   Batch Accuracy:    0.875 
Iteration:    713: Loss:     0.855282   Batch Accuracy:    0.859 
Iteration:    714: Loss:     0.424809   Batch Accuracy:    0.914 
Iteration:    715: Loss:     0.703128   Batch Accuracy:    0.891 
Iteration:    716: Loss:     0.959781   Batch Accuracy:    0.836 
Iteration:    717: Loss:     0.374053   Batch Accuracy:    0.906 
Iteration:    718: Loss:     0.481589   Batch Accuracy:    0.930 
Iteration:    719: Loss:     0.733318   Batch Accuracy:    0.875 
Iteration:    720: Loss:     0.720142   Batch Accuracy:    0.898 
Iteration:    721: Loss:     0.686910   Batch Accuracy:    0.891 
Iteration:    722: Loss:     0.683786   Batch Accuracy:    0.867 
Iteration:    723: Loss:     0.448665   Batch Accuracy:    0.906 
Iteration:    724: Loss:     1.047184   Batch Accuracy:    0.859 
Iteration:    725: Loss:     0.618550   Batch Accuracy:    0.930 
Iteration:    726: Loss:     0.692819   Batch Accuracy:    0.906 
Iteration:    727: Loss:     0.548674   Batch Accuracy:    0.922 
Iteration:    728: Loss:     0.629026   Batch Accuracy:    0.898 
Iteration:    729: Loss:     1.214845   Batch Accuracy:    0.859 
Iteration:    730: Loss:     0.734550   Batch Accuracy:    0.875 
Iteration:    731: Loss:     0.388829   Batch Accuracy:    0.906 
Iteration:    732: Loss:     0.563728   Batch Accuracy:    0.875 
Iteration:    733: Loss:     1.476308   Batch Accuracy:    0.836 
Iteration:    734: Loss:     0.271214   Batch Accuracy:    0.945 
Iteration:    735: Loss:     0.807986   Batch Accuracy:    0.883 
Iteration:    736: Loss:     0.907954   Batch Accuracy:    0.844 
Iteration:    737: Loss:     0.196441   Batch Accuracy:    0.953 
Iteration:    738: Loss:     0.487589   Batch Accuracy:    0.938 
Iteration:    739: Loss:     0.533825   Batch Accuracy:    0.891 
Iteration:    740: Loss:     0.761257   Batch Accuracy:    0.898 
Iteration:    741: Loss:     1.057679   Batch Accuracy:    0.828 
Iteration:    742: Loss:     0.406168   Batch Accuracy:    0.945 
Iteration:    743: Loss:     0.229183   Batch Accuracy:    0.953 
Iteration:    744: Loss:     0.622736   Batch Accuracy:    0.914 
Iteration:    745: Loss:     0.818924   Batch Accuracy:    0.883 
Iteration:    746: Loss:     0.374628   Batch Accuracy:    0.922 
Iteration:    747: Loss:     0.644838   Batch Accuracy:    0.891 
Iteration:    748: Loss:     0.398040   Batch Accuracy:    0.898 
Iteration:    749: Loss:     0.535912   Batch Accuracy:    0.906 
Iteration:    750: Loss:     0.709399   Batch Accuracy:    0.867 
Iteration:    751: Loss:     0.489021   Batch Accuracy:    0.875 
Iteration:    752: Loss:     0.540356   Batch Accuracy:    0.938 
Iteration:    753: Loss:     1.169375   Batch Accuracy:    0.828 
Iteration:    754: Loss:     0.617642   Batch Accuracy:    0.883 
Iteration:    755: Loss:     0.625530   Batch Accuracy:    0.914 
Iteration:    756: Loss:     0.845730   Batch Accuracy:    0.883 
Iteration:    757: Loss:     0.691455   Batch Accuracy:    0.859 
Iteration:    758: Loss:     0.370003   Batch Accuracy:    0.906 
Iteration:    759: Loss:     0.912858   Batch Accuracy:    0.836 
Iteration:    760: Loss:     0.391655   Batch Accuracy:    0.906 
Iteration:    761: Loss:     0.582942   Batch Accuracy:    0.875 
Iteration:    762: Loss:     0.412335   Batch Accuracy:    0.859 
Iteration:    763: Loss:     0.597141   Batch Accuracy:    0.922 
Iteration:    764: Loss:     1.027575   Batch Accuracy:    0.812 
Iteration:    765: Loss:     0.845952   Batch Accuracy:    0.883 
Iteration:    766: Loss:     0.541755   Batch Accuracy:    0.883 
Iteration:    767: Loss:     0.383126   Batch Accuracy:    0.883 
Iteration:    768: Loss:     1.181378   Batch Accuracy:    0.867 
Iteration:    769: Loss:     0.865172   Batch Accuracy:    0.891 
Iteration:    770: Loss:     0.880309   Batch Accuracy:    0.820 
Iteration:    771: Loss:     0.557947   Batch Accuracy:    0.875 
Iteration:    772: Loss:     1.201107   Batch Accuracy:    0.805 
Iteration:    773: Loss:     0.856789   Batch Accuracy:    0.883 
Iteration:    774: Loss:     1.129511   Batch Accuracy:    0.875 
Iteration:    775: Loss:     0.626945   Batch Accuracy:    0.867 
Iteration:    776: Loss:     1.227474   Batch Accuracy:    0.867 
Iteration:    777: Loss:     0.615729   Batch Accuracy:    0.844 
Iteration:    778: Loss:     0.654704   Batch Accuracy:    0.898 
Iteration:    779: Loss:     0.339963   Batch Accuracy:    0.914 
Iteration:    780: Loss:     0.651628   Batch Accuracy:    0.875 
Iteration:    781: Loss:     0.604178   Batch Accuracy:    0.844 
Iteration:    782: Loss:     1.068991   Batch Accuracy:    0.891 
Iteration:    783: Loss:     0.658508   Batch Accuracy:    0.891 
Iteration:    784: Loss:     0.197532   Batch Accuracy:    0.930 
Iteration:    785: Loss:     0.521321   Batch Accuracy:    0.922 
Iteration:    786: Loss:     0.748655   Batch Accuracy:    0.836 
Iteration:    787: Loss:     0.734620   Batch Accuracy:    0.906 
Iteration:    788: Loss:     0.622284   Batch Accuracy:    0.898 
Iteration:    789: Loss:     0.706158   Batch Accuracy:    0.891 
Iteration:    790: Loss:     0.838927   Batch Accuracy:    0.859 
Iteration:    791: Loss:     0.405923   Batch Accuracy:    0.922 
Iteration:    792: Loss:     0.628657   Batch Accuracy:    0.898 
Iteration:    793: Loss:     0.758048   Batch Accuracy:    0.883 
Iteration:    794: Loss:     0.989552   Batch Accuracy:    0.820 
Iteration:    795: Loss:     0.342364   Batch Accuracy:    0.930 
Iteration:    796: Loss:     0.496223   Batch Accuracy:    0.914 
Iteration:    797: Loss:     0.794280   Batch Accuracy:    0.898 
Iteration:    798: Loss:     0.883535   Batch Accuracy:    0.883 
Iteration:    799: Loss:     0.477458   Batch Accuracy:    0.867 
Iteration:    800: Loss:     0.567348   Batch Accuracy:    0.930 
Iteration:    801: Loss:     0.535104   Batch Accuracy:    0.875 
Iteration:    802: Loss:     0.581197   Batch Accuracy:    0.883 
Iteration:    803: Loss:     0.313235   Batch Accuracy:    0.906 
Iteration:    804: Loss:     0.419671   Batch Accuracy:    0.883 
Iteration:    805: Loss:     0.754943   Batch Accuracy:    0.883 
Iteration:    806: Loss:     0.518532   Batch Accuracy:    0.875 
Iteration:    807: Loss:     1.237132   Batch Accuracy:    0.859 
Iteration:    808: Loss:     0.286293   Batch Accuracy:    0.953 
Iteration:    809: Loss:     0.446366   Batch Accuracy:    0.898 
Iteration:    810: Loss:     0.584985   Batch Accuracy:    0.898 
Iteration:    811: Loss:     0.747772   Batch Accuracy:    0.875 
Iteration:    812: Loss:     0.892521   Batch Accuracy:    0.875 
Iteration:    813: Loss:     0.363920   Batch Accuracy:    0.953 
Iteration:    814: Loss:     0.906810   Batch Accuracy:    0.883 
Iteration:    815: Loss:     0.842210   Batch Accuracy:    0.898 
Iteration:    816: Loss:     0.947797   Batch Accuracy:    0.844 
Iteration:    817: Loss:     0.669363   Batch Accuracy:    0.875 
Iteration:    818: Loss:     0.583292   Batch Accuracy:    0.914 
Iteration:    819: Loss:     0.657784   Batch Accuracy:    0.891 
Iteration:    820: Loss:     0.521694   Batch Accuracy:    0.906 
Iteration:    821: Loss:     0.908329   Batch Accuracy:    0.836 
Iteration:    822: Loss:     0.790624   Batch Accuracy:    0.898 
Iteration:    823: Loss:     0.466145   Batch Accuracy:    0.898 
Iteration:    824: Loss:     1.066487   Batch Accuracy:    0.898 
Iteration:    825: Loss:     1.021101   Batch Accuracy:    0.836 
Iteration:    826: Loss:     0.793228   Batch Accuracy:    0.922 
Iteration:    827: Loss:     0.932229   Batch Accuracy:    0.875 
Iteration:    828: Loss:     0.882723   Batch Accuracy:    0.828 
Iteration:    829: Loss:     0.641561   Batch Accuracy:    0.891 
Iteration:    830: Loss:     0.809564   Batch Accuracy:    0.883 
Iteration:    831: Loss:     0.806666   Batch Accuracy:    0.852 
Iteration:    832: Loss:     0.767501   Batch Accuracy:    0.891 
Iteration:    833: Loss:     0.936110   Batch Accuracy:    0.844 
Iteration:    834: Loss:     0.815347   Batch Accuracy:    0.875 
Iteration:    835: Loss:     0.582602   Batch Accuracy:    0.898 
Iteration:    836: Loss:     0.958383   Batch Accuracy:    0.836 
Iteration:    837: Loss:     0.549473   Batch Accuracy:    0.898 
Iteration:    838: Loss:     0.691419   Batch Accuracy:    0.867 
Iteration:    839: Loss:     0.809752   Batch Accuracy:    0.906 
Iteration:    840: Loss:     0.634272   Batch Accuracy:    0.867 
Iteration:    841: Loss:     0.508755   Batch Accuracy:    0.898 
Iteration:    842: Loss:     0.792399   Batch Accuracy:    0.852 
Iteration:    843: Loss:     0.919579   Batch Accuracy:    0.859 
Iteration:    844: Loss:     0.896817   Batch Accuracy:    0.875 
Iteration:    845: Loss:     0.323546   Batch Accuracy:    0.906 
Iteration:    846: Loss:     0.507576   Batch Accuracy:    0.875 
Iteration:    847: Loss:     0.488442   Batch Accuracy:    0.914 
Iteration:    848: Loss:     0.937900   Batch Accuracy:    0.867 
Iteration:    849: Loss:     0.678887   Batch Accuracy:    0.883 
Iteration:    850: Loss:     0.785212   Batch Accuracy:    0.906 
Iteration:    851: Loss:     0.601580   Batch Accuracy:    0.898 
Iteration:    852: Loss:     0.484499   Batch Accuracy:    0.906 
Iteration:    853: Loss:     0.615101   Batch Accuracy:    0.875 
Iteration:    854: Loss:     0.705412   Batch Accuracy:    0.883 
Iteration:    855: Loss:     0.636471   Batch Accuracy:    0.883 
Iteration:    856: Loss:     1.004448   Batch Accuracy:    0.836 
Iteration:    857: Loss:     0.962529   Batch Accuracy:    0.836 
Iteration:    858: Loss:     0.996565   Batch Accuracy:    0.852 
Iteration:    859: Loss:     0.643468   Batch Accuracy:    0.867 
Iteration:    860: Loss:     0.701379   Batch Accuracy:    0.914 
Iteration:    861: Loss:     0.501657   Batch Accuracy:    0.898 
Iteration:    862: Loss:     0.870788   Batch Accuracy:    0.883 
Iteration:    863: Loss:     0.749162   Batch Accuracy:    0.852 
Iteration:    864: Loss:     0.715403   Batch Accuracy:    0.883 
Iteration:    865: Loss:     0.515910   Batch Accuracy:    0.883 
Iteration:    866: Loss:     0.550701   Batch Accuracy:    0.891 
Iteration:    867: Loss:     0.695415   Batch Accuracy:    0.867 
Iteration:    868: Loss:     1.029443   Batch Accuracy:    0.898 
Iteration:    869: Loss:     0.552771   Batch Accuracy:    0.875 
Iteration:    870: Loss:     0.439590   Batch Accuracy:    0.875 
Iteration:    871: Loss:     0.738572   Batch Accuracy:    0.867 
Iteration:    872: Loss:     0.873919   Batch Accuracy:    0.883 
Iteration:    873: Loss:     0.345666   Batch Accuracy:    0.930 
Iteration:    874: Loss:     0.512382   Batch Accuracy:    0.938 
Iteration:    875: Loss:     0.493905   Batch Accuracy:    0.922 
Iteration:    876: Loss:     0.332143   Batch Accuracy:    0.891 
Iteration:    877: Loss:     0.827327   Batch Accuracy:    0.828 
Iteration:    878: Loss:     0.477410   Batch Accuracy:    0.906 
Iteration:    879: Loss:     0.614779   Batch Accuracy:    0.898 
Iteration:    880: Loss:     0.829852   Batch Accuracy:    0.859 
Iteration:    881: Loss:     1.379636   Batch Accuracy:    0.852 
Iteration:    882: Loss:     0.409243   Batch Accuracy:    0.945 
Iteration:    883: Loss:     0.567943   Batch Accuracy:    0.883 
Iteration:    884: Loss:     0.346907   Batch Accuracy:    0.922 
Iteration:    885: Loss:     0.861955   Batch Accuracy:    0.883 
Iteration:    886: Loss:     0.752845   Batch Accuracy:    0.891 
Iteration:    887: Loss:     0.207206   Batch Accuracy:    0.969 
Iteration:    888: Loss:     0.576902   Batch Accuracy:    0.891 
Iteration:    889: Loss:     0.657250   Batch Accuracy:    0.906 
Iteration:    890: Loss:     0.442616   Batch Accuracy:    0.906 
Iteration:    891: Loss:     0.528336   Batch Accuracy:    0.906 
Iteration:    892: Loss:     0.578698   Batch Accuracy:    0.898 
Iteration:    893: Loss:     0.657112   Batch Accuracy:    0.922 
Iteration:    894: Loss:     0.767403   Batch Accuracy:    0.867 
Iteration:    895: Loss:     0.311290   Batch Accuracy:    0.930 
Iteration:    896: Loss:     0.742975   Batch Accuracy:    0.875 
Iteration:    897: Loss:     0.311468   Batch Accuracy:    0.922 
Iteration:    898: Loss:     0.432662   Batch Accuracy:    0.891 
Iteration:    899: Loss:     0.580957   Batch Accuracy:    0.859 
Iteration:    900: Loss:     0.513637   Batch Accuracy:    0.883 
Iteration:    901: Loss:     0.372432   Batch Accuracy:    0.922 
Iteration:    902: Loss:     0.554707   Batch Accuracy:    0.891 
Iteration:    903: Loss:     0.520727   Batch Accuracy:    0.891 
Iteration:    904: Loss:     0.535145   Batch Accuracy:    0.914 
Iteration:    905: Loss:     0.345508   Batch Accuracy:    0.953 
Iteration:    906: Loss:     0.437057   Batch Accuracy:    0.898 
Iteration:    907: Loss:     0.862769   Batch Accuracy:    0.859 
Iteration:    908: Loss:     0.550559   Batch Accuracy:    0.898 
Iteration:    909: Loss:     0.415844   Batch Accuracy:    0.938 
Iteration:    910: Loss:     0.363215   Batch Accuracy:    0.914 
Iteration:    911: Loss:     1.051040   Batch Accuracy:    0.828 
Iteration:    912: Loss:     0.648157   Batch Accuracy:    0.867 
Iteration:    913: Loss:     1.096566   Batch Accuracy:    0.836 
Iteration:    914: Loss:     0.877633   Batch Accuracy:    0.844 
Iteration:    915: Loss:     0.840947   Batch Accuracy:    0.883 
Iteration:    916: Loss:     0.788320   Batch Accuracy:    0.859 
Iteration:    917: Loss:     0.281484   Batch Accuracy:    0.922 
Iteration:    918: Loss:     0.994571   Batch Accuracy:    0.828 
Iteration:    919: Loss:     0.521181   Batch Accuracy:    0.922 
Iteration:    920: Loss:     0.650388   Batch Accuracy:    0.859 
Iteration:    921: Loss:     0.363968   Batch Accuracy:    0.906 
Iteration:    922: Loss:     0.410983   Batch Accuracy:    0.898 
Iteration:    923: Loss:     0.604393   Batch Accuracy:    0.883 
Iteration:    924: Loss:     0.697604   Batch Accuracy:    0.875 
Iteration:    925: Loss:     0.550418   Batch Accuracy:    0.891 
Iteration:    926: Loss:     0.514818   Batch Accuracy:    0.891 
Iteration:    927: Loss:     0.952957   Batch Accuracy:    0.859 
Iteration:    928: Loss:     0.817423   Batch Accuracy:    0.883 
Iteration:    929: Loss:     0.640566   Batch Accuracy:    0.859 
Iteration:    930: Loss:     0.615758   Batch Accuracy:    0.883 
Iteration:    931: Loss:     0.801005   Batch Accuracy:    0.883 
Iteration:    932: Loss:     0.875806   Batch Accuracy:    0.891 
Iteration:    933: Loss:     0.310311   Batch Accuracy:    0.922 
Iteration:    934: Loss:     0.426394   Batch Accuracy:    0.922 
Iteration:    935: Loss:     0.418670   Batch Accuracy:    0.891 
Iteration:    936: Loss:     0.721958   Batch Accuracy:    0.906 
Iteration:    937: Loss:     0.628138   Batch Accuracy:    0.906 
Iteration:    938: Loss:     0.835035   Batch Accuracy:    0.859 
Iteration:    939: Loss:     0.457770   Batch Accuracy:    0.898 
Iteration:    940: Loss:     0.994827   Batch Accuracy:    0.867 
Iteration:    941: Loss:     0.432590   Batch Accuracy:    0.906 
Iteration:    942: Loss:     0.618883   Batch Accuracy:    0.891 
Iteration:    943: Loss:     0.926978   Batch Accuracy:    0.852 
Iteration:    944: Loss:     0.663417   Batch Accuracy:    0.875 
Iteration:    945: Loss:     0.516003   Batch Accuracy:    0.891 
Iteration:    946: Loss:     0.941227   Batch Accuracy:    0.875 
Iteration:    947: Loss:     0.706793   Batch Accuracy:    0.891 
Iteration:    948: Loss:     0.894486   Batch Accuracy:    0.883 
Iteration:    949: Loss:     0.937447   Batch Accuracy:    0.844 
Iteration:    950: Loss:     1.111663   Batch Accuracy:    0.844 
Iteration:    951: Loss:     0.760230   Batch Accuracy:    0.867 
Iteration:    952: Loss:     1.196207   Batch Accuracy:    0.828 
Iteration:    953: Loss:     0.723020   Batch Accuracy:    0.859 
Iteration:    954: Loss:     0.818889   Batch Accuracy:    0.836 
Iteration:    955: Loss:     0.813540   Batch Accuracy:    0.836 
Iteration:    956: Loss:     0.704512   Batch Accuracy:    0.883 
Iteration:    957: Loss:     0.797188   Batch Accuracy:    0.883 
Iteration:    958: Loss:     0.645693   Batch Accuracy:    0.883 
Iteration:    959: Loss:     0.856429   Batch Accuracy:    0.875 
Iteration:    960: Loss:     0.581514   Batch Accuracy:    0.883 
Iteration:    961: Loss:     0.868380   Batch Accuracy:    0.844 
Iteration:    962: Loss:     0.874950   Batch Accuracy:    0.906 
Iteration:    963: Loss:     0.688336   Batch Accuracy:    0.883 
Iteration:    964: Loss:     0.420154   Batch Accuracy:    0.898 
Iteration:    965: Loss:     0.377583   Batch Accuracy:    0.906 
Iteration:    966: Loss:     0.907860   Batch Accuracy:    0.891 
Iteration:    967: Loss:     0.771257   Batch Accuracy:    0.859 
Iteration:    968: Loss:     1.295845   Batch Accuracy:    0.820 
Iteration:    969: Loss:     0.901430   Batch Accuracy:    0.859 
Iteration:    970: Loss:     0.619899   Batch Accuracy:    0.898 
Iteration:    971: Loss:     0.671155   Batch Accuracy:    0.898 
Iteration:    972: Loss:     0.791430   Batch Accuracy:    0.844 
Iteration:    973: Loss:     0.867866   Batch Accuracy:    0.883 
Iteration:    974: Loss:     0.684866   Batch Accuracy:    0.867 
Iteration:    975: Loss:     0.667201   Batch Accuracy:    0.891 
Iteration:    976: Loss:     0.670053   Batch Accuracy:    0.867 
Iteration:    977: Loss:     0.773216   Batch Accuracy:    0.875 
Iteration:    978: Loss:     0.823938   Batch Accuracy:    0.906 
Iteration:    979: Loss:     0.412590   Batch Accuracy:    0.883 
Iteration:    980: Loss:     0.951553   Batch Accuracy:    0.828 
Iteration:    981: Loss:     0.806848   Batch Accuracy:    0.828 
Iteration:    982: Loss:     0.508720   Batch Accuracy:    0.891 
Iteration:    983: Loss:     0.853523   Batch Accuracy:    0.836 
Iteration:    984: Loss:     0.665730   Batch Accuracy:    0.867 
Iteration:    985: Loss:     0.655091   Batch Accuracy:    0.906 
Iteration:    986: Loss:     0.566258   Batch Accuracy:    0.906 
Iteration:    987: Loss:     0.336665   Batch Accuracy:    0.930 
Iteration:    988: Loss:     0.844891   Batch Accuracy:    0.891 
Iteration:    989: Loss:     0.550474   Batch Accuracy:    0.906 
Iteration:    990: Loss:     0.596459   Batch Accuracy:    0.898 
Iteration:    991: Loss:     0.664186   Batch Accuracy:    0.891 
Iteration:    992: Loss:     0.599620   Batch Accuracy:    0.875 
Iteration:    993: Loss:     0.533312   Batch Accuracy:    0.859 
Iteration:    994: Loss:     0.666263   Batch Accuracy:    0.906 
Iteration:    995: Loss:     0.606685   Batch Accuracy:    0.891 
Iteration:    996: Loss:     0.596506   Batch Accuracy:    0.938 
Iteration:    997: Loss:     0.171228   Batch Accuracy:    0.922 
Iteration:    998: Loss:     0.576479   Batch Accuracy:    0.898 
Iteration:    999: Loss:     0.545984   Batch Accuracy:    0.883 
evaluating model...
training accuracy: 0.898917
test accuracy:     0.898500
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./compile.sh 
-- Configuring done
CMake Warning (dev):
  Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run "cmake
  --help-policy CMP0042" for policy details.  Use the cmake_policy command to
  set the policy and suppress this warning.

  MACOSX_RPATH is not specified for the following targets:

   nn

This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /Users/jasonhoffman/repos/cv576/cse576_sp20_hw3/build
[ 55%] Built target nn
Scanning dependencies of target train
[ 77%] Built target test
[ 88%] Building CXX object CMakeFiles/train.dir/src/train.cpp.o
[100%] Linking CXX executable ../train
[100%] Built target train
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./train
Loading dataset
Parameters: Rate=0.100000
Training model...
Iteration:      0: Loss:     2.305447   Batch Accuracy:    0.094 
Iteration:      1: Loss:     2.204280   Batch Accuracy:    0.164 
Iteration:      2: Loss:     1.993208   Batch Accuracy:    0.391 
Iteration:      3: Loss:     1.930538   Batch Accuracy:    0.312 
Iteration:      4: Loss:     1.676623   Batch Accuracy:    0.484 
Iteration:      5: Loss:     1.402649   Batch Accuracy:    0.602 
Iteration:      6: Loss:     1.164973   Batch Accuracy:    0.758 
Iteration:      7: Loss:     1.005539   Batch Accuracy:    0.789 
Iteration:      8: Loss:     1.045901   Batch Accuracy:    0.672 
Iteration:      9: Loss:     0.836692   Batch Accuracy:    0.820 
Iteration:     10: Loss:     0.735480   Batch Accuracy:    0.828 
Iteration:     11: Loss:     0.713594   Batch Accuracy:    0.797 
Iteration:     12: Loss:     0.671508   Batch Accuracy:    0.805 
Iteration:     13: Loss:     0.654377   Batch Accuracy:    0.789 
Iteration:     14: Loss:     0.728712   Batch Accuracy:    0.773 
Iteration:     15: Loss:     0.460882   Batch Accuracy:    0.883 
Iteration:     16: Loss:     0.618415   Batch Accuracy:    0.766 
Iteration:     17: Loss:     0.608696   Batch Accuracy:    0.789 
Iteration:     18: Loss:     0.635043   Batch Accuracy:    0.797 
Iteration:     19: Loss:     0.550385   Batch Accuracy:    0.820 
Iteration:     20: Loss:     0.392319   Batch Accuracy:    0.891 
Iteration:     21: Loss:     0.502781   Batch Accuracy:    0.828 
Iteration:     22: Loss:     0.375964   Batch Accuracy:    0.922 
Iteration:     23: Loss:     0.562854   Batch Accuracy:    0.836 
Iteration:     24: Loss:     0.514998   Batch Accuracy:    0.844 
Iteration:     25: Loss:     0.534769   Batch Accuracy:    0.859 
Iteration:     26: Loss:     0.533253   Batch Accuracy:    0.844 
Iteration:     27: Loss:     0.658661   Batch Accuracy:    0.797 
Iteration:     28: Loss:     0.389038   Batch Accuracy:    0.852 
Iteration:     29: Loss:     0.482474   Batch Accuracy:    0.867 
Iteration:     30: Loss:     0.495975   Batch Accuracy:    0.836 
Iteration:     31: Loss:     0.400468   Batch Accuracy:    0.875 
Iteration:     32: Loss:     0.415391   Batch Accuracy:    0.875 
Iteration:     33: Loss:     0.237193   Batch Accuracy:    0.930 
Iteration:     34: Loss:     0.478785   Batch Accuracy:    0.844 
Iteration:     35: Loss:     0.356033   Batch Accuracy:    0.859 
Iteration:     36: Loss:     0.415681   Batch Accuracy:    0.875 
Iteration:     37: Loss:     0.536893   Batch Accuracy:    0.820 
Iteration:     38: Loss:     0.328755   Batch Accuracy:    0.844 
Iteration:     39: Loss:     0.284795   Batch Accuracy:    0.906 
Iteration:     40: Loss:     0.467888   Batch Accuracy:    0.875 
Iteration:     41: Loss:     0.366051   Batch Accuracy:    0.891 
Iteration:     42: Loss:     0.501601   Batch Accuracy:    0.852 
Iteration:     43: Loss:     0.324679   Batch Accuracy:    0.883 
Iteration:     44: Loss:     0.631821   Batch Accuracy:    0.812 
Iteration:     45: Loss:     0.393083   Batch Accuracy:    0.891 
Iteration:     46: Loss:     0.360722   Batch Accuracy:    0.883 
Iteration:     47: Loss:     0.442555   Batch Accuracy:    0.898 
Iteration:     48: Loss:     0.546020   Batch Accuracy:    0.852 
Iteration:     49: Loss:     0.584666   Batch Accuracy:    0.828 
Iteration:     50: Loss:     0.422724   Batch Accuracy:    0.859 
Iteration:     51: Loss:     0.419099   Batch Accuracy:    0.875 
Iteration:     52: Loss:     0.475902   Batch Accuracy:    0.891 
Iteration:     53: Loss:     0.415413   Batch Accuracy:    0.859 
Iteration:     54: Loss:     0.305934   Batch Accuracy:    0.898 
Iteration:     55: Loss:     0.435115   Batch Accuracy:    0.867 
Iteration:     56: Loss:     0.472392   Batch Accuracy:    0.867 
Iteration:     57: Loss:     0.325984   Batch Accuracy:    0.914 
Iteration:     58: Loss:     0.336704   Batch Accuracy:    0.922 
Iteration:     59: Loss:     0.360970   Batch Accuracy:    0.906 
Iteration:     60: Loss:     0.492012   Batch Accuracy:    0.836 
Iteration:     61: Loss:     0.370338   Batch Accuracy:    0.906 
Iteration:     62: Loss:     0.668917   Batch Accuracy:    0.852 
Iteration:     63: Loss:     0.380613   Batch Accuracy:    0.883 
Iteration:     64: Loss:     0.393206   Batch Accuracy:    0.875 
Iteration:     65: Loss:     0.502403   Batch Accuracy:    0.852 
Iteration:     66: Loss:     0.424575   Batch Accuracy:    0.883 
Iteration:     67: Loss:     0.366800   Batch Accuracy:    0.891 
Iteration:     68: Loss:     0.526589   Batch Accuracy:    0.836 
Iteration:     69: Loss:     0.564107   Batch Accuracy:    0.836 
Iteration:     70: Loss:     0.517554   Batch Accuracy:    0.844 
Iteration:     71: Loss:     0.442452   Batch Accuracy:    0.875 
Iteration:     72: Loss:     0.543454   Batch Accuracy:    0.875 
Iteration:     73: Loss:     0.374234   Batch Accuracy:    0.891 
Iteration:     74: Loss:     0.342562   Batch Accuracy:    0.906 
Iteration:     75: Loss:     0.287726   Batch Accuracy:    0.914 
Iteration:     76: Loss:     0.490529   Batch Accuracy:    0.875 
Iteration:     77: Loss:     0.315164   Batch Accuracy:    0.930 
Iteration:     78: Loss:     0.382849   Batch Accuracy:    0.914 
Iteration:     79: Loss:     0.559949   Batch Accuracy:    0.898 
Iteration:     80: Loss:     0.387726   Batch Accuracy:    0.875 
Iteration:     81: Loss:     0.346088   Batch Accuracy:    0.898 
Iteration:     82: Loss:     0.243012   Batch Accuracy:    0.938 
Iteration:     83: Loss:     0.320737   Batch Accuracy:    0.914 
Iteration:     84: Loss:     0.425637   Batch Accuracy:    0.859 
Iteration:     85: Loss:     0.322663   Batch Accuracy:    0.906 
Iteration:     86: Loss:     0.432737   Batch Accuracy:    0.891 
Iteration:     87: Loss:     0.341401   Batch Accuracy:    0.867 
Iteration:     88: Loss:     0.495707   Batch Accuracy:    0.852 
Iteration:     89: Loss:     0.294819   Batch Accuracy:    0.930 
Iteration:     90: Loss:     0.354194   Batch Accuracy:    0.898 
Iteration:     91: Loss:     0.494381   Batch Accuracy:    0.867 
Iteration:     92: Loss:     0.265636   Batch Accuracy:    0.914 
Iteration:     93: Loss:     0.479649   Batch Accuracy:    0.875 
Iteration:     94: Loss:     0.429061   Batch Accuracy:    0.875 
Iteration:     95: Loss:     0.282915   Batch Accuracy:    0.922 
Iteration:     96: Loss:     0.368016   Batch Accuracy:    0.891 
Iteration:     97: Loss:     0.345225   Batch Accuracy:    0.883 
Iteration:     98: Loss:     0.402527   Batch Accuracy:    0.844 
Iteration:     99: Loss:     0.210291   Batch Accuracy:    0.938 
Iteration:    100: Loss:     0.324671   Batch Accuracy:    0.867 
Iteration:    101: Loss:     0.422119   Batch Accuracy:    0.883 
Iteration:    102: Loss:     0.268334   Batch Accuracy:    0.938 
Iteration:    103: Loss:     0.409207   Batch Accuracy:    0.875 
Iteration:    104: Loss:     0.315530   Batch Accuracy:    0.898 
Iteration:    105: Loss:     0.401617   Batch Accuracy:    0.867 
Iteration:    106: Loss:     0.419714   Batch Accuracy:    0.844 
Iteration:    107: Loss:     0.371265   Batch Accuracy:    0.906 
Iteration:    108: Loss:     0.407310   Batch Accuracy:    0.859 
Iteration:    109: Loss:     0.321333   Batch Accuracy:    0.914 
Iteration:    110: Loss:     0.378373   Batch Accuracy:    0.906 
Iteration:    111: Loss:     0.294132   Batch Accuracy:    0.922 
Iteration:    112: Loss:     0.398067   Batch Accuracy:    0.898 
Iteration:    113: Loss:     0.329825   Batch Accuracy:    0.891 
Iteration:    114: Loss:     0.277116   Batch Accuracy:    0.930 
Iteration:    115: Loss:     0.368630   Batch Accuracy:    0.875 
Iteration:    116: Loss:     0.349327   Batch Accuracy:    0.891 
Iteration:    117: Loss:     0.320184   Batch Accuracy:    0.891 
Iteration:    118: Loss:     0.335808   Batch Accuracy:    0.906 
Iteration:    119: Loss:     0.342302   Batch Accuracy:    0.883 
Iteration:    120: Loss:     0.433594   Batch Accuracy:    0.859 
Iteration:    121: Loss:     0.438315   Batch Accuracy:    0.867 
Iteration:    122: Loss:     0.337871   Batch Accuracy:    0.891 
Iteration:    123: Loss:     0.365472   Batch Accuracy:    0.898 
Iteration:    124: Loss:     0.458916   Batch Accuracy:    0.859 
Iteration:    125: Loss:     0.350904   Batch Accuracy:    0.930 
Iteration:    126: Loss:     0.246334   Batch Accuracy:    0.914 
Iteration:    127: Loss:     0.439675   Batch Accuracy:    0.859 
Iteration:    128: Loss:     0.319355   Batch Accuracy:    0.914 
Iteration:    129: Loss:     0.308431   Batch Accuracy:    0.898 
Iteration:    130: Loss:     0.408358   Batch Accuracy:    0.875 
Iteration:    131: Loss:     0.403811   Batch Accuracy:    0.891 
Iteration:    132: Loss:     0.334247   Batch Accuracy:    0.961 
Iteration:    133: Loss:     0.388265   Batch Accuracy:    0.898 
Iteration:    134: Loss:     0.399972   Batch Accuracy:    0.875 
Iteration:    135: Loss:     0.200139   Batch Accuracy:    0.938 
Iteration:    136: Loss:     0.411509   Batch Accuracy:    0.891 
Iteration:    137: Loss:     0.446312   Batch Accuracy:    0.875 
Iteration:    138: Loss:     0.335446   Batch Accuracy:    0.906 
Iteration:    139: Loss:     0.329290   Batch Accuracy:    0.891 
Iteration:    140: Loss:     0.358646   Batch Accuracy:    0.898 
Iteration:    141: Loss:     0.285008   Batch Accuracy:    0.898 
Iteration:    142: Loss:     0.365362   Batch Accuracy:    0.922 
Iteration:    143: Loss:     0.332774   Batch Accuracy:    0.922 
Iteration:    144: Loss:     0.347631   Batch Accuracy:    0.906 
Iteration:    145: Loss:     0.328739   Batch Accuracy:    0.883 
Iteration:    146: Loss:     0.404656   Batch Accuracy:    0.883 
Iteration:    147: Loss:     0.331805   Batch Accuracy:    0.930 
Iteration:    148: Loss:     0.336572   Batch Accuracy:    0.875 
Iteration:    149: Loss:     0.295214   Batch Accuracy:    0.906 
Iteration:    150: Loss:     0.436741   Batch Accuracy:    0.883 
Iteration:    151: Loss:     0.322001   Batch Accuracy:    0.938 
Iteration:    152: Loss:     0.339790   Batch Accuracy:    0.891 
Iteration:    153: Loss:     0.367903   Batch Accuracy:    0.898 
Iteration:    154: Loss:     0.363905   Batch Accuracy:    0.898 
Iteration:    155: Loss:     0.440683   Batch Accuracy:    0.883 
Iteration:    156: Loss:     0.247871   Batch Accuracy:    0.930 
Iteration:    157: Loss:     0.255805   Batch Accuracy:    0.898 
Iteration:    158: Loss:     0.298486   Batch Accuracy:    0.906 
Iteration:    159: Loss:     0.354102   Batch Accuracy:    0.883 
Iteration:    160: Loss:     0.279807   Batch Accuracy:    0.930 
Iteration:    161: Loss:     0.368376   Batch Accuracy:    0.891 
Iteration:    162: Loss:     0.464373   Batch Accuracy:    0.852 
Iteration:    163: Loss:     0.284811   Batch Accuracy:    0.930 
Iteration:    164: Loss:     0.333367   Batch Accuracy:    0.898 
Iteration:    165: Loss:     0.283504   Batch Accuracy:    0.922 
Iteration:    166: Loss:     0.341387   Batch Accuracy:    0.891 
Iteration:    167: Loss:     0.408604   Batch Accuracy:    0.867 
Iteration:    168: Loss:     0.368704   Batch Accuracy:    0.891 
Iteration:    169: Loss:     0.257767   Batch Accuracy:    0.938 
Iteration:    170: Loss:     0.290462   Batch Accuracy:    0.922 
Iteration:    171: Loss:     0.472616   Batch Accuracy:    0.867 
Iteration:    172: Loss:     0.504702   Batch Accuracy:    0.852 
Iteration:    173: Loss:     0.445261   Batch Accuracy:    0.906 
Iteration:    174: Loss:     0.430794   Batch Accuracy:    0.883 
Iteration:    175: Loss:     0.247126   Batch Accuracy:    0.953 
Iteration:    176: Loss:     0.337099   Batch Accuracy:    0.914 
Iteration:    177: Loss:     0.315883   Batch Accuracy:    0.914 
Iteration:    178: Loss:     0.287288   Batch Accuracy:    0.914 
Iteration:    179: Loss:     0.296990   Batch Accuracy:    0.914 
Iteration:    180: Loss:     0.225835   Batch Accuracy:    0.914 
Iteration:    181: Loss:     0.368216   Batch Accuracy:    0.891 
Iteration:    182: Loss:     0.419518   Batch Accuracy:    0.891 
Iteration:    183: Loss:     0.252566   Batch Accuracy:    0.914 
Iteration:    184: Loss:     0.427254   Batch Accuracy:    0.859 
Iteration:    185: Loss:     0.268948   Batch Accuracy:    0.930 
Iteration:    186: Loss:     0.379524   Batch Accuracy:    0.906 
Iteration:    187: Loss:     0.353995   Batch Accuracy:    0.891 
Iteration:    188: Loss:     0.356926   Batch Accuracy:    0.906 
Iteration:    189: Loss:     0.290942   Batch Accuracy:    0.922 
Iteration:    190: Loss:     0.419812   Batch Accuracy:    0.898 
Iteration:    191: Loss:     0.182191   Batch Accuracy:    0.898 
Iteration:    192: Loss:     0.366540   Batch Accuracy:    0.914 
Iteration:    193: Loss:     0.365074   Batch Accuracy:    0.914 
Iteration:    194: Loss:     0.337737   Batch Accuracy:    0.906 
Iteration:    195: Loss:     0.254839   Batch Accuracy:    0.891 
Iteration:    196: Loss:     0.292166   Batch Accuracy:    0.898 
Iteration:    197: Loss:     0.281783   Batch Accuracy:    0.922 
Iteration:    198: Loss:     0.315660   Batch Accuracy:    0.883 
Iteration:    199: Loss:     0.513805   Batch Accuracy:    0.844 
Iteration:    200: Loss:     0.304277   Batch Accuracy:    0.922 
Iteration:    201: Loss:     0.392517   Batch Accuracy:    0.867 
Iteration:    202: Loss:     0.386153   Batch Accuracy:    0.891 
Iteration:    203: Loss:     0.371980   Batch Accuracy:    0.875 
Iteration:    204: Loss:     0.391661   Batch Accuracy:    0.875 
Iteration:    205: Loss:     0.315988   Batch Accuracy:    0.883 
Iteration:    206: Loss:     0.251663   Batch Accuracy:    0.930 
Iteration:    207: Loss:     0.247178   Batch Accuracy:    0.938 
Iteration:    208: Loss:     0.367114   Batch Accuracy:    0.891 
Iteration:    209: Loss:     0.241072   Batch Accuracy:    0.914 
Iteration:    210: Loss:     0.422464   Batch Accuracy:    0.914 
Iteration:    211: Loss:     0.298178   Batch Accuracy:    0.922 
Iteration:    212: Loss:     0.241272   Batch Accuracy:    0.930 
Iteration:    213: Loss:     0.246009   Batch Accuracy:    0.922 
Iteration:    214: Loss:     0.358486   Batch Accuracy:    0.891 
Iteration:    215: Loss:     0.368077   Batch Accuracy:    0.906 
Iteration:    216: Loss:     0.321294   Batch Accuracy:    0.906 
Iteration:    217: Loss:     0.287674   Batch Accuracy:    0.945 
Iteration:    218: Loss:     0.327296   Batch Accuracy:    0.875 
Iteration:    219: Loss:     0.401837   Batch Accuracy:    0.883 
Iteration:    220: Loss:     0.403090   Batch Accuracy:    0.906 
Iteration:    221: Loss:     0.213006   Batch Accuracy:    0.969 
Iteration:    222: Loss:     0.295681   Batch Accuracy:    0.906 
Iteration:    223: Loss:     0.659176   Batch Accuracy:    0.891 
Iteration:    224: Loss:     0.366672   Batch Accuracy:    0.883 
Iteration:    225: Loss:     0.361636   Batch Accuracy:    0.891 
Iteration:    226: Loss:     0.569459   Batch Accuracy:    0.805 
Iteration:    227: Loss:     0.445997   Batch Accuracy:    0.914 
Iteration:    228: Loss:     0.299008   Batch Accuracy:    0.914 
Iteration:    229: Loss:     0.273503   Batch Accuracy:    0.898 
Iteration:    230: Loss:     0.250202   Batch Accuracy:    0.906 
Iteration:    231: Loss:     0.304914   Batch Accuracy:    0.938 
Iteration:    232: Loss:     0.237596   Batch Accuracy:    0.906 
Iteration:    233: Loss:     0.307198   Batch Accuracy:    0.898 
Iteration:    234: Loss:     0.105436   Batch Accuracy:    0.977 
Iteration:    235: Loss:     0.373155   Batch Accuracy:    0.898 
Iteration:    236: Loss:     0.266721   Batch Accuracy:    0.906 
Iteration:    237: Loss:     0.305163   Batch Accuracy:    0.930 
Iteration:    238: Loss:     0.454725   Batch Accuracy:    0.883 
Iteration:    239: Loss:     0.360809   Batch Accuracy:    0.914 
Iteration:    240: Loss:     0.255132   Batch Accuracy:    0.930 
Iteration:    241: Loss:     0.229831   Batch Accuracy:    0.938 
Iteration:    242: Loss:     0.239787   Batch Accuracy:    0.898 
Iteration:    243: Loss:     0.237375   Batch Accuracy:    0.938 
Iteration:    244: Loss:     0.387487   Batch Accuracy:    0.914 
Iteration:    245: Loss:     0.327300   Batch Accuracy:    0.938 
Iteration:    246: Loss:     0.317060   Batch Accuracy:    0.938 
Iteration:    247: Loss:     0.316681   Batch Accuracy:    0.930 
Iteration:    248: Loss:     0.326276   Batch Accuracy:    0.914 
Iteration:    249: Loss:     0.231469   Batch Accuracy:    0.930 
Iteration:    250: Loss:     0.270568   Batch Accuracy:    0.906 
Iteration:    251: Loss:     0.319178   Batch Accuracy:    0.906 
Iteration:    252: Loss:     0.478011   Batch Accuracy:    0.883 
Iteration:    253: Loss:     0.335284   Batch Accuracy:    0.906 
Iteration:    254: Loss:     0.385686   Batch Accuracy:    0.859 
Iteration:    255: Loss:     0.326559   Batch Accuracy:    0.930 
Iteration:    256: Loss:     0.326939   Batch Accuracy:    0.914 
Iteration:    257: Loss:     0.272443   Batch Accuracy:    0.914 
Iteration:    258: Loss:     0.349899   Batch Accuracy:    0.914 
Iteration:    259: Loss:     0.282671   Batch Accuracy:    0.891 
Iteration:    260: Loss:     0.416076   Batch Accuracy:    0.898 
Iteration:    261: Loss:     0.434357   Batch Accuracy:    0.891 
Iteration:    262: Loss:     0.411433   Batch Accuracy:    0.914 
Iteration:    263: Loss:     0.310176   Batch Accuracy:    0.898 
Iteration:    264: Loss:     0.433874   Batch Accuracy:    0.898 
Iteration:    265: Loss:     0.377669   Batch Accuracy:    0.883 
Iteration:    266: Loss:     0.332278   Batch Accuracy:    0.906 
Iteration:    267: Loss:     0.299888   Batch Accuracy:    0.906 
Iteration:    268: Loss:     0.202081   Batch Accuracy:    0.961 
Iteration:    269: Loss:     0.185009   Batch Accuracy:    0.953 
Iteration:    270: Loss:     0.341434   Batch Accuracy:    0.930 
Iteration:    271: Loss:     0.315020   Batch Accuracy:    0.914 
Iteration:    272: Loss:     0.258808   Batch Accuracy:    0.938 
Iteration:    273: Loss:     0.343629   Batch Accuracy:    0.922 
Iteration:    274: Loss:     0.416206   Batch Accuracy:    0.875 
Iteration:    275: Loss:     0.374659   Batch Accuracy:    0.867 
Iteration:    276: Loss:     0.394525   Batch Accuracy:    0.891 
Iteration:    277: Loss:     0.530241   Batch Accuracy:    0.859 
Iteration:    278: Loss:     0.333775   Batch Accuracy:    0.906 
Iteration:    279: Loss:     0.335262   Batch Accuracy:    0.930 
Iteration:    280: Loss:     0.444265   Batch Accuracy:    0.875 
Iteration:    281: Loss:     0.303516   Batch Accuracy:    0.914 
Iteration:    282: Loss:     0.340566   Batch Accuracy:    0.891 
Iteration:    283: Loss:     0.395325   Batch Accuracy:    0.898 
Iteration:    284: Loss:     0.356792   Batch Accuracy:    0.867 
Iteration:    285: Loss:     0.223834   Batch Accuracy:    0.914 
Iteration:    286: Loss:     0.341835   Batch Accuracy:    0.891 
Iteration:    287: Loss:     0.438282   Batch Accuracy:    0.883 
Iteration:    288: Loss:     0.278749   Batch Accuracy:    0.914 
Iteration:    289: Loss:     0.433705   Batch Accuracy:    0.875 
Iteration:    290: Loss:     0.248902   Batch Accuracy:    0.906 
Iteration:    291: Loss:     0.401902   Batch Accuracy:    0.914 
Iteration:    292: Loss:     0.258559   Batch Accuracy:    0.945 
Iteration:    293: Loss:     0.295322   Batch Accuracy:    0.914 
Iteration:    294: Loss:     0.527350   Batch Accuracy:    0.867 
Iteration:    295: Loss:     0.341040   Batch Accuracy:    0.914 
Iteration:    296: Loss:     0.297469   Batch Accuracy:    0.914 
Iteration:    297: Loss:     0.301458   Batch Accuracy:    0.930 
Iteration:    298: Loss:     0.334925   Batch Accuracy:    0.914 
Iteration:    299: Loss:     0.330856   Batch Accuracy:    0.898 
Iteration:    300: Loss:     0.261265   Batch Accuracy:    0.922 
Iteration:    301: Loss:     0.300967   Batch Accuracy:    0.930 
Iteration:    302: Loss:     0.208541   Batch Accuracy:    0.914 
Iteration:    303: Loss:     0.338565   Batch Accuracy:    0.891 
Iteration:    304: Loss:     0.324658   Batch Accuracy:    0.914 
Iteration:    305: Loss:     0.262536   Batch Accuracy:    0.930 
Iteration:    306: Loss:     0.179771   Batch Accuracy:    0.930 
Iteration:    307: Loss:     0.311314   Batch Accuracy:    0.906 
Iteration:    308: Loss:     0.417007   Batch Accuracy:    0.852 
Iteration:    309: Loss:     0.385892   Batch Accuracy:    0.875 
Iteration:    310: Loss:     0.502092   Batch Accuracy:    0.836 
Iteration:    311: Loss:     0.217010   Batch Accuracy:    0.938 
Iteration:    312: Loss:     0.332243   Batch Accuracy:    0.875 
Iteration:    313: Loss:     0.230117   Batch Accuracy:    0.938 
Iteration:    314: Loss:     0.374127   Batch Accuracy:    0.906 
Iteration:    315: Loss:     0.261986   Batch Accuracy:    0.922 
Iteration:    316: Loss:     0.277991   Batch Accuracy:    0.930 
Iteration:    317: Loss:     0.373734   Batch Accuracy:    0.898 
Iteration:    318: Loss:     0.511895   Batch Accuracy:    0.859 
Iteration:    319: Loss:     0.339200   Batch Accuracy:    0.922 
Iteration:    320: Loss:     0.425048   Batch Accuracy:    0.906 
Iteration:    321: Loss:     0.508538   Batch Accuracy:    0.875 
Iteration:    322: Loss:     0.206612   Batch Accuracy:    0.914 
Iteration:    323: Loss:     0.194596   Batch Accuracy:    0.938 
Iteration:    324: Loss:     0.306202   Batch Accuracy:    0.906 
Iteration:    325: Loss:     0.265579   Batch Accuracy:    0.938 
Iteration:    326: Loss:     0.384003   Batch Accuracy:    0.914 
Iteration:    327: Loss:     0.343813   Batch Accuracy:    0.922 
Iteration:    328: Loss:     0.263071   Batch Accuracy:    0.938 
Iteration:    329: Loss:     0.447448   Batch Accuracy:    0.852 
Iteration:    330: Loss:     0.120009   Batch Accuracy:    0.984 
Iteration:    331: Loss:     0.139831   Batch Accuracy:    0.969 
Iteration:    332: Loss:     0.469664   Batch Accuracy:    0.875 
Iteration:    333: Loss:     0.281349   Batch Accuracy:    0.898 
Iteration:    334: Loss:     0.485308   Batch Accuracy:    0.859 
Iteration:    335: Loss:     0.226043   Batch Accuracy:    0.938 
Iteration:    336: Loss:     0.189915   Batch Accuracy:    0.945 
Iteration:    337: Loss:     0.309588   Batch Accuracy:    0.922 
Iteration:    338: Loss:     0.324224   Batch Accuracy:    0.898 
Iteration:    339: Loss:     0.354754   Batch Accuracy:    0.914 
Iteration:    340: Loss:     0.294219   Batch Accuracy:    0.906 
Iteration:    341: Loss:     0.293059   Batch Accuracy:    0.930 
Iteration:    342: Loss:     0.283162   Batch Accuracy:    0.922 
Iteration:    343: Loss:     0.284238   Batch Accuracy:    0.922 
Iteration:    344: Loss:     0.338045   Batch Accuracy:    0.898 
Iteration:    345: Loss:     0.370737   Batch Accuracy:    0.898 
Iteration:    346: Loss:     0.219337   Batch Accuracy:    0.938 
Iteration:    347: Loss:     0.242047   Batch Accuracy:    0.906 
Iteration:    348: Loss:     0.443797   Batch Accuracy:    0.883 
Iteration:    349: Loss:     0.412843   Batch Accuracy:    0.891 
Iteration:    350: Loss:     0.209650   Batch Accuracy:    0.945 
Iteration:    351: Loss:     0.311045   Batch Accuracy:    0.906 
Iteration:    352: Loss:     0.278887   Batch Accuracy:    0.930 
Iteration:    353: Loss:     0.466455   Batch Accuracy:    0.875 
Iteration:    354: Loss:     0.348046   Batch Accuracy:    0.914 
Iteration:    355: Loss:     0.399699   Batch Accuracy:    0.906 
Iteration:    356: Loss:     0.280993   Batch Accuracy:    0.914 
Iteration:    357: Loss:     0.340340   Batch Accuracy:    0.914 
Iteration:    358: Loss:     0.236731   Batch Accuracy:    0.945 
Iteration:    359: Loss:     0.228264   Batch Accuracy:    0.922 
Iteration:    360: Loss:     0.330916   Batch Accuracy:    0.891 
Iteration:    361: Loss:     0.326451   Batch Accuracy:    0.906 
Iteration:    362: Loss:     0.331888   Batch Accuracy:    0.922 
Iteration:    363: Loss:     0.402117   Batch Accuracy:    0.906 
Iteration:    364: Loss:     0.237371   Batch Accuracy:    0.930 
Iteration:    365: Loss:     0.374030   Batch Accuracy:    0.867 
Iteration:    366: Loss:     0.470446   Batch Accuracy:    0.891 
Iteration:    367: Loss:     0.322477   Batch Accuracy:    0.922 
Iteration:    368: Loss:     0.335662   Batch Accuracy:    0.906 
Iteration:    369: Loss:     0.451217   Batch Accuracy:    0.883 
Iteration:    370: Loss:     0.251794   Batch Accuracy:    0.961 
Iteration:    371: Loss:     0.289500   Batch Accuracy:    0.938 
Iteration:    372: Loss:     0.381118   Batch Accuracy:    0.891 
Iteration:    373: Loss:     0.279740   Batch Accuracy:    0.906 
Iteration:    374: Loss:     0.285944   Batch Accuracy:    0.930 
Iteration:    375: Loss:     0.273181   Batch Accuracy:    0.938 
Iteration:    376: Loss:     0.183135   Batch Accuracy:    0.945 
Iteration:    377: Loss:     0.275738   Batch Accuracy:    0.922 
Iteration:    378: Loss:     0.240849   Batch Accuracy:    0.938 
Iteration:    379: Loss:     0.268291   Batch Accuracy:    0.914 
Iteration:    380: Loss:     0.304242   Batch Accuracy:    0.891 
Iteration:    381: Loss:     0.328589   Batch Accuracy:    0.906 
Iteration:    382: Loss:     0.352599   Batch Accuracy:    0.914 
Iteration:    383: Loss:     0.288878   Batch Accuracy:    0.898 
Iteration:    384: Loss:     0.304286   Batch Accuracy:    0.906 
Iteration:    385: Loss:     0.229853   Batch Accuracy:    0.922 
Iteration:    386: Loss:     0.339183   Batch Accuracy:    0.875 
Iteration:    387: Loss:     0.237878   Batch Accuracy:    0.945 
Iteration:    388: Loss:     0.467035   Batch Accuracy:    0.859 
Iteration:    389: Loss:     0.411944   Batch Accuracy:    0.891 
Iteration:    390: Loss:     0.345295   Batch Accuracy:    0.898 
Iteration:    391: Loss:     0.294481   Batch Accuracy:    0.930 
Iteration:    392: Loss:     0.316783   Batch Accuracy:    0.914 
Iteration:    393: Loss:     0.303141   Batch Accuracy:    0.906 
Iteration:    394: Loss:     0.419931   Batch Accuracy:    0.914 
Iteration:    395: Loss:     0.343824   Batch Accuracy:    0.906 
Iteration:    396: Loss:     0.199153   Batch Accuracy:    0.953 
Iteration:    397: Loss:     0.375505   Batch Accuracy:    0.891 
Iteration:    398: Loss:     0.414521   Batch Accuracy:    0.867 
Iteration:    399: Loss:     0.491013   Batch Accuracy:    0.883 
Iteration:    400: Loss:     0.310036   Batch Accuracy:    0.930 
Iteration:    401: Loss:     0.243499   Batch Accuracy:    0.914 
Iteration:    402: Loss:     0.337922   Batch Accuracy:    0.930 
Iteration:    403: Loss:     0.299120   Batch Accuracy:    0.914 
Iteration:    404: Loss:     0.246944   Batch Accuracy:    0.953 
Iteration:    405: Loss:     0.239047   Batch Accuracy:    0.914 
Iteration:    406: Loss:     0.398908   Batch Accuracy:    0.930 
Iteration:    407: Loss:     0.233939   Batch Accuracy:    0.930 
Iteration:    408: Loss:     0.386474   Batch Accuracy:    0.891 
Iteration:    409: Loss:     0.229017   Batch Accuracy:    0.914 
Iteration:    410: Loss:     0.297453   Batch Accuracy:    0.914 
Iteration:    411: Loss:     0.295826   Batch Accuracy:    0.922 
Iteration:    412: Loss:     0.337495   Batch Accuracy:    0.914 
Iteration:    413: Loss:     0.265370   Batch Accuracy:    0.930 
Iteration:    414: Loss:     0.201836   Batch Accuracy:    0.945 
Iteration:    415: Loss:     0.295544   Batch Accuracy:    0.898 
Iteration:    416: Loss:     0.260170   Batch Accuracy:    0.914 
Iteration:    417: Loss:     0.336662   Batch Accuracy:    0.859 
Iteration:    418: Loss:     0.546163   Batch Accuracy:    0.891 
Iteration:    419: Loss:     0.390831   Batch Accuracy:    0.883 
Iteration:    420: Loss:     0.498781   Batch Accuracy:    0.883 
Iteration:    421: Loss:     0.315490   Batch Accuracy:    0.883 
Iteration:    422: Loss:     0.318953   Batch Accuracy:    0.898 
Iteration:    423: Loss:     0.262206   Batch Accuracy:    0.930 
Iteration:    424: Loss:     0.410040   Batch Accuracy:    0.883 
Iteration:    425: Loss:     0.236373   Batch Accuracy:    0.914 
Iteration:    426: Loss:     0.338197   Batch Accuracy:    0.891 
Iteration:    427: Loss:     0.344526   Batch Accuracy:    0.922 
Iteration:    428: Loss:     0.257438   Batch Accuracy:    0.945 
Iteration:    429: Loss:     0.228548   Batch Accuracy:    0.945 
Iteration:    430: Loss:     0.290488   Batch Accuracy:    0.930 
Iteration:    431: Loss:     0.357120   Batch Accuracy:    0.945 
Iteration:    432: Loss:     0.384497   Batch Accuracy:    0.867 
Iteration:    433: Loss:     0.262885   Batch Accuracy:    0.922 
Iteration:    434: Loss:     0.275330   Batch Accuracy:    0.914 
Iteration:    435: Loss:     0.250198   Batch Accuracy:    0.953 
Iteration:    436: Loss:     0.245134   Batch Accuracy:    0.938 
Iteration:    437: Loss:     0.242954   Batch Accuracy:    0.938 
Iteration:    438: Loss:     0.435085   Batch Accuracy:    0.867 
Iteration:    439: Loss:     0.276206   Batch Accuracy:    0.891 
Iteration:    440: Loss:     0.226689   Batch Accuracy:    0.938 
Iteration:    441: Loss:     0.296666   Batch Accuracy:    0.938 
Iteration:    442: Loss:     0.272250   Batch Accuracy:    0.938 
Iteration:    443: Loss:     0.413361   Batch Accuracy:    0.883 
Iteration:    444: Loss:     0.210295   Batch Accuracy:    0.969 
Iteration:    445: Loss:     0.243770   Batch Accuracy:    0.930 
Iteration:    446: Loss:     0.297774   Batch Accuracy:    0.922 
Iteration:    447: Loss:     0.352168   Batch Accuracy:    0.883 
Iteration:    448: Loss:     0.187828   Batch Accuracy:    0.938 
Iteration:    449: Loss:     0.259682   Batch Accuracy:    0.930 
Iteration:    450: Loss:     0.369261   Batch Accuracy:    0.883 
Iteration:    451: Loss:     0.241092   Batch Accuracy:    0.945 
Iteration:    452: Loss:     0.335748   Batch Accuracy:    0.867 
Iteration:    453: Loss:     0.224207   Batch Accuracy:    0.930 
Iteration:    454: Loss:     0.377989   Batch Accuracy:    0.883 
Iteration:    455: Loss:     0.445241   Batch Accuracy:    0.891 
Iteration:    456: Loss:     0.259862   Batch Accuracy:    0.922 
Iteration:    457: Loss:     0.168720   Batch Accuracy:    0.938 
Iteration:    458: Loss:     0.400592   Batch Accuracy:    0.891 
Iteration:    459: Loss:     0.217452   Batch Accuracy:    0.930 
Iteration:    460: Loss:     0.189166   Batch Accuracy:    0.969 
Iteration:    461: Loss:     0.545919   Batch Accuracy:    0.875 
Iteration:    462: Loss:     0.436658   Batch Accuracy:    0.891 
Iteration:    463: Loss:     0.325244   Batch Accuracy:    0.891 
Iteration:    464: Loss:     0.183085   Batch Accuracy:    0.961 
Iteration:    465: Loss:     0.430937   Batch Accuracy:    0.844 
Iteration:    466: Loss:     0.187311   Batch Accuracy:    0.945 
Iteration:    467: Loss:     0.359348   Batch Accuracy:    0.883 
Iteration:    468: Loss:     0.376282   Batch Accuracy:    0.852 
Iteration:    469: Loss:     0.219331   Batch Accuracy:    0.914 
Iteration:    470: Loss:     0.414876   Batch Accuracy:    0.859 
Iteration:    471: Loss:     0.331153   Batch Accuracy:    0.914 
Iteration:    472: Loss:     0.277431   Batch Accuracy:    0.906 
Iteration:    473: Loss:     0.277048   Batch Accuracy:    0.906 
Iteration:    474: Loss:     0.432017   Batch Accuracy:    0.891 
Iteration:    475: Loss:     0.282776   Batch Accuracy:    0.945 
Iteration:    476: Loss:     0.325661   Batch Accuracy:    0.914 
Iteration:    477: Loss:     0.368961   Batch Accuracy:    0.898 
Iteration:    478: Loss:     0.363066   Batch Accuracy:    0.891 
Iteration:    479: Loss:     0.381526   Batch Accuracy:    0.898 
Iteration:    480: Loss:     0.364426   Batch Accuracy:    0.875 
Iteration:    481: Loss:     0.446917   Batch Accuracy:    0.906 
Iteration:    482: Loss:     0.283908   Batch Accuracy:    0.945 
Iteration:    483: Loss:     0.234117   Batch Accuracy:    0.930 
Iteration:    484: Loss:     0.333389   Batch Accuracy:    0.906 
Iteration:    485: Loss:     0.262153   Batch Accuracy:    0.898 
Iteration:    486: Loss:     0.219141   Batch Accuracy:    0.953 
Iteration:    487: Loss:     0.304593   Batch Accuracy:    0.883 
Iteration:    488: Loss:     0.288204   Batch Accuracy:    0.922 
Iteration:    489: Loss:     0.331431   Batch Accuracy:    0.906 
Iteration:    490: Loss:     0.265064   Batch Accuracy:    0.922 
Iteration:    491: Loss:     0.271273   Batch Accuracy:    0.906 
Iteration:    492: Loss:     0.280850   Batch Accuracy:    0.906 
Iteration:    493: Loss:     0.344224   Batch Accuracy:    0.898 
Iteration:    494: Loss:     0.243070   Batch Accuracy:    0.930 
Iteration:    495: Loss:     0.354972   Batch Accuracy:    0.883 
Iteration:    496: Loss:     0.490308   Batch Accuracy:    0.867 
Iteration:    497: Loss:     0.270544   Batch Accuracy:    0.922 
Iteration:    498: Loss:     0.207028   Batch Accuracy:    0.938 
Iteration:    499: Loss:     0.250166   Batch Accuracy:    0.922 
Iteration:    500: Loss:     0.346933   Batch Accuracy:    0.922 
Iteration:    501: Loss:     0.264368   Batch Accuracy:    0.938 
Iteration:    502: Loss:     0.315554   Batch Accuracy:    0.930 
Iteration:    503: Loss:     0.647784   Batch Accuracy:    0.859 
Iteration:    504: Loss:     0.247692   Batch Accuracy:    0.930 
Iteration:    505: Loss:     0.441816   Batch Accuracy:    0.883 
Iteration:    506: Loss:     0.427955   Batch Accuracy:    0.852 
Iteration:    507: Loss:     0.235982   Batch Accuracy:    0.930 
Iteration:    508: Loss:     0.155588   Batch Accuracy:    0.945 
Iteration:    509: Loss:     0.391817   Batch Accuracy:    0.914 
Iteration:    510: Loss:     0.397310   Batch Accuracy:    0.867 
Iteration:    511: Loss:     0.398069   Batch Accuracy:    0.852 
Iteration:    512: Loss:     0.207493   Batch Accuracy:    0.930 
Iteration:    513: Loss:     0.275007   Batch Accuracy:    0.922 
Iteration:    514: Loss:     0.211798   Batch Accuracy:    0.930 
Iteration:    515: Loss:     0.229481   Batch Accuracy:    0.938 
Iteration:    516: Loss:     0.273799   Batch Accuracy:    0.922 
Iteration:    517: Loss:     0.181374   Batch Accuracy:    0.938 
Iteration:    518: Loss:     0.298579   Batch Accuracy:    0.930 
Iteration:    519: Loss:     0.246269   Batch Accuracy:    0.938 
Iteration:    520: Loss:     0.255187   Batch Accuracy:    0.945 
Iteration:    521: Loss:     0.416293   Batch Accuracy:    0.898 
Iteration:    522: Loss:     0.319169   Batch Accuracy:    0.898 
Iteration:    523: Loss:     0.251659   Batch Accuracy:    0.922 
Iteration:    524: Loss:     0.494531   Batch Accuracy:    0.883 
Iteration:    525: Loss:     0.300220   Batch Accuracy:    0.930 
Iteration:    526: Loss:     0.246723   Batch Accuracy:    0.922 
Iteration:    527: Loss:     0.342154   Batch Accuracy:    0.883 
Iteration:    528: Loss:     0.277712   Batch Accuracy:    0.930 
Iteration:    529: Loss:     0.241403   Batch Accuracy:    0.914 
Iteration:    530: Loss:     0.291335   Batch Accuracy:    0.930 
Iteration:    531: Loss:     0.281478   Batch Accuracy:    0.914 
Iteration:    532: Loss:     0.266322   Batch Accuracy:    0.914 
Iteration:    533: Loss:     0.252017   Batch Accuracy:    0.930 
Iteration:    534: Loss:     0.387711   Batch Accuracy:    0.883 
Iteration:    535: Loss:     0.221747   Batch Accuracy:    0.906 
Iteration:    536: Loss:     0.345637   Batch Accuracy:    0.914 
Iteration:    537: Loss:     0.270229   Batch Accuracy:    0.953 
Iteration:    538: Loss:     0.536490   Batch Accuracy:    0.859 
Iteration:    539: Loss:     0.367713   Batch Accuracy:    0.867 
Iteration:    540: Loss:     0.382173   Batch Accuracy:    0.867 
Iteration:    541: Loss:     0.224172   Batch Accuracy:    0.914 
Iteration:    542: Loss:     0.496191   Batch Accuracy:    0.891 
Iteration:    543: Loss:     0.301170   Batch Accuracy:    0.906 
Iteration:    544: Loss:     0.200328   Batch Accuracy:    0.930 
Iteration:    545: Loss:     0.205757   Batch Accuracy:    0.945 
Iteration:    546: Loss:     0.359324   Batch Accuracy:    0.914 
Iteration:    547: Loss:     0.255858   Batch Accuracy:    0.922 
Iteration:    548: Loss:     0.360053   Batch Accuracy:    0.867 
Iteration:    549: Loss:     0.321597   Batch Accuracy:    0.914 
Iteration:    550: Loss:     0.287633   Batch Accuracy:    0.930 
Iteration:    551: Loss:     0.388812   Batch Accuracy:    0.891 
Iteration:    552: Loss:     0.159825   Batch Accuracy:    0.961 
Iteration:    553: Loss:     0.339503   Batch Accuracy:    0.906 
Iteration:    554: Loss:     0.473190   Batch Accuracy:    0.867 
Iteration:    555: Loss:     0.302140   Batch Accuracy:    0.922 
Iteration:    556: Loss:     0.366542   Batch Accuracy:    0.914 
Iteration:    557: Loss:     0.242224   Batch Accuracy:    0.930 
Iteration:    558: Loss:     0.602129   Batch Accuracy:    0.898 
Iteration:    559: Loss:     0.227024   Batch Accuracy:    0.922 
Iteration:    560: Loss:     0.212531   Batch Accuracy:    0.914 
Iteration:    561: Loss:     0.218001   Batch Accuracy:    0.945 
Iteration:    562: Loss:     0.337384   Batch Accuracy:    0.898 
Iteration:    563: Loss:     0.450722   Batch Accuracy:    0.875 
Iteration:    564: Loss:     0.347207   Batch Accuracy:    0.898 
Iteration:    565: Loss:     0.224048   Batch Accuracy:    0.922 
Iteration:    566: Loss:     0.359836   Batch Accuracy:    0.875 
Iteration:    567: Loss:     0.272070   Batch Accuracy:    0.914 
Iteration:    568: Loss:     0.382913   Batch Accuracy:    0.922 
Iteration:    569: Loss:     0.413716   Batch Accuracy:    0.938 
Iteration:    570: Loss:     0.316491   Batch Accuracy:    0.930 
Iteration:    571: Loss:     0.307495   Batch Accuracy:    0.914 
Iteration:    572: Loss:     0.219315   Batch Accuracy:    0.930 
Iteration:    573: Loss:     0.193484   Batch Accuracy:    0.945 
Iteration:    574: Loss:     0.421194   Batch Accuracy:    0.906 
Iteration:    575: Loss:     0.265062   Batch Accuracy:    0.891 
Iteration:    576: Loss:     0.466205   Batch Accuracy:    0.914 
Iteration:    577: Loss:     0.355272   Batch Accuracy:    0.875 
Iteration:    578: Loss:     0.339766   Batch Accuracy:    0.906 
Iteration:    579: Loss:     0.243993   Batch Accuracy:    0.945 
Iteration:    580: Loss:     0.301976   Batch Accuracy:    0.914 
Iteration:    581: Loss:     0.202059   Batch Accuracy:    0.953 
Iteration:    582: Loss:     0.279559   Batch Accuracy:    0.930 
Iteration:    583: Loss:     0.234505   Batch Accuracy:    0.922 
Iteration:    584: Loss:     0.398514   Batch Accuracy:    0.898 
Iteration:    585: Loss:     0.179070   Batch Accuracy:    0.938 
Iteration:    586: Loss:     0.203902   Batch Accuracy:    0.945 
Iteration:    587: Loss:     0.251021   Batch Accuracy:    0.922 
Iteration:    588: Loss:     0.197906   Batch Accuracy:    0.922 
Iteration:    589: Loss:     0.223179   Batch Accuracy:    0.938 
Iteration:    590: Loss:     0.465707   Batch Accuracy:    0.867 
Iteration:    591: Loss:     0.185411   Batch Accuracy:    0.930 
Iteration:    592: Loss:     0.210440   Batch Accuracy:    0.945 
Iteration:    593: Loss:     0.232141   Batch Accuracy:    0.930 
Iteration:    594: Loss:     0.473780   Batch Accuracy:    0.875 
Iteration:    595: Loss:     0.286784   Batch Accuracy:    0.914 
Iteration:    596: Loss:     0.250207   Batch Accuracy:    0.922 
Iteration:    597: Loss:     0.522490   Batch Accuracy:    0.867 
Iteration:    598: Loss:     0.268408   Batch Accuracy:    0.922 
Iteration:    599: Loss:     0.346928   Batch Accuracy:    0.898 
Iteration:    600: Loss:     0.244936   Batch Accuracy:    0.922 
Iteration:    601: Loss:     0.256047   Batch Accuracy:    0.898 
Iteration:    602: Loss:     0.376967   Batch Accuracy:    0.859 
Iteration:    603: Loss:     0.354772   Batch Accuracy:    0.914 
Iteration:    604: Loss:     0.228167   Batch Accuracy:    0.930 
Iteration:    605: Loss:     0.246070   Batch Accuracy:    0.930 
Iteration:    606: Loss:     0.280029   Batch Accuracy:    0.891 
Iteration:    607: Loss:     0.255574   Batch Accuracy:    0.898 
Iteration:    608: Loss:     0.325104   Batch Accuracy:    0.898 
Iteration:    609: Loss:     0.336107   Batch Accuracy:    0.898 
Iteration:    610: Loss:     0.293996   Batch Accuracy:    0.922 
Iteration:    611: Loss:     0.291460   Batch Accuracy:    0.898 
Iteration:    612: Loss:     0.342085   Batch Accuracy:    0.898 
Iteration:    613: Loss:     0.402931   Batch Accuracy:    0.922 
Iteration:    614: Loss:     0.201073   Batch Accuracy:    0.938 
Iteration:    615: Loss:     0.276853   Batch Accuracy:    0.922 
Iteration:    616: Loss:     0.310803   Batch Accuracy:    0.914 
Iteration:    617: Loss:     0.432901   Batch Accuracy:    0.875 
Iteration:    618: Loss:     0.241038   Batch Accuracy:    0.938 
Iteration:    619: Loss:     0.286768   Batch Accuracy:    0.891 
Iteration:    620: Loss:     0.318690   Batch Accuracy:    0.914 
Iteration:    621: Loss:     0.166111   Batch Accuracy:    0.961 
Iteration:    622: Loss:     0.390250   Batch Accuracy:    0.883 
Iteration:    623: Loss:     0.306214   Batch Accuracy:    0.906 
Iteration:    624: Loss:     0.551105   Batch Accuracy:    0.891 
Iteration:    625: Loss:     0.246229   Batch Accuracy:    0.922 
Iteration:    626: Loss:     0.468052   Batch Accuracy:    0.867 
Iteration:    627: Loss:     0.291322   Batch Accuracy:    0.930 
Iteration:    628: Loss:     0.275904   Batch Accuracy:    0.906 
Iteration:    629: Loss:     0.189164   Batch Accuracy:    0.930 
Iteration:    630: Loss:     0.266985   Batch Accuracy:    0.914 
Iteration:    631: Loss:     0.241510   Batch Accuracy:    0.906 
Iteration:    632: Loss:     0.399746   Batch Accuracy:    0.938 
Iteration:    633: Loss:     0.307743   Batch Accuracy:    0.922 
Iteration:    634: Loss:     0.300647   Batch Accuracy:    0.922 
Iteration:    635: Loss:     0.317231   Batch Accuracy:    0.922 
Iteration:    636: Loss:     0.232338   Batch Accuracy:    0.953 
Iteration:    637: Loss:     0.219667   Batch Accuracy:    0.953 
Iteration:    638: Loss:     0.237606   Batch Accuracy:    0.945 
Iteration:    639: Loss:     0.199157   Batch Accuracy:    0.930 
Iteration:    640: Loss:     0.281222   Batch Accuracy:    0.906 
Iteration:    641: Loss:     0.248650   Batch Accuracy:    0.938 
Iteration:    642: Loss:     0.255787   Batch Accuracy:    0.891 
Iteration:    643: Loss:     0.266679   Batch Accuracy:    0.906 
Iteration:    644: Loss:     0.201849   Batch Accuracy:    0.930 
Iteration:    645: Loss:     0.328626   Batch Accuracy:    0.914 
Iteration:    646: Loss:     0.207581   Batch Accuracy:    0.930 
Iteration:    647: Loss:     0.370794   Batch Accuracy:    0.922 
Iteration:    648: Loss:     0.283265   Batch Accuracy:    0.938 
Iteration:    649: Loss:     0.315386   Batch Accuracy:    0.930 
Iteration:    650: Loss:     0.363977   Batch Accuracy:    0.891 
Iteration:    651: Loss:     0.371230   Batch Accuracy:    0.875 
Iteration:    652: Loss:     0.332993   Batch Accuracy:    0.898 
Iteration:    653: Loss:     0.398056   Batch Accuracy:    0.898 
Iteration:    654: Loss:     0.324464   Batch Accuracy:    0.922 
Iteration:    655: Loss:     0.243386   Batch Accuracy:    0.914 
Iteration:    656: Loss:     0.363812   Batch Accuracy:    0.891 
Iteration:    657: Loss:     0.321456   Batch Accuracy:    0.906 
Iteration:    658: Loss:     0.225178   Batch Accuracy:    0.930 
Iteration:    659: Loss:     0.340583   Batch Accuracy:    0.891 
Iteration:    660: Loss:     0.223408   Batch Accuracy:    0.930 
Iteration:    661: Loss:     0.256730   Batch Accuracy:    0.930 
Iteration:    662: Loss:     0.267354   Batch Accuracy:    0.922 
Iteration:    663: Loss:     0.190908   Batch Accuracy:    0.953 
Iteration:    664: Loss:     0.351747   Batch Accuracy:    0.914 
Iteration:    665: Loss:     0.339300   Batch Accuracy:    0.914 
Iteration:    666: Loss:     0.353059   Batch Accuracy:    0.898 
Iteration:    667: Loss:     0.352639   Batch Accuracy:    0.891 
Iteration:    668: Loss:     0.259781   Batch Accuracy:    0.906 
Iteration:    669: Loss:     0.316972   Batch Accuracy:    0.930 
Iteration:    670: Loss:     0.403559   Batch Accuracy:    0.891 
Iteration:    671: Loss:     0.229334   Batch Accuracy:    0.938 
Iteration:    672: Loss:     0.534736   Batch Accuracy:    0.875 
Iteration:    673: Loss:     0.281357   Batch Accuracy:    0.930 
Iteration:    674: Loss:     0.362305   Batch Accuracy:    0.891 
Iteration:    675: Loss:     0.204500   Batch Accuracy:    0.945 
Iteration:    676: Loss:     0.266004   Batch Accuracy:    0.914 
Iteration:    677: Loss:     0.312146   Batch Accuracy:    0.906 
Iteration:    678: Loss:     0.167559   Batch Accuracy:    0.953 
Iteration:    679: Loss:     0.226169   Batch Accuracy:    0.938 
Iteration:    680: Loss:     0.262472   Batch Accuracy:    0.922 
Iteration:    681: Loss:     0.228175   Batch Accuracy:    0.938 
Iteration:    682: Loss:     0.439743   Batch Accuracy:    0.906 
Iteration:    683: Loss:     0.224717   Batch Accuracy:    0.930 
Iteration:    684: Loss:     0.351058   Batch Accuracy:    0.906 
Iteration:    685: Loss:     0.298783   Batch Accuracy:    0.922 
Iteration:    686: Loss:     0.469422   Batch Accuracy:    0.898 
Iteration:    687: Loss:     0.354413   Batch Accuracy:    0.906 
Iteration:    688: Loss:     0.389884   Batch Accuracy:    0.891 
Iteration:    689: Loss:     0.384466   Batch Accuracy:    0.898 
Iteration:    690: Loss:     0.379154   Batch Accuracy:    0.930 
Iteration:    691: Loss:     0.430991   Batch Accuracy:    0.883 
Iteration:    692: Loss:     0.241011   Batch Accuracy:    0.953 
Iteration:    693: Loss:     0.435276   Batch Accuracy:    0.852 
Iteration:    694: Loss:     0.350688   Batch Accuracy:    0.898 
Iteration:    695: Loss:     0.329607   Batch Accuracy:    0.906 
Iteration:    696: Loss:     0.267996   Batch Accuracy:    0.922 
Iteration:    697: Loss:     0.220074   Batch Accuracy:    0.938 
Iteration:    698: Loss:     0.310898   Batch Accuracy:    0.922 
Iteration:    699: Loss:     0.366489   Batch Accuracy:    0.883 
Iteration:    700: Loss:     0.310235   Batch Accuracy:    0.914 
Iteration:    701: Loss:     0.191406   Batch Accuracy:    0.969 
Iteration:    702: Loss:     0.460701   Batch Accuracy:    0.891 
Iteration:    703: Loss:     0.281839   Batch Accuracy:    0.922 
Iteration:    704: Loss:     0.304751   Batch Accuracy:    0.898 
Iteration:    705: Loss:     0.302566   Batch Accuracy:    0.906 
Iteration:    706: Loss:     0.499677   Batch Accuracy:    0.875 
Iteration:    707: Loss:     0.192077   Batch Accuracy:    0.961 
Iteration:    708: Loss:     0.368832   Batch Accuracy:    0.914 
Iteration:    709: Loss:     0.205141   Batch Accuracy:    0.938 
Iteration:    710: Loss:     0.267963   Batch Accuracy:    0.898 
Iteration:    711: Loss:     0.299879   Batch Accuracy:    0.922 
Iteration:    712: Loss:     0.342416   Batch Accuracy:    0.891 
Iteration:    713: Loss:     0.382905   Batch Accuracy:    0.891 
Iteration:    714: Loss:     0.218896   Batch Accuracy:    0.922 
Iteration:    715: Loss:     0.266502   Batch Accuracy:    0.945 
Iteration:    716: Loss:     0.384826   Batch Accuracy:    0.906 
Iteration:    717: Loss:     0.213090   Batch Accuracy:    0.945 
Iteration:    718: Loss:     0.247726   Batch Accuracy:    0.930 
Iteration:    719: Loss:     0.205884   Batch Accuracy:    0.922 
Iteration:    720: Loss:     0.328063   Batch Accuracy:    0.922 
Iteration:    721: Loss:     0.281767   Batch Accuracy:    0.938 
Iteration:    722: Loss:     0.255093   Batch Accuracy:    0.953 
Iteration:    723: Loss:     0.234575   Batch Accuracy:    0.930 
Iteration:    724: Loss:     0.439376   Batch Accuracy:    0.914 
Iteration:    725: Loss:     0.269840   Batch Accuracy:    0.922 
Iteration:    726: Loss:     0.293312   Batch Accuracy:    0.938 
Iteration:    727: Loss:     0.225930   Batch Accuracy:    0.969 
Iteration:    728: Loss:     0.224964   Batch Accuracy:    0.953 
Iteration:    729: Loss:     0.335462   Batch Accuracy:    0.914 
Iteration:    730: Loss:     0.361952   Batch Accuracy:    0.883 
Iteration:    731: Loss:     0.160731   Batch Accuracy:    0.961 
Iteration:    732: Loss:     0.199689   Batch Accuracy:    0.938 
Iteration:    733: Loss:     0.502841   Batch Accuracy:    0.906 
Iteration:    734: Loss:     0.216626   Batch Accuracy:    0.914 
Iteration:    735: Loss:     0.324272   Batch Accuracy:    0.930 
Iteration:    736: Loss:     0.284000   Batch Accuracy:    0.930 
Iteration:    737: Loss:     0.162901   Batch Accuracy:    0.969 
Iteration:    738: Loss:     0.266258   Batch Accuracy:    0.953 
Iteration:    739: Loss:     0.297701   Batch Accuracy:    0.906 
Iteration:    740: Loss:     0.275741   Batch Accuracy:    0.922 
Iteration:    741: Loss:     0.353281   Batch Accuracy:    0.898 
Iteration:    742: Loss:     0.189844   Batch Accuracy:    0.938 
Iteration:    743: Loss:     0.137827   Batch Accuracy:    0.953 
Iteration:    744: Loss:     0.235213   Batch Accuracy:    0.930 
Iteration:    745: Loss:     0.301758   Batch Accuracy:    0.922 
Iteration:    746: Loss:     0.196993   Batch Accuracy:    0.945 
Iteration:    747: Loss:     0.244588   Batch Accuracy:    0.922 
Iteration:    748: Loss:     0.181038   Batch Accuracy:    0.945 
Iteration:    749: Loss:     0.232453   Batch Accuracy:    0.945 
Iteration:    750: Loss:     0.330040   Batch Accuracy:    0.922 
Iteration:    751: Loss:     0.232338   Batch Accuracy:    0.922 
Iteration:    752: Loss:     0.257147   Batch Accuracy:    0.938 
Iteration:    753: Loss:     0.386814   Batch Accuracy:    0.891 
Iteration:    754: Loss:     0.310011   Batch Accuracy:    0.898 
Iteration:    755: Loss:     0.319373   Batch Accuracy:    0.938 
Iteration:    756: Loss:     0.384409   Batch Accuracy:    0.875 
Iteration:    757: Loss:     0.247944   Batch Accuracy:    0.930 
Iteration:    758: Loss:     0.231930   Batch Accuracy:    0.922 
Iteration:    759: Loss:     0.387537   Batch Accuracy:    0.922 
Iteration:    760: Loss:     0.206550   Batch Accuracy:    0.953 
Iteration:    761: Loss:     0.275319   Batch Accuracy:    0.953 
Iteration:    762: Loss:     0.236840   Batch Accuracy:    0.906 
Iteration:    763: Loss:     0.293040   Batch Accuracy:    0.883 
Iteration:    764: Loss:     0.444993   Batch Accuracy:    0.859 
Iteration:    765: Loss:     0.357228   Batch Accuracy:    0.891 
Iteration:    766: Loss:     0.311632   Batch Accuracy:    0.906 
Iteration:    767: Loss:     0.195628   Batch Accuracy:    0.930 
Iteration:    768: Loss:     0.440236   Batch Accuracy:    0.914 
Iteration:    769: Loss:     0.370687   Batch Accuracy:    0.914 
Iteration:    770: Loss:     0.312192   Batch Accuracy:    0.906 
Iteration:    771: Loss:     0.210029   Batch Accuracy:    0.922 
Iteration:    772: Loss:     0.422641   Batch Accuracy:    0.914 
Iteration:    773: Loss:     0.390417   Batch Accuracy:    0.891 
Iteration:    774: Loss:     0.479096   Batch Accuracy:    0.914 
Iteration:    775: Loss:     0.285128   Batch Accuracy:    0.930 
Iteration:    776: Loss:     0.531617   Batch Accuracy:    0.898 
Iteration:    777: Loss:     0.194839   Batch Accuracy:    0.953 
Iteration:    778: Loss:     0.245868   Batch Accuracy:    0.953 
Iteration:    779: Loss:     0.248475   Batch Accuracy:    0.922 
Iteration:    780: Loss:     0.372365   Batch Accuracy:    0.844 
Iteration:    781: Loss:     0.231941   Batch Accuracy:    0.914 
Iteration:    782: Loss:     0.375445   Batch Accuracy:    0.922 
Iteration:    783: Loss:     0.295307   Batch Accuracy:    0.938 
Iteration:    784: Loss:     0.162241   Batch Accuracy:    0.938 
Iteration:    785: Loss:     0.307858   Batch Accuracy:    0.938 
Iteration:    786: Loss:     0.242623   Batch Accuracy:    0.953 
Iteration:    787: Loss:     0.334173   Batch Accuracy:    0.922 
Iteration:    788: Loss:     0.252036   Batch Accuracy:    0.922 
Iteration:    789: Loss:     0.289877   Batch Accuracy:    0.914 
Iteration:    790: Loss:     0.341459   Batch Accuracy:    0.906 
Iteration:    791: Loss:     0.253952   Batch Accuracy:    0.906 
Iteration:    792: Loss:     0.331302   Batch Accuracy:    0.906 
Iteration:    793: Loss:     0.338149   Batch Accuracy:    0.898 
Iteration:    794: Loss:     0.399796   Batch Accuracy:    0.906 
Iteration:    795: Loss:     0.126982   Batch Accuracy:    0.969 
Iteration:    796: Loss:     0.265476   Batch Accuracy:    0.945 
Iteration:    797: Loss:     0.371294   Batch Accuracy:    0.930 
Iteration:    798: Loss:     0.421158   Batch Accuracy:    0.875 
Iteration:    799: Loss:     0.291847   Batch Accuracy:    0.906 
Iteration:    800: Loss:     0.241670   Batch Accuracy:    0.945 
Iteration:    801: Loss:     0.269227   Batch Accuracy:    0.922 
Iteration:    802: Loss:     0.298881   Batch Accuracy:    0.914 
Iteration:    803: Loss:     0.242494   Batch Accuracy:    0.906 
Iteration:    804: Loss:     0.277423   Batch Accuracy:    0.906 
Iteration:    805: Loss:     0.292238   Batch Accuracy:    0.906 
Iteration:    806: Loss:     0.306407   Batch Accuracy:    0.867 
Iteration:    807: Loss:     0.560963   Batch Accuracy:    0.883 
Iteration:    808: Loss:     0.187188   Batch Accuracy:    0.938 
Iteration:    809: Loss:     0.261586   Batch Accuracy:    0.922 
Iteration:    810: Loss:     0.211779   Batch Accuracy:    0.945 
Iteration:    811: Loss:     0.300686   Batch Accuracy:    0.883 
Iteration:    812: Loss:     0.399477   Batch Accuracy:    0.883 
Iteration:    813: Loss:     0.251670   Batch Accuracy:    0.938 
Iteration:    814: Loss:     0.401142   Batch Accuracy:    0.898 
Iteration:    815: Loss:     0.417655   Batch Accuracy:    0.914 
Iteration:    816: Loss:     0.406593   Batch Accuracy:    0.914 
Iteration:    817: Loss:     0.312775   Batch Accuracy:    0.875 
Iteration:    818: Loss:     0.286253   Batch Accuracy:    0.914 
Iteration:    819: Loss:     0.232602   Batch Accuracy:    0.922 
Iteration:    820: Loss:     0.267956   Batch Accuracy:    0.906 
Iteration:    821: Loss:     0.299142   Batch Accuracy:    0.938 
Iteration:    822: Loss:     0.295116   Batch Accuracy:    0.922 
Iteration:    823: Loss:     0.256372   Batch Accuracy:    0.914 
Iteration:    824: Loss:     0.436488   Batch Accuracy:    0.898 
Iteration:    825: Loss:     0.372978   Batch Accuracy:    0.922 
Iteration:    826: Loss:     0.308257   Batch Accuracy:    0.938 
Iteration:    827: Loss:     0.314715   Batch Accuracy:    0.922 
Iteration:    828: Loss:     0.414948   Batch Accuracy:    0.898 
Iteration:    829: Loss:     0.334873   Batch Accuracy:    0.898 
Iteration:    830: Loss:     0.368601   Batch Accuracy:    0.898 
Iteration:    831: Loss:     0.271003   Batch Accuracy:    0.906 
Iteration:    832: Loss:     0.403631   Batch Accuracy:    0.898 
Iteration:    833: Loss:     0.313034   Batch Accuracy:    0.891 
Iteration:    834: Loss:     0.334534   Batch Accuracy:    0.922 
Iteration:    835: Loss:     0.296963   Batch Accuracy:    0.906 
Iteration:    836: Loss:     0.339921   Batch Accuracy:    0.891 
Iteration:    837: Loss:     0.227247   Batch Accuracy:    0.938 
Iteration:    838: Loss:     0.318038   Batch Accuracy:    0.938 
Iteration:    839: Loss:     0.327740   Batch Accuracy:    0.930 
Iteration:    840: Loss:     0.242187   Batch Accuracy:    0.922 
Iteration:    841: Loss:     0.286107   Batch Accuracy:    0.898 
Iteration:    842: Loss:     0.343995   Batch Accuracy:    0.906 
Iteration:    843: Loss:     0.400559   Batch Accuracy:    0.883 
Iteration:    844: Loss:     0.335536   Batch Accuracy:    0.906 
Iteration:    845: Loss:     0.212476   Batch Accuracy:    0.922 
Iteration:    846: Loss:     0.224418   Batch Accuracy:    0.914 
Iteration:    847: Loss:     0.255333   Batch Accuracy:    0.914 
Iteration:    848: Loss:     0.324786   Batch Accuracy:    0.914 
Iteration:    849: Loss:     0.262004   Batch Accuracy:    0.938 
Iteration:    850: Loss:     0.297165   Batch Accuracy:    0.945 
Iteration:    851: Loss:     0.208197   Batch Accuracy:    0.953 
Iteration:    852: Loss:     0.219771   Batch Accuracy:    0.922 
Iteration:    853: Loss:     0.232381   Batch Accuracy:    0.922 
Iteration:    854: Loss:     0.271016   Batch Accuracy:    0.922 
Iteration:    855: Loss:     0.429398   Batch Accuracy:    0.906 
Iteration:    856: Loss:     0.356571   Batch Accuracy:    0.898 
Iteration:    857: Loss:     0.326502   Batch Accuracy:    0.883 
Iteration:    858: Loss:     0.327953   Batch Accuracy:    0.875 
Iteration:    859: Loss:     0.363143   Batch Accuracy:    0.914 
Iteration:    860: Loss:     0.354473   Batch Accuracy:    0.898 
Iteration:    861: Loss:     0.218320   Batch Accuracy:    0.938 
Iteration:    862: Loss:     0.281358   Batch Accuracy:    0.945 
Iteration:    863: Loss:     0.377285   Batch Accuracy:    0.883 
Iteration:    864: Loss:     0.266307   Batch Accuracy:    0.961 
Iteration:    865: Loss:     0.258735   Batch Accuracy:    0.930 
Iteration:    866: Loss:     0.299381   Batch Accuracy:    0.906 
Iteration:    867: Loss:     0.268774   Batch Accuracy:    0.906 
Iteration:    868: Loss:     0.365282   Batch Accuracy:    0.922 
Iteration:    869: Loss:     0.350981   Batch Accuracy:    0.875 
Iteration:    870: Loss:     0.205500   Batch Accuracy:    0.938 
Iteration:    871: Loss:     0.277937   Batch Accuracy:    0.914 
Iteration:    872: Loss:     0.347414   Batch Accuracy:    0.930 
Iteration:    873: Loss:     0.293907   Batch Accuracy:    0.922 
Iteration:    874: Loss:     0.271746   Batch Accuracy:    0.914 
Iteration:    875: Loss:     0.202145   Batch Accuracy:    0.922 
Iteration:    876: Loss:     0.203030   Batch Accuracy:    0.898 
Iteration:    877: Loss:     0.456542   Batch Accuracy:    0.875 
Iteration:    878: Loss:     0.229409   Batch Accuracy:    0.930 
Iteration:    879: Loss:     0.371151   Batch Accuracy:    0.898 
Iteration:    880: Loss:     0.333207   Batch Accuracy:    0.938 
Iteration:    881: Loss:     0.540575   Batch Accuracy:    0.867 
Iteration:    882: Loss:     0.234691   Batch Accuracy:    0.922 
Iteration:    883: Loss:     0.320899   Batch Accuracy:    0.938 
Iteration:    884: Loss:     0.277430   Batch Accuracy:    0.906 
Iteration:    885: Loss:     0.297282   Batch Accuracy:    0.945 
Iteration:    886: Loss:     0.380335   Batch Accuracy:    0.914 
Iteration:    887: Loss:     0.183161   Batch Accuracy:    0.938 
Iteration:    888: Loss:     0.293823   Batch Accuracy:    0.922 
Iteration:    889: Loss:     0.253205   Batch Accuracy:    0.938 
Iteration:    890: Loss:     0.230752   Batch Accuracy:    0.930 
Iteration:    891: Loss:     0.230933   Batch Accuracy:    0.945 
Iteration:    892: Loss:     0.295022   Batch Accuracy:    0.914 
Iteration:    893: Loss:     0.360282   Batch Accuracy:    0.922 
Iteration:    894: Loss:     0.292790   Batch Accuracy:    0.906 
Iteration:    895: Loss:     0.231088   Batch Accuracy:    0.930 
Iteration:    896: Loss:     0.349403   Batch Accuracy:    0.914 
Iteration:    897: Loss:     0.187654   Batch Accuracy:    0.945 
Iteration:    898: Loss:     0.358225   Batch Accuracy:    0.898 
Iteration:    899: Loss:     0.250625   Batch Accuracy:    0.945 
Iteration:    900: Loss:     0.247758   Batch Accuracy:    0.883 
Iteration:    901: Loss:     0.201442   Batch Accuracy:    0.945 
Iteration:    902: Loss:     0.274070   Batch Accuracy:    0.938 
Iteration:    903: Loss:     0.274652   Batch Accuracy:    0.883 
Iteration:    904: Loss:     0.254727   Batch Accuracy:    0.922 
Iteration:    905: Loss:     0.202058   Batch Accuracy:    0.961 
Iteration:    906: Loss:     0.203543   Batch Accuracy:    0.938 
Iteration:    907: Loss:     0.344003   Batch Accuracy:    0.898 
Iteration:    908: Loss:     0.250836   Batch Accuracy:    0.938 
Iteration:    909: Loss:     0.248842   Batch Accuracy:    0.945 
Iteration:    910: Loss:     0.167125   Batch Accuracy:    0.969 
Iteration:    911: Loss:     0.216636   Batch Accuracy:    0.953 
Iteration:    912: Loss:     0.273146   Batch Accuracy:    0.930 
Iteration:    913: Loss:     0.466774   Batch Accuracy:    0.875 
Iteration:    914: Loss:     0.348231   Batch Accuracy:    0.891 
Iteration:    915: Loss:     0.350078   Batch Accuracy:    0.898 
Iteration:    916: Loss:     0.249530   Batch Accuracy:    0.922 
Iteration:    917: Loss:     0.197348   Batch Accuracy:    0.938 
Iteration:    918: Loss:     0.227468   Batch Accuracy:    0.922 
Iteration:    919: Loss:     0.173528   Batch Accuracy:    0.953 
Iteration:    920: Loss:     0.336646   Batch Accuracy:    0.883 
Iteration:    921: Loss:     0.169355   Batch Accuracy:    0.938 
Iteration:    922: Loss:     0.189482   Batch Accuracy:    0.930 
Iteration:    923: Loss:     0.252845   Batch Accuracy:    0.914 
Iteration:    924: Loss:     0.344669   Batch Accuracy:    0.906 
Iteration:    925: Loss:     0.317343   Batch Accuracy:    0.914 
Iteration:    926: Loss:     0.300449   Batch Accuracy:    0.914 
Iteration:    927: Loss:     0.384746   Batch Accuracy:    0.922 
Iteration:    928: Loss:     0.427089   Batch Accuracy:    0.852 
Iteration:    929: Loss:     0.362004   Batch Accuracy:    0.891 
Iteration:    930: Loss:     0.300443   Batch Accuracy:    0.906 
Iteration:    931: Loss:     0.402526   Batch Accuracy:    0.883 
Iteration:    932: Loss:     0.320943   Batch Accuracy:    0.922 
Iteration:    933: Loss:     0.213317   Batch Accuracy:    0.938 
Iteration:    934: Loss:     0.315175   Batch Accuracy:    0.883 
Iteration:    935: Loss:     0.183715   Batch Accuracy:    0.938 
Iteration:    936: Loss:     0.359447   Batch Accuracy:    0.930 
Iteration:    937: Loss:     0.287713   Batch Accuracy:    0.914 
Iteration:    938: Loss:     0.434757   Batch Accuracy:    0.906 
Iteration:    939: Loss:     0.312287   Batch Accuracy:    0.906 
Iteration:    940: Loss:     0.340572   Batch Accuracy:    0.891 
Iteration:    941: Loss:     0.189556   Batch Accuracy:    0.938 
Iteration:    942: Loss:     0.268245   Batch Accuracy:    0.906 
Iteration:    943: Loss:     0.307727   Batch Accuracy:    0.891 
Iteration:    944: Loss:     0.285237   Batch Accuracy:    0.914 
Iteration:    945: Loss:     0.288248   Batch Accuracy:    0.906 
Iteration:    946: Loss:     0.348142   Batch Accuracy:    0.875 
Iteration:    947: Loss:     0.183342   Batch Accuracy:    0.953 
Iteration:    948: Loss:     0.366959   Batch Accuracy:    0.906 
Iteration:    949: Loss:     0.445239   Batch Accuracy:    0.875 
Iteration:    950: Loss:     0.382829   Batch Accuracy:    0.914 
Iteration:    951: Loss:     0.246580   Batch Accuracy:    0.898 
Iteration:    952: Loss:     0.202110   Batch Accuracy:    0.938 
Iteration:    953: Loss:     0.332404   Batch Accuracy:    0.906 
Iteration:    954: Loss:     0.340512   Batch Accuracy:    0.898 
Iteration:    955: Loss:     0.407306   Batch Accuracy:    0.891 
Iteration:    956: Loss:     0.407828   Batch Accuracy:    0.883 
Iteration:    957: Loss:     0.364960   Batch Accuracy:    0.906 
Iteration:    958: Loss:     0.230014   Batch Accuracy:    0.938 
Iteration:    959: Loss:     0.360446   Batch Accuracy:    0.922 
Iteration:    960: Loss:     0.184647   Batch Accuracy:    0.945 
Iteration:    961: Loss:     0.362344   Batch Accuracy:    0.883 
Iteration:    962: Loss:     0.267523   Batch Accuracy:    0.930 
Iteration:    963: Loss:     0.313394   Batch Accuracy:    0.922 
Iteration:    964: Loss:     0.195798   Batch Accuracy:    0.914 
Iteration:    965: Loss:     0.265897   Batch Accuracy:    0.914 
Iteration:    966: Loss:     0.358011   Batch Accuracy:    0.922 
Iteration:    967: Loss:     0.297989   Batch Accuracy:    0.938 
Iteration:    968: Loss:     0.518324   Batch Accuracy:    0.852 
Iteration:    969: Loss:     0.419957   Batch Accuracy:    0.891 
Iteration:    970: Loss:     0.310862   Batch Accuracy:    0.922 
Iteration:    971: Loss:     0.331862   Batch Accuracy:    0.914 
Iteration:    972: Loss:     0.340391   Batch Accuracy:    0.914 
Iteration:    973: Loss:     0.319611   Batch Accuracy:    0.906 
Iteration:    974: Loss:     0.344472   Batch Accuracy:    0.898 
Iteration:    975: Loss:     0.345854   Batch Accuracy:    0.906 
Iteration:    976: Loss:     0.277323   Batch Accuracy:    0.930 
Iteration:    977: Loss:     0.316878   Batch Accuracy:    0.922 
Iteration:    978: Loss:     0.358543   Batch Accuracy:    0.906 
Iteration:    979: Loss:     0.213485   Batch Accuracy:    0.922 
Iteration:    980: Loss:     0.326719   Batch Accuracy:    0.883 
Iteration:    981: Loss:     0.279827   Batch Accuracy:    0.898 
Iteration:    982: Loss:     0.190085   Batch Accuracy:    0.914 
Iteration:    983: Loss:     0.400585   Batch Accuracy:    0.844 
Iteration:    984: Loss:     0.261581   Batch Accuracy:    0.945 
Iteration:    985: Loss:     0.362022   Batch Accuracy:    0.898 
Iteration:    986: Loss:     0.234993   Batch Accuracy:    0.938 
Iteration:    987: Loss:     0.241845   Batch Accuracy:    0.930 
Iteration:    988: Loss:     0.352845   Batch Accuracy:    0.930 
Iteration:    989: Loss:     0.300119   Batch Accuracy:    0.922 
Iteration:    990: Loss:     0.313792   Batch Accuracy:    0.898 
Iteration:    991: Loss:     0.376343   Batch Accuracy:    0.891 
Iteration:    992: Loss:     0.255303   Batch Accuracy:    0.938 
Iteration:    993: Loss:     0.262900   Batch Accuracy:    0.883 
Iteration:    994: Loss:     0.311866   Batch Accuracy:    0.906 
Iteration:    995: Loss:     0.257373   Batch Accuracy:    0.930 
Iteration:    996: Loss:     0.333581   Batch Accuracy:    0.938 
Iteration:    997: Loss:     0.158902   Batch Accuracy:    0.961 
Iteration:    998: Loss:     0.251365   Batch Accuracy:    0.898 
Iteration:    999: Loss:     0.299483   Batch Accuracy:    0.898 
evaluating model...
training accuracy: 0.916550
test accuracy:     0.917400
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./compile.sh 
-- Configuring done
CMake Warning (dev):
  Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run "cmake
  --help-policy CMP0042" for policy details.  Use the cmake_policy command to
  set the policy and suppress this warning.

  MACOSX_RPATH is not specified for the following targets:

   nn

This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /Users/jasonhoffman/repos/cv576/cse576_sp20_hw3/build
[ 55%] Built target nn
Scanning dependencies of target train
[ 77%] Built target test
[ 88%] Building CXX object CMakeFiles/train.dir/src/train.cpp.o
[100%] Linking CXX executable ../train
[100%] Built target train
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./train
Loading dataset
Parameters: Rate=0.010000
Training model...
Iteration:      0: Loss:     2.305447   Batch Accuracy:    0.094 
Iteration:      1: Loss:     2.312885   Batch Accuracy:    0.047 
Iteration:      2: Loss:     2.288629   Batch Accuracy:    0.117 
Iteration:      3: Loss:     2.277914   Batch Accuracy:    0.109 
Iteration:      4: Loss:     2.205979   Batch Accuracy:    0.156 
Iteration:      5: Loss:     2.181271   Batch Accuracy:    0.195 
Iteration:      6: Loss:     2.132293   Batch Accuracy:    0.297 
Iteration:      7: Loss:     2.083115   Batch Accuracy:    0.367 
Iteration:      8: Loss:     2.022332   Batch Accuracy:    0.383 
Iteration:      9: Loss:     1.986233   Batch Accuracy:    0.430 
Iteration:     10: Loss:     1.929137   Batch Accuracy:    0.422 
Iteration:     11: Loss:     1.865869   Batch Accuracy:    0.453 
Iteration:     12: Loss:     1.825265   Batch Accuracy:    0.555 
Iteration:     13: Loss:     1.801974   Batch Accuracy:    0.492 
Iteration:     14: Loss:     1.715767   Batch Accuracy:    0.578 
Iteration:     15: Loss:     1.598987   Batch Accuracy:    0.711 
Iteration:     16: Loss:     1.533111   Batch Accuracy:    0.742 
Iteration:     17: Loss:     1.578413   Batch Accuracy:    0.680 
Iteration:     18: Loss:     1.548540   Batch Accuracy:    0.680 
Iteration:     19: Loss:     1.500443   Batch Accuracy:    0.719 
Iteration:     20: Loss:     1.398893   Batch Accuracy:    0.797 
Iteration:     21: Loss:     1.313986   Batch Accuracy:    0.727 
Iteration:     22: Loss:     1.228117   Batch Accuracy:    0.766 
Iteration:     23: Loss:     1.336982   Batch Accuracy:    0.766 
Iteration:     24: Loss:     1.306732   Batch Accuracy:    0.734 
Iteration:     25: Loss:     1.268805   Batch Accuracy:    0.727 
Iteration:     26: Loss:     1.114982   Batch Accuracy:    0.781 
Iteration:     27: Loss:     1.214090   Batch Accuracy:    0.750 
Iteration:     28: Loss:     1.081687   Batch Accuracy:    0.781 
Iteration:     29: Loss:     1.065684   Batch Accuracy:    0.766 
Iteration:     30: Loss:     1.073326   Batch Accuracy:    0.742 
Iteration:     31: Loss:     1.012687   Batch Accuracy:    0.789 
Iteration:     32: Loss:     1.021062   Batch Accuracy:    0.781 
Iteration:     33: Loss:     0.916445   Batch Accuracy:    0.828 
Iteration:     34: Loss:     0.977361   Batch Accuracy:    0.742 
Iteration:     35: Loss:     0.926220   Batch Accuracy:    0.820 
Iteration:     36: Loss:     0.946078   Batch Accuracy:    0.781 
Iteration:     37: Loss:     0.949531   Batch Accuracy:    0.797 
Iteration:     38: Loss:     0.842609   Batch Accuracy:    0.844 
Iteration:     39: Loss:     0.890660   Batch Accuracy:    0.812 
Iteration:     40: Loss:     0.946475   Batch Accuracy:    0.805 
Iteration:     41: Loss:     0.872257   Batch Accuracy:    0.797 
Iteration:     42: Loss:     0.933221   Batch Accuracy:    0.734 
Iteration:     43: Loss:     0.791373   Batch Accuracy:    0.859 
Iteration:     44: Loss:     0.975238   Batch Accuracy:    0.773 
Iteration:     45: Loss:     0.820331   Batch Accuracy:    0.836 
Iteration:     46: Loss:     0.783941   Batch Accuracy:    0.812 
Iteration:     47: Loss:     0.854890   Batch Accuracy:    0.797 
Iteration:     48: Loss:     0.862059   Batch Accuracy:    0.773 
Iteration:     49: Loss:     0.900260   Batch Accuracy:    0.773 
Iteration:     50: Loss:     0.896435   Batch Accuracy:    0.766 
Iteration:     51: Loss:     0.751762   Batch Accuracy:    0.820 
Iteration:     52: Loss:     0.761615   Batch Accuracy:    0.836 
Iteration:     53: Loss:     0.788631   Batch Accuracy:    0.820 
Iteration:     54: Loss:     0.762458   Batch Accuracy:    0.805 
Iteration:     55: Loss:     0.761292   Batch Accuracy:    0.852 
Iteration:     56: Loss:     0.766755   Batch Accuracy:    0.812 
Iteration:     57: Loss:     0.706284   Batch Accuracy:    0.836 
Iteration:     58: Loss:     0.697706   Batch Accuracy:    0.875 
Iteration:     59: Loss:     0.708254   Batch Accuracy:    0.844 
Iteration:     60: Loss:     0.884744   Batch Accuracy:    0.805 
Iteration:     61: Loss:     0.677417   Batch Accuracy:    0.867 
Iteration:     62: Loss:     0.873406   Batch Accuracy:    0.766 
Iteration:     63: Loss:     0.732811   Batch Accuracy:    0.844 
Iteration:     64: Loss:     0.717891   Batch Accuracy:    0.859 
Iteration:     65: Loss:     0.850188   Batch Accuracy:    0.812 
Iteration:     66: Loss:     0.720047   Batch Accuracy:    0.852 
Iteration:     67: Loss:     0.665109   Batch Accuracy:    0.883 
Iteration:     68: Loss:     0.726727   Batch Accuracy:    0.812 
Iteration:     69: Loss:     0.782462   Batch Accuracy:    0.820 
Iteration:     70: Loss:     0.798580   Batch Accuracy:    0.805 
Iteration:     71: Loss:     0.706837   Batch Accuracy:    0.805 
Iteration:     72: Loss:     0.825092   Batch Accuracy:    0.773 
Iteration:     73: Loss:     0.637983   Batch Accuracy:    0.797 
Iteration:     74: Loss:     0.599104   Batch Accuracy:    0.867 
Iteration:     75: Loss:     0.595619   Batch Accuracy:    0.898 
Iteration:     76: Loss:     0.697830   Batch Accuracy:    0.836 
Iteration:     77: Loss:     0.636599   Batch Accuracy:    0.875 
Iteration:     78: Loss:     0.625662   Batch Accuracy:    0.852 
Iteration:     79: Loss:     0.714174   Batch Accuracy:    0.820 
Iteration:     80: Loss:     0.637682   Batch Accuracy:    0.852 
Iteration:     81: Loss:     0.662699   Batch Accuracy:    0.844 
Iteration:     82: Loss:     0.593937   Batch Accuracy:    0.914 
Iteration:     83: Loss:     0.630150   Batch Accuracy:    0.844 
Iteration:     84: Loss:     0.626952   Batch Accuracy:    0.844 
Iteration:     85: Loss:     0.560647   Batch Accuracy:    0.867 
Iteration:     86: Loss:     0.678083   Batch Accuracy:    0.812 
Iteration:     87: Loss:     0.594675   Batch Accuracy:    0.852 
Iteration:     88: Loss:     0.685303   Batch Accuracy:    0.828 
Iteration:     89: Loss:     0.549566   Batch Accuracy:    0.883 
Iteration:     90: Loss:     0.632413   Batch Accuracy:    0.859 
Iteration:     91: Loss:     0.736367   Batch Accuracy:    0.789 
Iteration:     92: Loss:     0.514290   Batch Accuracy:    0.883 
Iteration:     93: Loss:     0.733145   Batch Accuracy:    0.789 
Iteration:     94: Loss:     0.699182   Batch Accuracy:    0.820 
Iteration:     95: Loss:     0.519610   Batch Accuracy:    0.906 
Iteration:     96: Loss:     0.670903   Batch Accuracy:    0.852 
Iteration:     97: Loss:     0.607403   Batch Accuracy:    0.852 
Iteration:     98: Loss:     0.657640   Batch Accuracy:    0.773 
Iteration:     99: Loss:     0.513714   Batch Accuracy:    0.867 
Iteration:    100: Loss:     0.528230   Batch Accuracy:    0.859 
Iteration:    101: Loss:     0.635868   Batch Accuracy:    0.852 
Iteration:    102: Loss:     0.512873   Batch Accuracy:    0.875 
Iteration:    103: Loss:     0.615968   Batch Accuracy:    0.852 
Iteration:    104: Loss:     0.557722   Batch Accuracy:    0.867 
Iteration:    105: Loss:     0.591128   Batch Accuracy:    0.805 
Iteration:    106: Loss:     0.644620   Batch Accuracy:    0.820 
Iteration:    107: Loss:     0.656488   Batch Accuracy:    0.836 
Iteration:    108: Loss:     0.668268   Batch Accuracy:    0.789 
Iteration:    109: Loss:     0.577840   Batch Accuracy:    0.859 
Iteration:    110: Loss:     0.632731   Batch Accuracy:    0.836 
Iteration:    111: Loss:     0.548849   Batch Accuracy:    0.859 
Iteration:    112: Loss:     0.669541   Batch Accuracy:    0.820 
Iteration:    113: Loss:     0.591102   Batch Accuracy:    0.852 
Iteration:    114: Loss:     0.522295   Batch Accuracy:    0.891 
Iteration:    115: Loss:     0.577880   Batch Accuracy:    0.883 
Iteration:    116: Loss:     0.546453   Batch Accuracy:    0.867 
Iteration:    117: Loss:     0.535340   Batch Accuracy:    0.852 
Iteration:    118: Loss:     0.578386   Batch Accuracy:    0.828 
Iteration:    119: Loss:     0.567301   Batch Accuracy:    0.844 
Iteration:    120: Loss:     0.605654   Batch Accuracy:    0.828 
Iteration:    121: Loss:     0.612160   Batch Accuracy:    0.859 
Iteration:    122: Loss:     0.528236   Batch Accuracy:    0.844 
Iteration:    123: Loss:     0.576620   Batch Accuracy:    0.844 
Iteration:    124: Loss:     0.706692   Batch Accuracy:    0.789 
Iteration:    125: Loss:     0.532307   Batch Accuracy:    0.906 
Iteration:    126: Loss:     0.493185   Batch Accuracy:    0.891 
Iteration:    127: Loss:     0.569636   Batch Accuracy:    0.859 
Iteration:    128: Loss:     0.511471   Batch Accuracy:    0.914 
Iteration:    129: Loss:     0.500992   Batch Accuracy:    0.891 
Iteration:    130: Loss:     0.593138   Batch Accuracy:    0.852 
Iteration:    131: Loss:     0.587722   Batch Accuracy:    0.820 
Iteration:    132: Loss:     0.503703   Batch Accuracy:    0.891 
Iteration:    133: Loss:     0.522661   Batch Accuracy:    0.898 
Iteration:    134: Loss:     0.632600   Batch Accuracy:    0.812 
Iteration:    135: Loss:     0.457085   Batch Accuracy:    0.883 
Iteration:    136: Loss:     0.593033   Batch Accuracy:    0.859 
Iteration:    137: Loss:     0.654840   Batch Accuracy:    0.797 
Iteration:    138: Loss:     0.573796   Batch Accuracy:    0.844 
Iteration:    139: Loss:     0.614316   Batch Accuracy:    0.828 
Iteration:    140: Loss:     0.541797   Batch Accuracy:    0.883 
Iteration:    141: Loss:     0.541498   Batch Accuracy:    0.875 
Iteration:    142: Loss:     0.497511   Batch Accuracy:    0.922 
Iteration:    143: Loss:     0.508338   Batch Accuracy:    0.875 
Iteration:    144: Loss:     0.543020   Batch Accuracy:    0.891 
Iteration:    145: Loss:     0.544659   Batch Accuracy:    0.883 
Iteration:    146: Loss:     0.580920   Batch Accuracy:    0.836 
Iteration:    147: Loss:     0.511924   Batch Accuracy:    0.867 
Iteration:    148: Loss:     0.544021   Batch Accuracy:    0.852 
Iteration:    149: Loss:     0.524089   Batch Accuracy:    0.867 
Iteration:    150: Loss:     0.626664   Batch Accuracy:    0.836 
Iteration:    151: Loss:     0.533428   Batch Accuracy:    0.883 
Iteration:    152: Loss:     0.484948   Batch Accuracy:    0.875 
Iteration:    153: Loss:     0.561455   Batch Accuracy:    0.836 
Iteration:    154: Loss:     0.498616   Batch Accuracy:    0.875 
Iteration:    155: Loss:     0.610498   Batch Accuracy:    0.852 
Iteration:    156: Loss:     0.447903   Batch Accuracy:    0.930 
Iteration:    157: Loss:     0.420174   Batch Accuracy:    0.914 
Iteration:    158: Loss:     0.500811   Batch Accuracy:    0.852 
Iteration:    159: Loss:     0.536904   Batch Accuracy:    0.859 
Iteration:    160: Loss:     0.491264   Batch Accuracy:    0.906 
Iteration:    161: Loss:     0.595553   Batch Accuracy:    0.828 
Iteration:    162: Loss:     0.612130   Batch Accuracy:    0.844 
Iteration:    163: Loss:     0.525592   Batch Accuracy:    0.852 
Iteration:    164: Loss:     0.467993   Batch Accuracy:    0.891 
Iteration:    165: Loss:     0.503241   Batch Accuracy:    0.852 
Iteration:    166: Loss:     0.543267   Batch Accuracy:    0.859 
Iteration:    167: Loss:     0.542572   Batch Accuracy:    0.844 
Iteration:    168: Loss:     0.497353   Batch Accuracy:    0.875 
Iteration:    169: Loss:     0.455275   Batch Accuracy:    0.906 
Iteration:    170: Loss:     0.461122   Batch Accuracy:    0.891 
Iteration:    171: Loss:     0.588328   Batch Accuracy:    0.828 
Iteration:    172: Loss:     0.637441   Batch Accuracy:    0.844 
Iteration:    173: Loss:     0.595052   Batch Accuracy:    0.852 
Iteration:    174: Loss:     0.584508   Batch Accuracy:    0.836 
Iteration:    175: Loss:     0.453014   Batch Accuracy:    0.906 
Iteration:    176: Loss:     0.499164   Batch Accuracy:    0.875 
Iteration:    177: Loss:     0.554013   Batch Accuracy:    0.859 
Iteration:    178: Loss:     0.425104   Batch Accuracy:    0.898 
Iteration:    179: Loss:     0.512024   Batch Accuracy:    0.867 
Iteration:    180: Loss:     0.419407   Batch Accuracy:    0.875 
Iteration:    181: Loss:     0.520151   Batch Accuracy:    0.898 
Iteration:    182: Loss:     0.507504   Batch Accuracy:    0.906 
Iteration:    183: Loss:     0.406010   Batch Accuracy:    0.906 
Iteration:    184: Loss:     0.578882   Batch Accuracy:    0.805 
Iteration:    185: Loss:     0.420160   Batch Accuracy:    0.867 
Iteration:    186: Loss:     0.535590   Batch Accuracy:    0.875 
Iteration:    187: Loss:     0.546675   Batch Accuracy:    0.852 
Iteration:    188: Loss:     0.481977   Batch Accuracy:    0.883 
Iteration:    189: Loss:     0.441713   Batch Accuracy:    0.891 
Iteration:    190: Loss:     0.544515   Batch Accuracy:    0.859 
Iteration:    191: Loss:     0.377247   Batch Accuracy:    0.883 
Iteration:    192: Loss:     0.433610   Batch Accuracy:    0.898 
Iteration:    193: Loss:     0.529263   Batch Accuracy:    0.883 
Iteration:    194: Loss:     0.462038   Batch Accuracy:    0.867 
Iteration:    195: Loss:     0.456403   Batch Accuracy:    0.883 
Iteration:    196: Loss:     0.441631   Batch Accuracy:    0.883 
Iteration:    197: Loss:     0.422717   Batch Accuracy:    0.922 
Iteration:    198: Loss:     0.470748   Batch Accuracy:    0.867 
Iteration:    199: Loss:     0.618792   Batch Accuracy:    0.812 
Iteration:    200: Loss:     0.442768   Batch Accuracy:    0.914 
Iteration:    201: Loss:     0.536858   Batch Accuracy:    0.852 
Iteration:    202: Loss:     0.548781   Batch Accuracy:    0.859 
Iteration:    203: Loss:     0.515046   Batch Accuracy:    0.844 
Iteration:    204: Loss:     0.599522   Batch Accuracy:    0.844 
Iteration:    205: Loss:     0.435575   Batch Accuracy:    0.891 
Iteration:    206: Loss:     0.376387   Batch Accuracy:    0.914 
Iteration:    207: Loss:     0.364812   Batch Accuracy:    0.930 
Iteration:    208: Loss:     0.507405   Batch Accuracy:    0.859 
Iteration:    209: Loss:     0.367927   Batch Accuracy:    0.891 
Iteration:    210: Loss:     0.513912   Batch Accuracy:    0.859 
Iteration:    211: Loss:     0.466493   Batch Accuracy:    0.875 
Iteration:    212: Loss:     0.448635   Batch Accuracy:    0.883 
Iteration:    213: Loss:     0.485384   Batch Accuracy:    0.875 
Iteration:    214: Loss:     0.501184   Batch Accuracy:    0.859 
Iteration:    215: Loss:     0.464958   Batch Accuracy:    0.891 
Iteration:    216: Loss:     0.535641   Batch Accuracy:    0.875 
Iteration:    217: Loss:     0.389930   Batch Accuracy:    0.922 
Iteration:    218: Loss:     0.465661   Batch Accuracy:    0.875 
Iteration:    219: Loss:     0.505671   Batch Accuracy:    0.875 
Iteration:    220: Loss:     0.511498   Batch Accuracy:    0.883 
Iteration:    221: Loss:     0.355503   Batch Accuracy:    0.961 
Iteration:    222: Loss:     0.429105   Batch Accuracy:    0.898 
Iteration:    223: Loss:     0.648741   Batch Accuracy:    0.859 
Iteration:    224: Loss:     0.579164   Batch Accuracy:    0.828 
Iteration:    225: Loss:     0.466482   Batch Accuracy:    0.875 
Iteration:    226: Loss:     0.648917   Batch Accuracy:    0.797 
Iteration:    227: Loss:     0.574844   Batch Accuracy:    0.867 
Iteration:    228: Loss:     0.454141   Batch Accuracy:    0.875 
Iteration:    229: Loss:     0.416591   Batch Accuracy:    0.906 
Iteration:    230: Loss:     0.424970   Batch Accuracy:    0.891 
Iteration:    231: Loss:     0.404584   Batch Accuracy:    0.922 
Iteration:    232: Loss:     0.372842   Batch Accuracy:    0.906 
Iteration:    233: Loss:     0.518569   Batch Accuracy:    0.875 
Iteration:    234: Loss:     0.281161   Batch Accuracy:    0.961 
Iteration:    235: Loss:     0.491916   Batch Accuracy:    0.883 
Iteration:    236: Loss:     0.368737   Batch Accuracy:    0.906 
Iteration:    237: Loss:     0.431375   Batch Accuracy:    0.883 
Iteration:    238: Loss:     0.545423   Batch Accuracy:    0.859 
Iteration:    239: Loss:     0.542440   Batch Accuracy:    0.867 
Iteration:    240: Loss:     0.427345   Batch Accuracy:    0.906 
Iteration:    241: Loss:     0.427842   Batch Accuracy:    0.898 
Iteration:    242: Loss:     0.371293   Batch Accuracy:    0.906 
Iteration:    243: Loss:     0.392303   Batch Accuracy:    0.891 
Iteration:    244: Loss:     0.469950   Batch Accuracy:    0.891 
Iteration:    245: Loss:     0.474238   Batch Accuracy:    0.875 
Iteration:    246: Loss:     0.471805   Batch Accuracy:    0.906 
Iteration:    247: Loss:     0.420157   Batch Accuracy:    0.898 
Iteration:    248: Loss:     0.467152   Batch Accuracy:    0.891 
Iteration:    249: Loss:     0.368297   Batch Accuracy:    0.898 
Iteration:    250: Loss:     0.444158   Batch Accuracy:    0.867 
Iteration:    251: Loss:     0.462444   Batch Accuracy:    0.883 
Iteration:    252: Loss:     0.577724   Batch Accuracy:    0.852 
Iteration:    253: Loss:     0.477602   Batch Accuracy:    0.883 
Iteration:    254: Loss:     0.529226   Batch Accuracy:    0.836 
Iteration:    255: Loss:     0.476641   Batch Accuracy:    0.875 
Iteration:    256: Loss:     0.447708   Batch Accuracy:    0.922 
Iteration:    257: Loss:     0.439873   Batch Accuracy:    0.883 
Iteration:    258: Loss:     0.499774   Batch Accuracy:    0.867 
Iteration:    259: Loss:     0.418692   Batch Accuracy:    0.914 
Iteration:    260: Loss:     0.504439   Batch Accuracy:    0.859 
Iteration:    261: Loss:     0.522274   Batch Accuracy:    0.883 
Iteration:    262: Loss:     0.512696   Batch Accuracy:    0.867 
Iteration:    263: Loss:     0.442473   Batch Accuracy:    0.891 
Iteration:    264: Loss:     0.555867   Batch Accuracy:    0.859 
Iteration:    265: Loss:     0.565542   Batch Accuracy:    0.852 
Iteration:    266: Loss:     0.434612   Batch Accuracy:    0.875 
Iteration:    267: Loss:     0.401264   Batch Accuracy:    0.891 
Iteration:    268: Loss:     0.407107   Batch Accuracy:    0.914 
Iteration:    269: Loss:     0.368468   Batch Accuracy:    0.906 
Iteration:    270: Loss:     0.463016   Batch Accuracy:    0.883 
Iteration:    271: Loss:     0.454066   Batch Accuracy:    0.859 
Iteration:    272: Loss:     0.431391   Batch Accuracy:    0.898 
Iteration:    273: Loss:     0.433900   Batch Accuracy:    0.914 
Iteration:    274: Loss:     0.523524   Batch Accuracy:    0.844 
Iteration:    275: Loss:     0.509503   Batch Accuracy:    0.859 
Iteration:    276: Loss:     0.501362   Batch Accuracy:    0.883 
Iteration:    277: Loss:     0.631232   Batch Accuracy:    0.828 
Iteration:    278: Loss:     0.444968   Batch Accuracy:    0.883 
Iteration:    279: Loss:     0.427986   Batch Accuracy:    0.930 
Iteration:    280: Loss:     0.546301   Batch Accuracy:    0.859 
Iteration:    281: Loss:     0.418403   Batch Accuracy:    0.906 
Iteration:    282: Loss:     0.497979   Batch Accuracy:    0.836 
Iteration:    283: Loss:     0.527462   Batch Accuracy:    0.859 
Iteration:    284: Loss:     0.507076   Batch Accuracy:    0.859 
Iteration:    285: Loss:     0.368265   Batch Accuracy:    0.898 
Iteration:    286: Loss:     0.444366   Batch Accuracy:    0.891 
Iteration:    287: Loss:     0.474471   Batch Accuracy:    0.875 
Iteration:    288: Loss:     0.468952   Batch Accuracy:    0.883 
Iteration:    289: Loss:     0.621141   Batch Accuracy:    0.828 
Iteration:    290: Loss:     0.393593   Batch Accuracy:    0.914 
Iteration:    291: Loss:     0.514137   Batch Accuracy:    0.867 
Iteration:    292: Loss:     0.386429   Batch Accuracy:    0.898 
Iteration:    293: Loss:     0.376326   Batch Accuracy:    0.906 
Iteration:    294: Loss:     0.549033   Batch Accuracy:    0.828 
Iteration:    295: Loss:     0.490666   Batch Accuracy:    0.867 
Iteration:    296: Loss:     0.432731   Batch Accuracy:    0.891 
Iteration:    297: Loss:     0.437082   Batch Accuracy:    0.883 
Iteration:    298: Loss:     0.434241   Batch Accuracy:    0.883 
Iteration:    299: Loss:     0.484833   Batch Accuracy:    0.859 
Iteration:    300: Loss:     0.428255   Batch Accuracy:    0.875 
Iteration:    301: Loss:     0.422688   Batch Accuracy:    0.906 
Iteration:    302: Loss:     0.361354   Batch Accuracy:    0.859 
Iteration:    303: Loss:     0.494511   Batch Accuracy:    0.883 
Iteration:    304: Loss:     0.478630   Batch Accuracy:    0.859 
Iteration:    305: Loss:     0.398940   Batch Accuracy:    0.914 
Iteration:    306: Loss:     0.261292   Batch Accuracy:    0.938 
Iteration:    307: Loss:     0.409957   Batch Accuracy:    0.875 
Iteration:    308: Loss:     0.529424   Batch Accuracy:    0.836 
Iteration:    309: Loss:     0.417469   Batch Accuracy:    0.859 
Iteration:    310: Loss:     0.525010   Batch Accuracy:    0.844 
Iteration:    311: Loss:     0.392678   Batch Accuracy:    0.859 
Iteration:    312: Loss:     0.374691   Batch Accuracy:    0.922 
Iteration:    313: Loss:     0.380268   Batch Accuracy:    0.906 
Iteration:    314: Loss:     0.484288   Batch Accuracy:    0.859 
Iteration:    315: Loss:     0.444255   Batch Accuracy:    0.875 
Iteration:    316: Loss:     0.379808   Batch Accuracy:    0.914 
Iteration:    317: Loss:     0.429718   Batch Accuracy:    0.883 
Iteration:    318: Loss:     0.559161   Batch Accuracy:    0.844 
Iteration:    319: Loss:     0.456838   Batch Accuracy:    0.891 
Iteration:    320: Loss:     0.506246   Batch Accuracy:    0.906 
Iteration:    321: Loss:     0.624437   Batch Accuracy:    0.812 
Iteration:    322: Loss:     0.367374   Batch Accuracy:    0.914 
Iteration:    323: Loss:     0.322857   Batch Accuracy:    0.930 
Iteration:    324: Loss:     0.452610   Batch Accuracy:    0.891 
Iteration:    325: Loss:     0.359155   Batch Accuracy:    0.938 
Iteration:    326: Loss:     0.467001   Batch Accuracy:    0.883 
Iteration:    327: Loss:     0.417854   Batch Accuracy:    0.914 
Iteration:    328: Loss:     0.382474   Batch Accuracy:    0.891 
Iteration:    329: Loss:     0.574933   Batch Accuracy:    0.836 
Iteration:    330: Loss:     0.250477   Batch Accuracy:    0.977 
Iteration:    331: Loss:     0.311368   Batch Accuracy:    0.938 
Iteration:    332: Loss:     0.489835   Batch Accuracy:    0.859 
Iteration:    333: Loss:     0.381057   Batch Accuracy:    0.891 
Iteration:    334: Loss:     0.604630   Batch Accuracy:    0.828 
Iteration:    335: Loss:     0.324734   Batch Accuracy:    0.922 
Iteration:    336: Loss:     0.306905   Batch Accuracy:    0.930 
Iteration:    337: Loss:     0.420106   Batch Accuracy:    0.875 
Iteration:    338: Loss:     0.422659   Batch Accuracy:    0.875 
Iteration:    339: Loss:     0.493360   Batch Accuracy:    0.891 
Iteration:    340: Loss:     0.389631   Batch Accuracy:    0.898 
Iteration:    341: Loss:     0.416336   Batch Accuracy:    0.898 
Iteration:    342: Loss:     0.404890   Batch Accuracy:    0.883 
Iteration:    343: Loss:     0.400645   Batch Accuracy:    0.922 
Iteration:    344: Loss:     0.425441   Batch Accuracy:    0.891 
Iteration:    345: Loss:     0.493806   Batch Accuracy:    0.867 
Iteration:    346: Loss:     0.364000   Batch Accuracy:    0.930 
Iteration:    347: Loss:     0.408929   Batch Accuracy:    0.883 
Iteration:    348: Loss:     0.550505   Batch Accuracy:    0.836 
Iteration:    349: Loss:     0.523485   Batch Accuracy:    0.852 
Iteration:    350: Loss:     0.336766   Batch Accuracy:    0.945 
Iteration:    351: Loss:     0.389589   Batch Accuracy:    0.914 
Iteration:    352: Loss:     0.371387   Batch Accuracy:    0.922 
Iteration:    353: Loss:     0.552347   Batch Accuracy:    0.859 
Iteration:    354: Loss:     0.420086   Batch Accuracy:    0.898 
Iteration:    355: Loss:     0.470715   Batch Accuracy:    0.891 
Iteration:    356: Loss:     0.386730   Batch Accuracy:    0.883 
Iteration:    357: Loss:     0.470594   Batch Accuracy:    0.859 
Iteration:    358: Loss:     0.354329   Batch Accuracy:    0.906 
Iteration:    359: Loss:     0.337543   Batch Accuracy:    0.898 
Iteration:    360: Loss:     0.479242   Batch Accuracy:    0.859 
Iteration:    361: Loss:     0.444089   Batch Accuracy:    0.914 
Iteration:    362: Loss:     0.453748   Batch Accuracy:    0.906 
Iteration:    363: Loss:     0.501534   Batch Accuracy:    0.852 
Iteration:    364: Loss:     0.378886   Batch Accuracy:    0.883 
Iteration:    365: Loss:     0.504257   Batch Accuracy:    0.836 
Iteration:    366: Loss:     0.570586   Batch Accuracy:    0.836 
Iteration:    367: Loss:     0.390758   Batch Accuracy:    0.914 
Iteration:    368: Loss:     0.432406   Batch Accuracy:    0.891 
Iteration:    369: Loss:     0.596586   Batch Accuracy:    0.836 
Iteration:    370: Loss:     0.356182   Batch Accuracy:    0.945 
Iteration:    371: Loss:     0.417208   Batch Accuracy:    0.906 
Iteration:    372: Loss:     0.461770   Batch Accuracy:    0.891 
Iteration:    373: Loss:     0.346094   Batch Accuracy:    0.930 
Iteration:    374: Loss:     0.390608   Batch Accuracy:    0.891 
Iteration:    375: Loss:     0.388453   Batch Accuracy:    0.898 
Iteration:    376: Loss:     0.288627   Batch Accuracy:    0.930 
Iteration:    377: Loss:     0.443506   Batch Accuracy:    0.875 
Iteration:    378: Loss:     0.385408   Batch Accuracy:    0.906 
Iteration:    379: Loss:     0.418361   Batch Accuracy:    0.875 
Iteration:    380: Loss:     0.453506   Batch Accuracy:    0.891 
Iteration:    381: Loss:     0.448533   Batch Accuracy:    0.875 
Iteration:    382: Loss:     0.450114   Batch Accuracy:    0.891 
Iteration:    383: Loss:     0.374253   Batch Accuracy:    0.898 
Iteration:    384: Loss:     0.442948   Batch Accuracy:    0.852 
Iteration:    385: Loss:     0.338929   Batch Accuracy:    0.891 
Iteration:    386: Loss:     0.441165   Batch Accuracy:    0.859 
Iteration:    387: Loss:     0.362196   Batch Accuracy:    0.930 
Iteration:    388: Loss:     0.511401   Batch Accuracy:    0.859 
Iteration:    389: Loss:     0.453249   Batch Accuracy:    0.867 
Iteration:    390: Loss:     0.472833   Batch Accuracy:    0.883 
Iteration:    391: Loss:     0.379854   Batch Accuracy:    0.922 
Iteration:    392: Loss:     0.383607   Batch Accuracy:    0.906 
Iteration:    393: Loss:     0.404985   Batch Accuracy:    0.906 
Iteration:    394: Loss:     0.513293   Batch Accuracy:    0.844 
Iteration:    395: Loss:     0.445056   Batch Accuracy:    0.875 
Iteration:    396: Loss:     0.323555   Batch Accuracy:    0.914 
Iteration:    397: Loss:     0.527300   Batch Accuracy:    0.828 
Iteration:    398: Loss:     0.498609   Batch Accuracy:    0.867 
Iteration:    399: Loss:     0.592816   Batch Accuracy:    0.883 
Iteration:    400: Loss:     0.343450   Batch Accuracy:    0.930 
Iteration:    401: Loss:     0.386673   Batch Accuracy:    0.875 
Iteration:    402: Loss:     0.403462   Batch Accuracy:    0.914 
Iteration:    403: Loss:     0.391295   Batch Accuracy:    0.898 
Iteration:    404: Loss:     0.366281   Batch Accuracy:    0.898 
Iteration:    405: Loss:     0.383287   Batch Accuracy:    0.883 
Iteration:    406: Loss:     0.496410   Batch Accuracy:    0.883 
Iteration:    407: Loss:     0.343155   Batch Accuracy:    0.898 
Iteration:    408: Loss:     0.529590   Batch Accuracy:    0.820 
Iteration:    409: Loss:     0.355243   Batch Accuracy:    0.898 
Iteration:    410: Loss:     0.435519   Batch Accuracy:    0.891 
Iteration:    411: Loss:     0.325379   Batch Accuracy:    0.945 
Iteration:    412: Loss:     0.417715   Batch Accuracy:    0.891 
Iteration:    413: Loss:     0.417629   Batch Accuracy:    0.867 
Iteration:    414: Loss:     0.339720   Batch Accuracy:    0.906 
Iteration:    415: Loss:     0.400634   Batch Accuracy:    0.852 
Iteration:    416: Loss:     0.442645   Batch Accuracy:    0.883 
Iteration:    417: Loss:     0.501739   Batch Accuracy:    0.836 
Iteration:    418: Loss:     0.584194   Batch Accuracy:    0.859 
Iteration:    419: Loss:     0.487259   Batch Accuracy:    0.852 
Iteration:    420: Loss:     0.521628   Batch Accuracy:    0.867 
Iteration:    421: Loss:     0.363840   Batch Accuracy:    0.914 
Iteration:    422: Loss:     0.418943   Batch Accuracy:    0.867 
Iteration:    423: Loss:     0.366681   Batch Accuracy:    0.914 
Iteration:    424: Loss:     0.469792   Batch Accuracy:    0.883 
Iteration:    425: Loss:     0.371807   Batch Accuracy:    0.883 
Iteration:    426: Loss:     0.449421   Batch Accuracy:    0.875 
Iteration:    427: Loss:     0.465096   Batch Accuracy:    0.875 
Iteration:    428: Loss:     0.332516   Batch Accuracy:    0.922 
Iteration:    429: Loss:     0.319779   Batch Accuracy:    0.930 
Iteration:    430: Loss:     0.397537   Batch Accuracy:    0.883 
Iteration:    431: Loss:     0.431903   Batch Accuracy:    0.906 
Iteration:    432: Loss:     0.438330   Batch Accuracy:    0.859 
Iteration:    433: Loss:     0.433387   Batch Accuracy:    0.852 
Iteration:    434: Loss:     0.364806   Batch Accuracy:    0.922 
Iteration:    435: Loss:     0.345529   Batch Accuracy:    0.930 
Iteration:    436: Loss:     0.330215   Batch Accuracy:    0.945 
Iteration:    437: Loss:     0.337646   Batch Accuracy:    0.938 
Iteration:    438: Loss:     0.541040   Batch Accuracy:    0.836 
Iteration:    439: Loss:     0.317721   Batch Accuracy:    0.891 
Iteration:    440: Loss:     0.354601   Batch Accuracy:    0.906 
Iteration:    441: Loss:     0.407952   Batch Accuracy:    0.891 
Iteration:    442: Loss:     0.412960   Batch Accuracy:    0.891 
Iteration:    443: Loss:     0.428552   Batch Accuracy:    0.891 
Iteration:    444: Loss:     0.306417   Batch Accuracy:    0.953 
Iteration:    445: Loss:     0.322944   Batch Accuracy:    0.930 
Iteration:    446: Loss:     0.391676   Batch Accuracy:    0.906 
Iteration:    447: Loss:     0.418712   Batch Accuracy:    0.867 
Iteration:    448: Loss:     0.314459   Batch Accuracy:    0.898 
Iteration:    449: Loss:     0.370413   Batch Accuracy:    0.922 
Iteration:    450: Loss:     0.456601   Batch Accuracy:    0.852 
Iteration:    451: Loss:     0.390302   Batch Accuracy:    0.883 
Iteration:    452: Loss:     0.427939   Batch Accuracy:    0.844 
Iteration:    453: Loss:     0.329154   Batch Accuracy:    0.875 
Iteration:    454: Loss:     0.431875   Batch Accuracy:    0.867 
Iteration:    455: Loss:     0.507278   Batch Accuracy:    0.883 
Iteration:    456: Loss:     0.328438   Batch Accuracy:    0.930 
Iteration:    457: Loss:     0.272952   Batch Accuracy:    0.938 
Iteration:    458: Loss:     0.497761   Batch Accuracy:    0.867 
Iteration:    459: Loss:     0.355386   Batch Accuracy:    0.914 
Iteration:    460: Loss:     0.282151   Batch Accuracy:    0.922 
Iteration:    461: Loss:     0.538264   Batch Accuracy:    0.898 
Iteration:    462: Loss:     0.481548   Batch Accuracy:    0.875 
Iteration:    463: Loss:     0.424776   Batch Accuracy:    0.867 
Iteration:    464: Loss:     0.342989   Batch Accuracy:    0.906 
Iteration:    465: Loss:     0.467152   Batch Accuracy:    0.844 
Iteration:    466: Loss:     0.319740   Batch Accuracy:    0.914 
Iteration:    467: Loss:     0.457925   Batch Accuracy:    0.875 
Iteration:    468: Loss:     0.528016   Batch Accuracy:    0.812 
Iteration:    469: Loss:     0.328056   Batch Accuracy:    0.906 
Iteration:    470: Loss:     0.506689   Batch Accuracy:    0.844 
Iteration:    471: Loss:     0.425715   Batch Accuracy:    0.867 
Iteration:    472: Loss:     0.358345   Batch Accuracy:    0.914 
Iteration:    473: Loss:     0.363238   Batch Accuracy:    0.891 
Iteration:    474: Loss:     0.439708   Batch Accuracy:    0.898 
Iteration:    475: Loss:     0.365994   Batch Accuracy:    0.922 
Iteration:    476: Loss:     0.404501   Batch Accuracy:    0.898 
Iteration:    477: Loss:     0.427614   Batch Accuracy:    0.891 
Iteration:    478: Loss:     0.449986   Batch Accuracy:    0.875 
Iteration:    479: Loss:     0.449666   Batch Accuracy:    0.891 
Iteration:    480: Loss:     0.373573   Batch Accuracy:    0.844 
Iteration:    481: Loss:     0.485593   Batch Accuracy:    0.891 
Iteration:    482: Loss:     0.373417   Batch Accuracy:    0.898 
Iteration:    483: Loss:     0.342592   Batch Accuracy:    0.891 
Iteration:    484: Loss:     0.383825   Batch Accuracy:    0.898 
Iteration:    485: Loss:     0.360983   Batch Accuracy:    0.883 
Iteration:    486: Loss:     0.351889   Batch Accuracy:    0.914 
Iteration:    487: Loss:     0.402777   Batch Accuracy:    0.867 
Iteration:    488: Loss:     0.356768   Batch Accuracy:    0.898 
Iteration:    489: Loss:     0.402799   Batch Accuracy:    0.883 
Iteration:    490: Loss:     0.333276   Batch Accuracy:    0.914 
Iteration:    491: Loss:     0.393941   Batch Accuracy:    0.898 
Iteration:    492: Loss:     0.422897   Batch Accuracy:    0.883 
Iteration:    493: Loss:     0.378815   Batch Accuracy:    0.883 
Iteration:    494: Loss:     0.300898   Batch Accuracy:    0.922 
Iteration:    495: Loss:     0.447626   Batch Accuracy:    0.867 
Iteration:    496: Loss:     0.561502   Batch Accuracy:    0.836 
Iteration:    497: Loss:     0.348290   Batch Accuracy:    0.922 
Iteration:    498: Loss:     0.262665   Batch Accuracy:    0.938 
Iteration:    499: Loss:     0.360753   Batch Accuracy:    0.914 
Iteration:    500: Loss:     0.390631   Batch Accuracy:    0.906 
Iteration:    501: Loss:     0.391616   Batch Accuracy:    0.891 
Iteration:    502: Loss:     0.414089   Batch Accuracy:    0.898 
Iteration:    503: Loss:     0.580460   Batch Accuracy:    0.844 
Iteration:    504: Loss:     0.332088   Batch Accuracy:    0.906 
Iteration:    505: Loss:     0.496952   Batch Accuracy:    0.883 
Iteration:    506: Loss:     0.456194   Batch Accuracy:    0.836 
Iteration:    507: Loss:     0.336740   Batch Accuracy:    0.914 
Iteration:    508: Loss:     0.264760   Batch Accuracy:    0.914 
Iteration:    509: Loss:     0.437060   Batch Accuracy:    0.891 
Iteration:    510: Loss:     0.473900   Batch Accuracy:    0.844 
Iteration:    511: Loss:     0.531245   Batch Accuracy:    0.812 
Iteration:    512: Loss:     0.299844   Batch Accuracy:    0.914 
Iteration:    513: Loss:     0.377202   Batch Accuracy:    0.891 
Iteration:    514: Loss:     0.316664   Batch Accuracy:    0.914 
Iteration:    515: Loss:     0.350527   Batch Accuracy:    0.898 
Iteration:    516: Loss:     0.355218   Batch Accuracy:    0.898 
Iteration:    517: Loss:     0.293412   Batch Accuracy:    0.930 
Iteration:    518: Loss:     0.388101   Batch Accuracy:    0.906 
Iteration:    519: Loss:     0.341142   Batch Accuracy:    0.906 
Iteration:    520: Loss:     0.307858   Batch Accuracy:    0.922 
Iteration:    521: Loss:     0.471863   Batch Accuracy:    0.852 
Iteration:    522: Loss:     0.445472   Batch Accuracy:    0.883 
Iteration:    523: Loss:     0.337767   Batch Accuracy:    0.906 
Iteration:    524: Loss:     0.597499   Batch Accuracy:    0.859 
Iteration:    525: Loss:     0.381465   Batch Accuracy:    0.906 
Iteration:    526: Loss:     0.329315   Batch Accuracy:    0.922 
Iteration:    527: Loss:     0.415533   Batch Accuracy:    0.867 
Iteration:    528: Loss:     0.352520   Batch Accuracy:    0.898 
Iteration:    529: Loss:     0.324087   Batch Accuracy:    0.914 
Iteration:    530: Loss:     0.385485   Batch Accuracy:    0.891 
Iteration:    531: Loss:     0.426385   Batch Accuracy:    0.898 
Iteration:    532: Loss:     0.368926   Batch Accuracy:    0.891 
Iteration:    533: Loss:     0.367735   Batch Accuracy:    0.891 
Iteration:    534: Loss:     0.462204   Batch Accuracy:    0.891 
Iteration:    535: Loss:     0.321396   Batch Accuracy:    0.914 
Iteration:    536: Loss:     0.397098   Batch Accuracy:    0.883 
Iteration:    537: Loss:     0.362429   Batch Accuracy:    0.930 
Iteration:    538: Loss:     0.543901   Batch Accuracy:    0.844 
Iteration:    539: Loss:     0.455475   Batch Accuracy:    0.859 
Iteration:    540: Loss:     0.459274   Batch Accuracy:    0.867 
Iteration:    541: Loss:     0.319098   Batch Accuracy:    0.914 
Iteration:    542: Loss:     0.582328   Batch Accuracy:    0.852 
Iteration:    543: Loss:     0.402890   Batch Accuracy:    0.891 
Iteration:    544: Loss:     0.294443   Batch Accuracy:    0.930 
Iteration:    545: Loss:     0.318242   Batch Accuracy:    0.906 
Iteration:    546: Loss:     0.440746   Batch Accuracy:    0.875 
Iteration:    547: Loss:     0.369792   Batch Accuracy:    0.914 
Iteration:    548: Loss:     0.432765   Batch Accuracy:    0.883 
Iteration:    549: Loss:     0.397095   Batch Accuracy:    0.914 
Iteration:    550: Loss:     0.315981   Batch Accuracy:    0.930 
Iteration:    551: Loss:     0.461758   Batch Accuracy:    0.875 
Iteration:    552: Loss:     0.257353   Batch Accuracy:    0.945 
Iteration:    553: Loss:     0.371088   Batch Accuracy:    0.906 
Iteration:    554: Loss:     0.557176   Batch Accuracy:    0.844 
Iteration:    555: Loss:     0.389740   Batch Accuracy:    0.875 
Iteration:    556: Loss:     0.470853   Batch Accuracy:    0.875 
Iteration:    557: Loss:     0.330360   Batch Accuracy:    0.922 
Iteration:    558: Loss:     0.582198   Batch Accuracy:    0.867 
Iteration:    559: Loss:     0.335293   Batch Accuracy:    0.906 
Iteration:    560: Loss:     0.296896   Batch Accuracy:    0.930 
Iteration:    561: Loss:     0.338169   Batch Accuracy:    0.898 
Iteration:    562: Loss:     0.479064   Batch Accuracy:    0.859 
Iteration:    563: Loss:     0.504331   Batch Accuracy:    0.859 
Iteration:    564: Loss:     0.419814   Batch Accuracy:    0.891 
Iteration:    565: Loss:     0.293500   Batch Accuracy:    0.930 
Iteration:    566: Loss:     0.470310   Batch Accuracy:    0.906 
Iteration:    567: Loss:     0.334136   Batch Accuracy:    0.891 
Iteration:    568: Loss:     0.399672   Batch Accuracy:    0.891 
Iteration:    569: Loss:     0.502209   Batch Accuracy:    0.875 
Iteration:    570: Loss:     0.372919   Batch Accuracy:    0.922 
Iteration:    571: Loss:     0.362000   Batch Accuracy:    0.906 
Iteration:    572: Loss:     0.337997   Batch Accuracy:    0.898 
Iteration:    573: Loss:     0.284037   Batch Accuracy:    0.922 
Iteration:    574: Loss:     0.497732   Batch Accuracy:    0.875 
Iteration:    575: Loss:     0.340270   Batch Accuracy:    0.875 
Iteration:    576: Loss:     0.454364   Batch Accuracy:    0.875 
Iteration:    577: Loss:     0.413920   Batch Accuracy:    0.859 
Iteration:    578: Loss:     0.464234   Batch Accuracy:    0.859 
Iteration:    579: Loss:     0.285036   Batch Accuracy:    0.945 
Iteration:    580: Loss:     0.402503   Batch Accuracy:    0.867 
Iteration:    581: Loss:     0.320946   Batch Accuracy:    0.938 
Iteration:    582: Loss:     0.355737   Batch Accuracy:    0.891 
Iteration:    583: Loss:     0.310344   Batch Accuracy:    0.906 
Iteration:    584: Loss:     0.439525   Batch Accuracy:    0.891 
Iteration:    585: Loss:     0.304983   Batch Accuracy:    0.891 
Iteration:    586: Loss:     0.292302   Batch Accuracy:    0.930 
Iteration:    587: Loss:     0.347864   Batch Accuracy:    0.906 
Iteration:    588: Loss:     0.325390   Batch Accuracy:    0.898 
Iteration:    589: Loss:     0.293465   Batch Accuracy:    0.938 
Iteration:    590: Loss:     0.531691   Batch Accuracy:    0.852 
Iteration:    591: Loss:     0.276765   Batch Accuracy:    0.922 
Iteration:    592: Loss:     0.327714   Batch Accuracy:    0.906 
Iteration:    593: Loss:     0.321674   Batch Accuracy:    0.930 
Iteration:    594: Loss:     0.518504   Batch Accuracy:    0.859 
Iteration:    595: Loss:     0.366143   Batch Accuracy:    0.906 
Iteration:    596: Loss:     0.341672   Batch Accuracy:    0.906 
Iteration:    597: Loss:     0.575659   Batch Accuracy:    0.867 
Iteration:    598: Loss:     0.388107   Batch Accuracy:    0.891 
Iteration:    599: Loss:     0.445308   Batch Accuracy:    0.875 
Iteration:    600: Loss:     0.312110   Batch Accuracy:    0.906 
Iteration:    601: Loss:     0.328329   Batch Accuracy:    0.906 
Iteration:    602: Loss:     0.450848   Batch Accuracy:    0.875 
Iteration:    603: Loss:     0.426800   Batch Accuracy:    0.891 
Iteration:    604: Loss:     0.335683   Batch Accuracy:    0.930 
Iteration:    605: Loss:     0.355627   Batch Accuracy:    0.891 
Iteration:    606: Loss:     0.413394   Batch Accuracy:    0.898 
Iteration:    607: Loss:     0.352425   Batch Accuracy:    0.883 
Iteration:    608: Loss:     0.451824   Batch Accuracy:    0.875 
Iteration:    609: Loss:     0.415575   Batch Accuracy:    0.883 
Iteration:    610: Loss:     0.339212   Batch Accuracy:    0.930 
Iteration:    611: Loss:     0.417845   Batch Accuracy:    0.891 
Iteration:    612: Loss:     0.436977   Batch Accuracy:    0.867 
Iteration:    613: Loss:     0.445532   Batch Accuracy:    0.930 
Iteration:    614: Loss:     0.280000   Batch Accuracy:    0.906 
Iteration:    615: Loss:     0.371532   Batch Accuracy:    0.914 
Iteration:    616: Loss:     0.373811   Batch Accuracy:    0.906 
Iteration:    617: Loss:     0.498582   Batch Accuracy:    0.852 
Iteration:    618: Loss:     0.316563   Batch Accuracy:    0.938 
Iteration:    619: Loss:     0.383869   Batch Accuracy:    0.898 
Iteration:    620: Loss:     0.404344   Batch Accuracy:    0.898 
Iteration:    621: Loss:     0.233048   Batch Accuracy:    0.953 
Iteration:    622: Loss:     0.441314   Batch Accuracy:    0.875 
Iteration:    623: Loss:     0.345424   Batch Accuracy:    0.914 
Iteration:    624: Loss:     0.587654   Batch Accuracy:    0.859 
Iteration:    625: Loss:     0.371259   Batch Accuracy:    0.891 
Iteration:    626: Loss:     0.499665   Batch Accuracy:    0.859 
Iteration:    627: Loss:     0.350758   Batch Accuracy:    0.891 
Iteration:    628: Loss:     0.362072   Batch Accuracy:    0.867 
Iteration:    629: Loss:     0.258532   Batch Accuracy:    0.922 
Iteration:    630: Loss:     0.338951   Batch Accuracy:    0.914 
Iteration:    631: Loss:     0.299611   Batch Accuracy:    0.906 
Iteration:    632: Loss:     0.480208   Batch Accuracy:    0.922 
Iteration:    633: Loss:     0.329571   Batch Accuracy:    0.906 
Iteration:    634: Loss:     0.386569   Batch Accuracy:    0.898 
Iteration:    635: Loss:     0.369526   Batch Accuracy:    0.883 
Iteration:    636: Loss:     0.328250   Batch Accuracy:    0.922 
Iteration:    637: Loss:     0.312807   Batch Accuracy:    0.930 
Iteration:    638: Loss:     0.315456   Batch Accuracy:    0.922 
Iteration:    639: Loss:     0.269111   Batch Accuracy:    0.930 
Iteration:    640: Loss:     0.379702   Batch Accuracy:    0.891 
Iteration:    641: Loss:     0.335326   Batch Accuracy:    0.914 
Iteration:    642: Loss:     0.333835   Batch Accuracy:    0.914 
Iteration:    643: Loss:     0.416706   Batch Accuracy:    0.898 
Iteration:    644: Loss:     0.308289   Batch Accuracy:    0.883 
Iteration:    645: Loss:     0.416799   Batch Accuracy:    0.914 
Iteration:    646: Loss:     0.330721   Batch Accuracy:    0.898 
Iteration:    647: Loss:     0.391069   Batch Accuracy:    0.914 
Iteration:    648: Loss:     0.320818   Batch Accuracy:    0.914 
Iteration:    649: Loss:     0.410078   Batch Accuracy:    0.906 
Iteration:    650: Loss:     0.392455   Batch Accuracy:    0.875 
Iteration:    651: Loss:     0.429666   Batch Accuracy:    0.883 
Iteration:    652: Loss:     0.383013   Batch Accuracy:    0.891 
Iteration:    653: Loss:     0.478912   Batch Accuracy:    0.867 
Iteration:    654: Loss:     0.356385   Batch Accuracy:    0.906 
Iteration:    655: Loss:     0.337419   Batch Accuracy:    0.898 
Iteration:    656: Loss:     0.420440   Batch Accuracy:    0.906 
Iteration:    657: Loss:     0.428118   Batch Accuracy:    0.875 
Iteration:    658: Loss:     0.304524   Batch Accuracy:    0.906 
Iteration:    659: Loss:     0.371699   Batch Accuracy:    0.852 
Iteration:    660: Loss:     0.297880   Batch Accuracy:    0.930 
Iteration:    661: Loss:     0.352082   Batch Accuracy:    0.883 
Iteration:    662: Loss:     0.338227   Batch Accuracy:    0.938 
Iteration:    663: Loss:     0.302954   Batch Accuracy:    0.922 
Iteration:    664: Loss:     0.403358   Batch Accuracy:    0.906 
Iteration:    665: Loss:     0.422952   Batch Accuracy:    0.898 
Iteration:    666: Loss:     0.440092   Batch Accuracy:    0.859 
Iteration:    667: Loss:     0.347507   Batch Accuracy:    0.891 
Iteration:    668: Loss:     0.383716   Batch Accuracy:    0.859 
Iteration:    669: Loss:     0.366992   Batch Accuracy:    0.914 
Iteration:    670: Loss:     0.488309   Batch Accuracy:    0.844 
Iteration:    671: Loss:     0.277605   Batch Accuracy:    0.938 
Iteration:    672: Loss:     0.526160   Batch Accuracy:    0.859 
Iteration:    673: Loss:     0.318592   Batch Accuracy:    0.922 
Iteration:    674: Loss:     0.384729   Batch Accuracy:    0.875 
Iteration:    675: Loss:     0.264135   Batch Accuracy:    0.945 
Iteration:    676: Loss:     0.313470   Batch Accuracy:    0.930 
Iteration:    677: Loss:     0.333246   Batch Accuracy:    0.898 
Iteration:    678: Loss:     0.294485   Batch Accuracy:    0.891 
Iteration:    679: Loss:     0.263490   Batch Accuracy:    0.938 
Iteration:    680: Loss:     0.361682   Batch Accuracy:    0.883 
Iteration:    681: Loss:     0.305051   Batch Accuracy:    0.922 
Iteration:    682: Loss:     0.458942   Batch Accuracy:    0.906 
Iteration:    683: Loss:     0.346164   Batch Accuracy:    0.914 
Iteration:    684: Loss:     0.379042   Batch Accuracy:    0.906 
Iteration:    685: Loss:     0.348750   Batch Accuracy:    0.898 
Iteration:    686: Loss:     0.498244   Batch Accuracy:    0.859 
Iteration:    687: Loss:     0.395027   Batch Accuracy:    0.883 
Iteration:    688: Loss:     0.466862   Batch Accuracy:    0.844 
Iteration:    689: Loss:     0.419472   Batch Accuracy:    0.883 
Iteration:    690: Loss:     0.407113   Batch Accuracy:    0.867 
Iteration:    691: Loss:     0.483979   Batch Accuracy:    0.883 
Iteration:    692: Loss:     0.309820   Batch Accuracy:    0.938 
Iteration:    693: Loss:     0.491413   Batch Accuracy:    0.859 
Iteration:    694: Loss:     0.422625   Batch Accuracy:    0.914 
Iteration:    695: Loss:     0.447709   Batch Accuracy:    0.844 
Iteration:    696: Loss:     0.362695   Batch Accuracy:    0.906 
Iteration:    697: Loss:     0.336617   Batch Accuracy:    0.891 
Iteration:    698: Loss:     0.424452   Batch Accuracy:    0.883 
Iteration:    699: Loss:     0.425017   Batch Accuracy:    0.852 
Iteration:    700: Loss:     0.377697   Batch Accuracy:    0.906 
Iteration:    701: Loss:     0.275755   Batch Accuracy:    0.945 
Iteration:    702: Loss:     0.476837   Batch Accuracy:    0.875 
Iteration:    703: Loss:     0.356751   Batch Accuracy:    0.930 
Iteration:    704: Loss:     0.360967   Batch Accuracy:    0.906 
Iteration:    705: Loss:     0.385162   Batch Accuracy:    0.875 
Iteration:    706: Loss:     0.581332   Batch Accuracy:    0.844 
Iteration:    707: Loss:     0.265275   Batch Accuracy:    0.930 
Iteration:    708: Loss:     0.454681   Batch Accuracy:    0.875 
Iteration:    709: Loss:     0.350711   Batch Accuracy:    0.898 
Iteration:    710: Loss:     0.371138   Batch Accuracy:    0.898 
Iteration:    711: Loss:     0.361809   Batch Accuracy:    0.898 
Iteration:    712: Loss:     0.451085   Batch Accuracy:    0.844 
Iteration:    713: Loss:     0.400430   Batch Accuracy:    0.891 
Iteration:    714: Loss:     0.327217   Batch Accuracy:    0.883 
Iteration:    715: Loss:     0.286774   Batch Accuracy:    0.930 
Iteration:    716: Loss:     0.463224   Batch Accuracy:    0.844 
Iteration:    717: Loss:     0.306618   Batch Accuracy:    0.930 
Iteration:    718: Loss:     0.349831   Batch Accuracy:    0.891 
Iteration:    719: Loss:     0.322356   Batch Accuracy:    0.922 
Iteration:    720: Loss:     0.397861   Batch Accuracy:    0.898 
Iteration:    721: Loss:     0.340549   Batch Accuracy:    0.922 
Iteration:    722: Loss:     0.357233   Batch Accuracy:    0.906 
Iteration:    723: Loss:     0.309965   Batch Accuracy:    0.922 
Iteration:    724: Loss:     0.403308   Batch Accuracy:    0.898 
Iteration:    725: Loss:     0.362539   Batch Accuracy:    0.906 
Iteration:    726: Loss:     0.367617   Batch Accuracy:    0.914 
Iteration:    727: Loss:     0.288226   Batch Accuracy:    0.945 
Iteration:    728: Loss:     0.340942   Batch Accuracy:    0.914 
Iteration:    729: Loss:     0.444805   Batch Accuracy:    0.836 
Iteration:    730: Loss:     0.494097   Batch Accuracy:    0.859 
Iteration:    731: Loss:     0.219038   Batch Accuracy:    0.930 
Iteration:    732: Loss:     0.272031   Batch Accuracy:    0.945 
Iteration:    733: Loss:     0.501997   Batch Accuracy:    0.891 
Iteration:    734: Loss:     0.360497   Batch Accuracy:    0.883 
Iteration:    735: Loss:     0.390328   Batch Accuracy:    0.906 
Iteration:    736: Loss:     0.341534   Batch Accuracy:    0.945 
Iteration:    737: Loss:     0.238690   Batch Accuracy:    0.945 
Iteration:    738: Loss:     0.335538   Batch Accuracy:    0.914 
Iteration:    739: Loss:     0.387672   Batch Accuracy:    0.852 
Iteration:    740: Loss:     0.312414   Batch Accuracy:    0.891 
Iteration:    741: Loss:     0.422670   Batch Accuracy:    0.867 
Iteration:    742: Loss:     0.283531   Batch Accuracy:    0.930 
Iteration:    743: Loss:     0.232910   Batch Accuracy:    0.938 
Iteration:    744: Loss:     0.268432   Batch Accuracy:    0.922 
Iteration:    745: Loss:     0.388027   Batch Accuracy:    0.891 
Iteration:    746: Loss:     0.278178   Batch Accuracy:    0.930 
Iteration:    747: Loss:     0.328621   Batch Accuracy:    0.914 
Iteration:    748: Loss:     0.251766   Batch Accuracy:    0.930 
Iteration:    749: Loss:     0.307786   Batch Accuracy:    0.945 
Iteration:    750: Loss:     0.376179   Batch Accuracy:    0.883 
Iteration:    751: Loss:     0.279908   Batch Accuracy:    0.945 
Iteration:    752: Loss:     0.306181   Batch Accuracy:    0.922 
Iteration:    753: Loss:     0.393577   Batch Accuracy:    0.898 
Iteration:    754: Loss:     0.377751   Batch Accuracy:    0.859 
Iteration:    755: Loss:     0.360834   Batch Accuracy:    0.906 
Iteration:    756: Loss:     0.422935   Batch Accuracy:    0.898 
Iteration:    757: Loss:     0.314400   Batch Accuracy:    0.930 
Iteration:    758: Loss:     0.303213   Batch Accuracy:    0.914 
Iteration:    759: Loss:     0.469613   Batch Accuracy:    0.867 
Iteration:    760: Loss:     0.304108   Batch Accuracy:    0.930 
Iteration:    761: Loss:     0.319075   Batch Accuracy:    0.914 
Iteration:    762: Loss:     0.326864   Batch Accuracy:    0.891 
Iteration:    763: Loss:     0.373571   Batch Accuracy:    0.883 
Iteration:    764: Loss:     0.494507   Batch Accuracy:    0.828 
Iteration:    765: Loss:     0.433171   Batch Accuracy:    0.859 
Iteration:    766: Loss:     0.385793   Batch Accuracy:    0.914 
Iteration:    767: Loss:     0.252671   Batch Accuracy:    0.914 
Iteration:    768: Loss:     0.429849   Batch Accuracy:    0.891 
Iteration:    769: Loss:     0.395804   Batch Accuracy:    0.914 
Iteration:    770: Loss:     0.429237   Batch Accuracy:    0.867 
Iteration:    771: Loss:     0.290368   Batch Accuracy:    0.898 
Iteration:    772: Loss:     0.426820   Batch Accuracy:    0.875 
Iteration:    773: Loss:     0.454687   Batch Accuracy:    0.844 
Iteration:    774: Loss:     0.452279   Batch Accuracy:    0.891 
Iteration:    775: Loss:     0.359936   Batch Accuracy:    0.875 
Iteration:    776: Loss:     0.529445   Batch Accuracy:    0.891 
Iteration:    777: Loss:     0.304740   Batch Accuracy:    0.914 
Iteration:    778: Loss:     0.300732   Batch Accuracy:    0.938 
Iteration:    779: Loss:     0.332251   Batch Accuracy:    0.922 
Iteration:    780: Loss:     0.434604   Batch Accuracy:    0.859 
Iteration:    781: Loss:     0.350312   Batch Accuracy:    0.914 
Iteration:    782: Loss:     0.403649   Batch Accuracy:    0.891 
Iteration:    783: Loss:     0.365434   Batch Accuracy:    0.906 
Iteration:    784: Loss:     0.241223   Batch Accuracy:    0.953 
Iteration:    785: Loss:     0.321185   Batch Accuracy:    0.922 
Iteration:    786: Loss:     0.349262   Batch Accuracy:    0.930 
Iteration:    787: Loss:     0.362914   Batch Accuracy:    0.922 
Iteration:    788: Loss:     0.343015   Batch Accuracy:    0.898 
Iteration:    789: Loss:     0.336425   Batch Accuracy:    0.922 
Iteration:    790: Loss:     0.417011   Batch Accuracy:    0.875 
Iteration:    791: Loss:     0.352929   Batch Accuracy:    0.898 
Iteration:    792: Loss:     0.407191   Batch Accuracy:    0.891 
Iteration:    793: Loss:     0.415239   Batch Accuracy:    0.875 
Iteration:    794: Loss:     0.429187   Batch Accuracy:    0.906 
Iteration:    795: Loss:     0.205432   Batch Accuracy:    0.945 
Iteration:    796: Loss:     0.319903   Batch Accuracy:    0.922 
Iteration:    797: Loss:     0.411169   Batch Accuracy:    0.914 
Iteration:    798: Loss:     0.431748   Batch Accuracy:    0.875 
Iteration:    799: Loss:     0.368540   Batch Accuracy:    0.867 
Iteration:    800: Loss:     0.290893   Batch Accuracy:    0.922 
Iteration:    801: Loss:     0.370394   Batch Accuracy:    0.875 
Iteration:    802: Loss:     0.374519   Batch Accuracy:    0.898 
Iteration:    803: Loss:     0.334019   Batch Accuracy:    0.883 
Iteration:    804: Loss:     0.328348   Batch Accuracy:    0.898 
Iteration:    805: Loss:     0.410538   Batch Accuracy:    0.859 
Iteration:    806: Loss:     0.377476   Batch Accuracy:    0.891 
Iteration:    807: Loss:     0.562880   Batch Accuracy:    0.836 
Iteration:    808: Loss:     0.277795   Batch Accuracy:    0.938 
Iteration:    809: Loss:     0.326848   Batch Accuracy:    0.914 
Iteration:    810: Loss:     0.301949   Batch Accuracy:    0.938 
Iteration:    811: Loss:     0.337080   Batch Accuracy:    0.898 
Iteration:    812: Loss:     0.394033   Batch Accuracy:    0.867 
Iteration:    813: Loss:     0.292227   Batch Accuracy:    0.930 
Iteration:    814: Loss:     0.419697   Batch Accuracy:    0.891 
Iteration:    815: Loss:     0.454315   Batch Accuracy:    0.875 
Iteration:    816: Loss:     0.413876   Batch Accuracy:    0.898 
Iteration:    817: Loss:     0.398775   Batch Accuracy:    0.875 
Iteration:    818: Loss:     0.370078   Batch Accuracy:    0.883 
Iteration:    819: Loss:     0.309788   Batch Accuracy:    0.906 
Iteration:    820: Loss:     0.333256   Batch Accuracy:    0.906 
Iteration:    821: Loss:     0.370549   Batch Accuracy:    0.906 
Iteration:    822: Loss:     0.319457   Batch Accuracy:    0.922 
Iteration:    823: Loss:     0.313699   Batch Accuracy:    0.898 
Iteration:    824: Loss:     0.465247   Batch Accuracy:    0.867 
Iteration:    825: Loss:     0.425739   Batch Accuracy:    0.898 
Iteration:    826: Loss:     0.367663   Batch Accuracy:    0.906 
Iteration:    827: Loss:     0.345544   Batch Accuracy:    0.914 
Iteration:    828: Loss:     0.492827   Batch Accuracy:    0.891 
Iteration:    829: Loss:     0.427203   Batch Accuracy:    0.867 
Iteration:    830: Loss:     0.406676   Batch Accuracy:    0.898 
Iteration:    831: Loss:     0.361861   Batch Accuracy:    0.898 
Iteration:    832: Loss:     0.407250   Batch Accuracy:    0.914 
Iteration:    833: Loss:     0.398459   Batch Accuracy:    0.867 
Iteration:    834: Loss:     0.385429   Batch Accuracy:    0.898 
Iteration:    835: Loss:     0.373481   Batch Accuracy:    0.914 
Iteration:    836: Loss:     0.418859   Batch Accuracy:    0.844 
Iteration:    837: Loss:     0.293223   Batch Accuracy:    0.922 
Iteration:    838: Loss:     0.404125   Batch Accuracy:    0.891 
Iteration:    839: Loss:     0.332049   Batch Accuracy:    0.898 
Iteration:    840: Loss:     0.322215   Batch Accuracy:    0.906 
Iteration:    841: Loss:     0.365631   Batch Accuracy:    0.883 
Iteration:    842: Loss:     0.433686   Batch Accuracy:    0.875 
Iteration:    843: Loss:     0.412582   Batch Accuracy:    0.875 
Iteration:    844: Loss:     0.405115   Batch Accuracy:    0.883 
Iteration:    845: Loss:     0.281641   Batch Accuracy:    0.922 
Iteration:    846: Loss:     0.301170   Batch Accuracy:    0.914 
Iteration:    847: Loss:     0.307440   Batch Accuracy:    0.922 
Iteration:    848: Loss:     0.409262   Batch Accuracy:    0.914 
Iteration:    849: Loss:     0.344289   Batch Accuracy:    0.898 
Iteration:    850: Loss:     0.374685   Batch Accuracy:    0.898 
Iteration:    851: Loss:     0.250297   Batch Accuracy:    0.938 
Iteration:    852: Loss:     0.302433   Batch Accuracy:    0.906 
Iteration:    853: Loss:     0.363844   Batch Accuracy:    0.883 
Iteration:    854: Loss:     0.388880   Batch Accuracy:    0.898 
Iteration:    855: Loss:     0.469848   Batch Accuracy:    0.883 
Iteration:    856: Loss:     0.428826   Batch Accuracy:    0.875 
Iteration:    857: Loss:     0.392508   Batch Accuracy:    0.883 
Iteration:    858: Loss:     0.379322   Batch Accuracy:    0.875 
Iteration:    859: Loss:     0.431310   Batch Accuracy:    0.891 
Iteration:    860: Loss:     0.385293   Batch Accuracy:    0.891 
Iteration:    861: Loss:     0.260652   Batch Accuracy:    0.922 
Iteration:    862: Loss:     0.377405   Batch Accuracy:    0.914 
Iteration:    863: Loss:     0.392624   Batch Accuracy:    0.898 
Iteration:    864: Loss:     0.333920   Batch Accuracy:    0.922 
Iteration:    865: Loss:     0.325460   Batch Accuracy:    0.930 
Iteration:    866: Loss:     0.339001   Batch Accuracy:    0.906 
Iteration:    867: Loss:     0.325698   Batch Accuracy:    0.875 
Iteration:    868: Loss:     0.353953   Batch Accuracy:    0.930 
Iteration:    869: Loss:     0.407865   Batch Accuracy:    0.852 
Iteration:    870: Loss:     0.259689   Batch Accuracy:    0.938 
Iteration:    871: Loss:     0.324945   Batch Accuracy:    0.906 
Iteration:    872: Loss:     0.380992   Batch Accuracy:    0.891 
Iteration:    873: Loss:     0.337022   Batch Accuracy:    0.906 
Iteration:    874: Loss:     0.339206   Batch Accuracy:    0.883 
Iteration:    875: Loss:     0.242284   Batch Accuracy:    0.922 
Iteration:    876: Loss:     0.263724   Batch Accuracy:    0.891 
Iteration:    877: Loss:     0.484128   Batch Accuracy:    0.867 
Iteration:    878: Loss:     0.265200   Batch Accuracy:    0.930 
Iteration:    879: Loss:     0.451455   Batch Accuracy:    0.867 
Iteration:    880: Loss:     0.422722   Batch Accuracy:    0.883 
Iteration:    881: Loss:     0.491040   Batch Accuracy:    0.852 
Iteration:    882: Loss:     0.312216   Batch Accuracy:    0.922 
Iteration:    883: Loss:     0.376956   Batch Accuracy:    0.898 
Iteration:    884: Loss:     0.381487   Batch Accuracy:    0.891 
Iteration:    885: Loss:     0.330552   Batch Accuracy:    0.938 
Iteration:    886: Loss:     0.383750   Batch Accuracy:    0.906 
Iteration:    887: Loss:     0.246547   Batch Accuracy:    0.930 
Iteration:    888: Loss:     0.369880   Batch Accuracy:    0.906 
Iteration:    889: Loss:     0.302812   Batch Accuracy:    0.930 
Iteration:    890: Loss:     0.319167   Batch Accuracy:    0.906 
Iteration:    891: Loss:     0.278530   Batch Accuracy:    0.945 
Iteration:    892: Loss:     0.375567   Batch Accuracy:    0.898 
Iteration:    893: Loss:     0.330187   Batch Accuracy:    0.914 
Iteration:    894: Loss:     0.387545   Batch Accuracy:    0.883 
Iteration:    895: Loss:     0.298321   Batch Accuracy:    0.906 
Iteration:    896: Loss:     0.395480   Batch Accuracy:    0.883 
Iteration:    897: Loss:     0.283886   Batch Accuracy:    0.922 
Iteration:    898: Loss:     0.427138   Batch Accuracy:    0.898 
Iteration:    899: Loss:     0.329607   Batch Accuracy:    0.930 
Iteration:    900: Loss:     0.347261   Batch Accuracy:    0.875 
Iteration:    901: Loss:     0.282901   Batch Accuracy:    0.938 
Iteration:    902: Loss:     0.338555   Batch Accuracy:    0.898 
Iteration:    903: Loss:     0.368080   Batch Accuracy:    0.859 
Iteration:    904: Loss:     0.322456   Batch Accuracy:    0.922 
Iteration:    905: Loss:     0.275027   Batch Accuracy:    0.930 
Iteration:    906: Loss:     0.288421   Batch Accuracy:    0.906 
Iteration:    907: Loss:     0.359738   Batch Accuracy:    0.898 
Iteration:    908: Loss:     0.300485   Batch Accuracy:    0.922 
Iteration:    909: Loss:     0.268303   Batch Accuracy:    0.945 
Iteration:    910: Loss:     0.214718   Batch Accuracy:    0.961 
Iteration:    911: Loss:     0.228236   Batch Accuracy:    0.961 
Iteration:    912: Loss:     0.379049   Batch Accuracy:    0.898 
Iteration:    913: Loss:     0.471458   Batch Accuracy:    0.844 
Iteration:    914: Loss:     0.432014   Batch Accuracy:    0.859 
Iteration:    915: Loss:     0.460453   Batch Accuracy:    0.867 
Iteration:    916: Loss:     0.366449   Batch Accuracy:    0.867 
Iteration:    917: Loss:     0.326911   Batch Accuracy:    0.906 
Iteration:    918: Loss:     0.311876   Batch Accuracy:    0.922 
Iteration:    919: Loss:     0.238375   Batch Accuracy:    0.938 
Iteration:    920: Loss:     0.414822   Batch Accuracy:    0.844 
Iteration:    921: Loss:     0.276267   Batch Accuracy:    0.922 
Iteration:    922: Loss:     0.277650   Batch Accuracy:    0.898 
Iteration:    923: Loss:     0.382052   Batch Accuracy:    0.883 
Iteration:    924: Loss:     0.420448   Batch Accuracy:    0.875 
Iteration:    925: Loss:     0.342428   Batch Accuracy:    0.898 
Iteration:    926: Loss:     0.370776   Batch Accuracy:    0.898 
Iteration:    927: Loss:     0.423051   Batch Accuracy:    0.875 
Iteration:    928: Loss:     0.508753   Batch Accuracy:    0.812 
Iteration:    929: Loss:     0.398675   Batch Accuracy:    0.891 
Iteration:    930: Loss:     0.344417   Batch Accuracy:    0.898 
Iteration:    931: Loss:     0.444863   Batch Accuracy:    0.852 
Iteration:    932: Loss:     0.355592   Batch Accuracy:    0.930 
Iteration:    933: Loss:     0.277985   Batch Accuracy:    0.938 
Iteration:    934: Loss:     0.411699   Batch Accuracy:    0.859 
Iteration:    935: Loss:     0.221485   Batch Accuracy:    0.961 
Iteration:    936: Loss:     0.413918   Batch Accuracy:    0.906 
Iteration:    937: Loss:     0.381108   Batch Accuracy:    0.859 
Iteration:    938: Loss:     0.501662   Batch Accuracy:    0.875 
Iteration:    939: Loss:     0.390364   Batch Accuracy:    0.891 
Iteration:    940: Loss:     0.398470   Batch Accuracy:    0.883 
Iteration:    941: Loss:     0.271938   Batch Accuracy:    0.914 
Iteration:    942: Loss:     0.358311   Batch Accuracy:    0.914 
Iteration:    943: Loss:     0.347592   Batch Accuracy:    0.891 
Iteration:    944: Loss:     0.320289   Batch Accuracy:    0.898 
Iteration:    945: Loss:     0.401647   Batch Accuracy:    0.891 
Iteration:    946: Loss:     0.430705   Batch Accuracy:    0.859 
Iteration:    947: Loss:     0.255156   Batch Accuracy:    0.945 
Iteration:    948: Loss:     0.357314   Batch Accuracy:    0.906 
Iteration:    949: Loss:     0.476093   Batch Accuracy:    0.891 
Iteration:    950: Loss:     0.408043   Batch Accuracy:    0.883 
Iteration:    951: Loss:     0.339016   Batch Accuracy:    0.859 
Iteration:    952: Loss:     0.268756   Batch Accuracy:    0.922 
Iteration:    953: Loss:     0.399173   Batch Accuracy:    0.883 
Iteration:    954: Loss:     0.418171   Batch Accuracy:    0.891 
Iteration:    955: Loss:     0.433503   Batch Accuracy:    0.891 
Iteration:    956: Loss:     0.436903   Batch Accuracy:    0.875 
Iteration:    957: Loss:     0.380356   Batch Accuracy:    0.906 
Iteration:    958: Loss:     0.335316   Batch Accuracy:    0.922 
Iteration:    959: Loss:     0.399846   Batch Accuracy:    0.867 
Iteration:    960: Loss:     0.256379   Batch Accuracy:    0.930 
Iteration:    961: Loss:     0.364320   Batch Accuracy:    0.914 
Iteration:    962: Loss:     0.321338   Batch Accuracy:    0.930 
Iteration:    963: Loss:     0.371247   Batch Accuracy:    0.891 
Iteration:    964: Loss:     0.253206   Batch Accuracy:    0.914 
Iteration:    965: Loss:     0.306873   Batch Accuracy:    0.914 
Iteration:    966: Loss:     0.387005   Batch Accuracy:    0.930 
Iteration:    967: Loss:     0.328121   Batch Accuracy:    0.922 
Iteration:    968: Loss:     0.518431   Batch Accuracy:    0.852 
Iteration:    969: Loss:     0.519646   Batch Accuracy:    0.883 
Iteration:    970: Loss:     0.310218   Batch Accuracy:    0.922 
Iteration:    971: Loss:     0.398567   Batch Accuracy:    0.883 
Iteration:    972: Loss:     0.417189   Batch Accuracy:    0.891 
Iteration:    973: Loss:     0.349917   Batch Accuracy:    0.914 
Iteration:    974: Loss:     0.380678   Batch Accuracy:    0.875 
Iteration:    975: Loss:     0.431579   Batch Accuracy:    0.836 
Iteration:    976: Loss:     0.326729   Batch Accuracy:    0.914 
Iteration:    977: Loss:     0.412203   Batch Accuracy:    0.898 
Iteration:    978: Loss:     0.352298   Batch Accuracy:    0.906 
Iteration:    979: Loss:     0.276101   Batch Accuracy:    0.914 
Iteration:    980: Loss:     0.377170   Batch Accuracy:    0.883 
Iteration:    981: Loss:     0.347658   Batch Accuracy:    0.891 
Iteration:    982: Loss:     0.271116   Batch Accuracy:    0.914 
Iteration:    983: Loss:     0.454987   Batch Accuracy:    0.844 
Iteration:    984: Loss:     0.279685   Batch Accuracy:    0.938 
Iteration:    985: Loss:     0.406539   Batch Accuracy:    0.891 
Iteration:    986: Loss:     0.305702   Batch Accuracy:    0.922 
Iteration:    987: Loss:     0.313746   Batch Accuracy:    0.930 
Iteration:    988: Loss:     0.371857   Batch Accuracy:    0.914 
Iteration:    989: Loss:     0.383920   Batch Accuracy:    0.914 
Iteration:    990: Loss:     0.400939   Batch Accuracy:    0.859 
Iteration:    991: Loss:     0.379283   Batch Accuracy:    0.898 
Iteration:    992: Loss:     0.343831   Batch Accuracy:    0.875 
Iteration:    993: Loss:     0.369462   Batch Accuracy:    0.883 
Iteration:    994: Loss:     0.334970   Batch Accuracy:    0.922 
Iteration:    995: Loss:     0.294903   Batch Accuracy:    0.938 
Iteration:    996: Loss:     0.374814   Batch Accuracy:    0.914 
Iteration:    997: Loss:     0.225465   Batch Accuracy:    0.938 
Iteration:    998: Loss:     0.303127   Batch Accuracy:    0.922 
Iteration:    999: Loss:     0.392895   Batch Accuracy:    0.867 
evaluating model...
training accuracy: 0.901600
test accuracy:     0.909300
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./compile.sh 
-- Configuring done
CMake Warning (dev):
  Policy CMP0042 is not set: MACOSX_RPATH is enabled by default.  Run "cmake
  --help-policy CMP0042" for policy details.  Use the cmake_policy command to
  set the policy and suppress this warning.

  MACOSX_RPATH is not specified for the following targets:

   nn

This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /Users/jasonhoffman/repos/cv576/cse576_sp20_hw3/build
[ 55%] Built target nn
Scanning dependencies of target train
[ 77%] Built target test
[ 88%] Building CXX object CMakeFiles/train.dir/src/train.cpp.o
[100%] Linking CXX executable ../train
[100%] Built target train
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ ./train
Loading dataset
Parameters: Rate=0.001000
Training model...
Iteration:      0: Loss:     2.305447   Batch Accuracy:    0.094 
Iteration:      1: Loss:     2.325351   Batch Accuracy:    0.047 
Iteration:      2: Loss:     2.329413   Batch Accuracy:    0.094 
Iteration:      3: Loss:     2.335426   Batch Accuracy:    0.078 
Iteration:      4: Loss:     2.293304   Batch Accuracy:    0.047 
Iteration:      5: Loss:     2.309836   Batch Accuracy:    0.031 
Iteration:      6: Loss:     2.301229   Batch Accuracy:    0.086 
Iteration:      7: Loss:     2.280718   Batch Accuracy:    0.141 
Iteration:      8: Loss:     2.292515   Batch Accuracy:    0.078 
Iteration:      9: Loss:     2.263387   Batch Accuracy:    0.141 
Iteration:     10: Loss:     2.283668   Batch Accuracy:    0.094 
Iteration:     11: Loss:     2.268785   Batch Accuracy:    0.164 
Iteration:     12: Loss:     2.250657   Batch Accuracy:    0.156 
Iteration:     13: Loss:     2.278127   Batch Accuracy:    0.109 
Iteration:     14: Loss:     2.227462   Batch Accuracy:    0.117 
Iteration:     15: Loss:     2.213162   Batch Accuracy:    0.117 
Iteration:     16: Loss:     2.186046   Batch Accuracy:    0.219 
Iteration:     17: Loss:     2.225745   Batch Accuracy:    0.172 
Iteration:     18: Loss:     2.216729   Batch Accuracy:    0.203 
Iteration:     19: Loss:     2.194769   Batch Accuracy:    0.234 
Iteration:     20: Loss:     2.179209   Batch Accuracy:    0.242 
Iteration:     21: Loss:     2.170590   Batch Accuracy:    0.219 
Iteration:     22: Loss:     2.136991   Batch Accuracy:    0.312 
Iteration:     23: Loss:     2.165896   Batch Accuracy:    0.234 
Iteration:     24: Loss:     2.172653   Batch Accuracy:    0.203 
Iteration:     25: Loss:     2.129099   Batch Accuracy:    0.305 
Iteration:     26: Loss:     2.107628   Batch Accuracy:    0.328 
Iteration:     27: Loss:     2.126710   Batch Accuracy:    0.289 
Iteration:     28: Loss:     2.088126   Batch Accuracy:    0.344 
Iteration:     29: Loss:     2.086729   Batch Accuracy:    0.344 
Iteration:     30: Loss:     2.088006   Batch Accuracy:    0.398 
Iteration:     31: Loss:     2.075271   Batch Accuracy:    0.398 
Iteration:     32: Loss:     2.066523   Batch Accuracy:    0.336 
Iteration:     33: Loss:     2.059367   Batch Accuracy:    0.391 
Iteration:     34: Loss:     2.051525   Batch Accuracy:    0.445 
Iteration:     35: Loss:     2.022667   Batch Accuracy:    0.461 
Iteration:     36: Loss:     2.012283   Batch Accuracy:    0.445 
Iteration:     37: Loss:     2.016652   Batch Accuracy:    0.445 
Iteration:     38: Loss:     1.952234   Batch Accuracy:    0.539 
Iteration:     39: Loss:     2.032251   Batch Accuracy:    0.430 
Iteration:     40: Loss:     2.021170   Batch Accuracy:    0.477 
Iteration:     41: Loss:     1.996155   Batch Accuracy:    0.375 
Iteration:     42: Loss:     1.982961   Batch Accuracy:    0.461 
Iteration:     43: Loss:     1.943228   Batch Accuracy:    0.539 
Iteration:     44: Loss:     1.997673   Batch Accuracy:    0.477 
Iteration:     45: Loss:     1.938374   Batch Accuracy:    0.547 
Iteration:     46: Loss:     1.918073   Batch Accuracy:    0.516 
Iteration:     47: Loss:     1.920314   Batch Accuracy:    0.602 
Iteration:     48: Loss:     1.918658   Batch Accuracy:    0.570 
Iteration:     49: Loss:     1.960264   Batch Accuracy:    0.477 
Iteration:     50: Loss:     1.986614   Batch Accuracy:    0.438 
Iteration:     51: Loss:     1.906123   Batch Accuracy:    0.578 
Iteration:     52: Loss:     1.892822   Batch Accuracy:    0.578 
Iteration:     53: Loss:     1.887802   Batch Accuracy:    0.586 
Iteration:     54: Loss:     1.921091   Batch Accuracy:    0.547 
Iteration:     55: Loss:     1.891639   Batch Accuracy:    0.570 
Iteration:     56: Loss:     1.863377   Batch Accuracy:    0.625 
Iteration:     57: Loss:     1.859385   Batch Accuracy:    0.586 
Iteration:     58: Loss:     1.804514   Batch Accuracy:    0.680 
Iteration:     59: Loss:     1.855162   Batch Accuracy:    0.594 
Iteration:     60: Loss:     1.911245   Batch Accuracy:    0.492 
Iteration:     61: Loss:     1.772235   Batch Accuracy:    0.641 
Iteration:     62: Loss:     1.872798   Batch Accuracy:    0.602 
Iteration:     63: Loss:     1.824428   Batch Accuracy:    0.586 
Iteration:     64: Loss:     1.837528   Batch Accuracy:    0.570 
Iteration:     65: Loss:     1.829960   Batch Accuracy:    0.570 
Iteration:     66: Loss:     1.770915   Batch Accuracy:    0.648 
Iteration:     67: Loss:     1.815227   Batch Accuracy:    0.641 
Iteration:     68: Loss:     1.771381   Batch Accuracy:    0.602 
Iteration:     69: Loss:     1.831664   Batch Accuracy:    0.648 
Iteration:     70: Loss:     1.823358   Batch Accuracy:    0.617 
Iteration:     71: Loss:     1.795563   Batch Accuracy:    0.641 
Iteration:     72: Loss:     1.798955   Batch Accuracy:    0.609 
Iteration:     73: Loss:     1.687458   Batch Accuracy:    0.742 
Iteration:     74: Loss:     1.681674   Batch Accuracy:    0.750 
Iteration:     75: Loss:     1.672160   Batch Accuracy:    0.695 
Iteration:     76: Loss:     1.780864   Batch Accuracy:    0.648 
Iteration:     77: Loss:     1.776908   Batch Accuracy:    0.641 
Iteration:     78: Loss:     1.687075   Batch Accuracy:    0.742 
Iteration:     79: Loss:     1.749084   Batch Accuracy:    0.664 
Iteration:     80: Loss:     1.691894   Batch Accuracy:    0.711 
Iteration:     81: Loss:     1.738518   Batch Accuracy:    0.719 
Iteration:     82: Loss:     1.693065   Batch Accuracy:    0.672 
Iteration:     83: Loss:     1.689905   Batch Accuracy:    0.664 
Iteration:     84: Loss:     1.685482   Batch Accuracy:    0.734 
Iteration:     85: Loss:     1.589830   Batch Accuracy:    0.766 
Iteration:     86: Loss:     1.687796   Batch Accuracy:    0.672 
Iteration:     87: Loss:     1.646968   Batch Accuracy:    0.766 
Iteration:     88: Loss:     1.657410   Batch Accuracy:    0.719 
Iteration:     89: Loss:     1.598634   Batch Accuracy:    0.742 
Iteration:     90: Loss:     1.662589   Batch Accuracy:    0.711 
Iteration:     91: Loss:     1.652737   Batch Accuracy:    0.656 
Iteration:     92: Loss:     1.599996   Batch Accuracy:    0.719 
Iteration:     93: Loss:     1.706603   Batch Accuracy:    0.633 
Iteration:     94: Loss:     1.615548   Batch Accuracy:    0.688 
Iteration:     95: Loss:     1.555438   Batch Accuracy:    0.750 
Iteration:     96: Loss:     1.663178   Batch Accuracy:    0.711 
Iteration:     97: Loss:     1.634133   Batch Accuracy:    0.727 
Iteration:     98: Loss:     1.624204   Batch Accuracy:    0.664 
Iteration:     99: Loss:     1.574891   Batch Accuracy:    0.734 
Iteration:    100: Loss:     1.579903   Batch Accuracy:    0.703 
Iteration:    101: Loss:     1.596457   Batch Accuracy:    0.766 
Iteration:    102: Loss:     1.523819   Batch Accuracy:    0.758 
Iteration:    103: Loss:     1.578899   Batch Accuracy:    0.734 
Iteration:    104: Loss:     1.558173   Batch Accuracy:    0.758 
Iteration:    105: Loss:     1.564236   Batch Accuracy:    0.727 
Iteration:    106: Loss:     1.604072   Batch Accuracy:    0.703 
Iteration:    107: Loss:     1.557074   Batch Accuracy:    0.727 
Iteration:    108: Loss:     1.587321   Batch Accuracy:    0.695 
Iteration:    109: Loss:     1.535129   Batch Accuracy:    0.695 
Iteration:    110: Loss:     1.530793   Batch Accuracy:    0.719 
Iteration:    111: Loss:     1.550202   Batch Accuracy:    0.711 
Iteration:    112: Loss:     1.586741   Batch Accuracy:    0.688 
Iteration:    113: Loss:     1.528958   Batch Accuracy:    0.695 
Iteration:    114: Loss:     1.468171   Batch Accuracy:    0.750 
Iteration:    115: Loss:     1.525251   Batch Accuracy:    0.773 
Iteration:    116: Loss:     1.515918   Batch Accuracy:    0.781 
Iteration:    117: Loss:     1.463471   Batch Accuracy:    0.750 
Iteration:    118: Loss:     1.517306   Batch Accuracy:    0.695 
Iteration:    119: Loss:     1.494568   Batch Accuracy:    0.758 
Iteration:    120: Loss:     1.510769   Batch Accuracy:    0.719 
Iteration:    121: Loss:     1.486517   Batch Accuracy:    0.719 
Iteration:    122: Loss:     1.439020   Batch Accuracy:    0.789 
Iteration:    123: Loss:     1.493444   Batch Accuracy:    0.750 
Iteration:    124: Loss:     1.565072   Batch Accuracy:    0.641 
Iteration:    125: Loss:     1.483354   Batch Accuracy:    0.766 
Iteration:    126: Loss:     1.453278   Batch Accuracy:    0.727 
Iteration:    127: Loss:     1.455621   Batch Accuracy:    0.742 
Iteration:    128: Loss:     1.460489   Batch Accuracy:    0.750 
Iteration:    129: Loss:     1.439878   Batch Accuracy:    0.742 
Iteration:    130: Loss:     1.477784   Batch Accuracy:    0.758 
Iteration:    131: Loss:     1.464363   Batch Accuracy:    0.719 
Iteration:    132: Loss:     1.435676   Batch Accuracy:    0.727 
Iteration:    133: Loss:     1.389087   Batch Accuracy:    0.750 
Iteration:    134: Loss:     1.497832   Batch Accuracy:    0.695 
Iteration:    135: Loss:     1.395812   Batch Accuracy:    0.734 
Iteration:    136: Loss:     1.440513   Batch Accuracy:    0.789 
Iteration:    137: Loss:     1.458775   Batch Accuracy:    0.750 
Iteration:    138: Loss:     1.476426   Batch Accuracy:    0.688 
Iteration:    139: Loss:     1.447672   Batch Accuracy:    0.703 
Iteration:    140: Loss:     1.418575   Batch Accuracy:    0.750 
Iteration:    141: Loss:     1.436421   Batch Accuracy:    0.773 
Iteration:    142: Loss:     1.383723   Batch Accuracy:    0.805 
Iteration:    143: Loss:     1.336191   Batch Accuracy:    0.812 
Iteration:    144: Loss:     1.436134   Batch Accuracy:    0.773 
Iteration:    145: Loss:     1.443306   Batch Accuracy:    0.773 
Iteration:    146: Loss:     1.417718   Batch Accuracy:    0.758 
Iteration:    147: Loss:     1.334663   Batch Accuracy:    0.750 
Iteration:    148: Loss:     1.396375   Batch Accuracy:    0.758 
Iteration:    149: Loss:     1.376830   Batch Accuracy:    0.734 
Iteration:    150: Loss:     1.428015   Batch Accuracy:    0.711 
Iteration:    151: Loss:     1.392693   Batch Accuracy:    0.750 
Iteration:    152: Loss:     1.304897   Batch Accuracy:    0.812 
Iteration:    153: Loss:     1.411499   Batch Accuracy:    0.719 
Iteration:    154: Loss:     1.348668   Batch Accuracy:    0.781 
Iteration:    155: Loss:     1.429073   Batch Accuracy:    0.766 
Iteration:    156: Loss:     1.339619   Batch Accuracy:    0.766 
Iteration:    157: Loss:     1.291369   Batch Accuracy:    0.844 
Iteration:    158: Loss:     1.325885   Batch Accuracy:    0.781 
Iteration:    159: Loss:     1.358888   Batch Accuracy:    0.789 
Iteration:    160: Loss:     1.345853   Batch Accuracy:    0.758 
Iteration:    161: Loss:     1.419565   Batch Accuracy:    0.727 
Iteration:    162: Loss:     1.303151   Batch Accuracy:    0.789 
Iteration:    163: Loss:     1.365586   Batch Accuracy:    0.766 
Iteration:    164: Loss:     1.288410   Batch Accuracy:    0.758 
Iteration:    165: Loss:     1.312158   Batch Accuracy:    0.781 
Iteration:    166: Loss:     1.350551   Batch Accuracy:    0.688 
Iteration:    167: Loss:     1.291370   Batch Accuracy:    0.797 
Iteration:    168: Loss:     1.319779   Batch Accuracy:    0.750 
Iteration:    169: Loss:     1.244776   Batch Accuracy:    0.805 
Iteration:    170: Loss:     1.281294   Batch Accuracy:    0.797 
Iteration:    171: Loss:     1.296855   Batch Accuracy:    0.789 
Iteration:    172: Loss:     1.373383   Batch Accuracy:    0.758 
Iteration:    173: Loss:     1.353527   Batch Accuracy:    0.812 
Iteration:    174: Loss:     1.314541   Batch Accuracy:    0.766 
Iteration:    175: Loss:     1.257895   Batch Accuracy:    0.797 
Iteration:    176: Loss:     1.276677   Batch Accuracy:    0.781 
Iteration:    177: Loss:     1.331863   Batch Accuracy:    0.773 
Iteration:    178: Loss:     1.210350   Batch Accuracy:    0.820 
Iteration:    179: Loss:     1.302779   Batch Accuracy:    0.766 
Iteration:    180: Loss:     1.203374   Batch Accuracy:    0.836 
Iteration:    181: Loss:     1.275551   Batch Accuracy:    0.812 
Iteration:    182: Loss:     1.259902   Batch Accuracy:    0.812 
Iteration:    183: Loss:     1.199694   Batch Accuracy:    0.781 
Iteration:    184: Loss:     1.317775   Batch Accuracy:    0.695 
Iteration:    185: Loss:     1.170481   Batch Accuracy:    0.781 
Iteration:    186: Loss:     1.230364   Batch Accuracy:    0.828 
Iteration:    187: Loss:     1.281867   Batch Accuracy:    0.766 
Iteration:    188: Loss:     1.236429   Batch Accuracy:    0.797 
Iteration:    189: Loss:     1.233344   Batch Accuracy:    0.789 
Iteration:    190: Loss:     1.235126   Batch Accuracy:    0.758 
Iteration:    191: Loss:     1.161155   Batch Accuracy:    0.805 
Iteration:    192: Loss:     1.174756   Batch Accuracy:    0.852 
Iteration:    193: Loss:     1.234272   Batch Accuracy:    0.781 
Iteration:    194: Loss:     1.258901   Batch Accuracy:    0.766 
Iteration:    195: Loss:     1.229352   Batch Accuracy:    0.727 
Iteration:    196: Loss:     1.215186   Batch Accuracy:    0.805 
Iteration:    197: Loss:     1.167740   Batch Accuracy:    0.805 
Iteration:    198: Loss:     1.208301   Batch Accuracy:    0.781 
Iteration:    199: Loss:     1.296940   Batch Accuracy:    0.711 
Iteration:    200: Loss:     1.204592   Batch Accuracy:    0.805 
Iteration:    201: Loss:     1.246041   Batch Accuracy:    0.750 
Iteration:    202: Loss:     1.245818   Batch Accuracy:    0.758 
Iteration:    203: Loss:     1.170203   Batch Accuracy:    0.773 
Iteration:    204: Loss:     1.291233   Batch Accuracy:    0.758 
Iteration:    205: Loss:     1.136632   Batch Accuracy:    0.805 
Iteration:    206: Loss:     1.100767   Batch Accuracy:    0.828 
Iteration:    207: Loss:     1.149355   Batch Accuracy:    0.867 
Iteration:    208: Loss:     1.206062   Batch Accuracy:    0.727 
Iteration:    209: Loss:     1.032742   Batch Accuracy:    0.852 
Iteration:    210: Loss:     1.138693   Batch Accuracy:    0.812 
Iteration:    211: Loss:     1.186046   Batch Accuracy:    0.797 
Iteration:    212: Loss:     1.147432   Batch Accuracy:    0.805 
Iteration:    213: Loss:     1.218482   Batch Accuracy:    0.734 
Iteration:    214: Loss:     1.198763   Batch Accuracy:    0.781 
Iteration:    215: Loss:     1.176085   Batch Accuracy:    0.781 
Iteration:    216: Loss:     1.247702   Batch Accuracy:    0.758 
Iteration:    217: Loss:     1.115411   Batch Accuracy:    0.844 
Iteration:    218: Loss:     1.132144   Batch Accuracy:    0.852 
Iteration:    219: Loss:     1.133982   Batch Accuracy:    0.820 
Iteration:    220: Loss:     1.210749   Batch Accuracy:    0.789 
Iteration:    221: Loss:     1.075167   Batch Accuracy:    0.891 
Iteration:    222: Loss:     1.144198   Batch Accuracy:    0.750 
Iteration:    223: Loss:     1.229646   Batch Accuracy:    0.766 
Iteration:    224: Loss:     1.235625   Batch Accuracy:    0.773 
Iteration:    225: Loss:     1.099013   Batch Accuracy:    0.812 
Iteration:    226: Loss:     1.213979   Batch Accuracy:    0.688 
Iteration:    227: Loss:     1.228057   Batch Accuracy:    0.773 
Iteration:    228: Loss:     1.159636   Batch Accuracy:    0.820 
Iteration:    229: Loss:     1.071106   Batch Accuracy:    0.852 
Iteration:    230: Loss:     1.122990   Batch Accuracy:    0.789 
Iteration:    231: Loss:     1.071595   Batch Accuracy:    0.852 
Iteration:    232: Loss:     1.082887   Batch Accuracy:    0.820 
Iteration:    233: Loss:     1.168865   Batch Accuracy:    0.766 
Iteration:    234: Loss:     1.019547   Batch Accuracy:    0.875 
Iteration:    235: Loss:     1.158571   Batch Accuracy:    0.742 
Iteration:    236: Loss:     1.034901   Batch Accuracy:    0.844 
Iteration:    237: Loss:     1.101409   Batch Accuracy:    0.820 
Iteration:    238: Loss:     1.124601   Batch Accuracy:    0.781 
Iteration:    239: Loss:     1.228175   Batch Accuracy:    0.766 
Iteration:    240: Loss:     1.129118   Batch Accuracy:    0.812 
Iteration:    241: Loss:     1.142016   Batch Accuracy:    0.773 
Iteration:    242: Loss:     1.072256   Batch Accuracy:    0.844 
Iteration:    243: Loss:     1.087910   Batch Accuracy:    0.852 
Iteration:    244: Loss:     1.109861   Batch Accuracy:    0.766 
Iteration:    245: Loss:     1.086176   Batch Accuracy:    0.820 
Iteration:    246: Loss:     1.078132   Batch Accuracy:    0.805 
Iteration:    247: Loss:     1.076044   Batch Accuracy:    0.820 
Iteration:    248: Loss:     1.126312   Batch Accuracy:    0.805 
Iteration:    249: Loss:     1.045465   Batch Accuracy:    0.836 
Iteration:    250: Loss:     1.091719   Batch Accuracy:    0.820 
Iteration:    251: Loss:     1.108569   Batch Accuracy:    0.781 
Iteration:    252: Loss:     1.138407   Batch Accuracy:    0.742 
Iteration:    253: Loss:     1.113160   Batch Accuracy:    0.820 
Iteration:    254: Loss:     1.140431   Batch Accuracy:    0.750 
Iteration:    255: Loss:     1.111730   Batch Accuracy:    0.773 
Iteration:    256: Loss:     1.098145   Batch Accuracy:    0.797 
Iteration:    257: Loss:     1.103677   Batch Accuracy:    0.820 
Iteration:    258: Loss:     1.119465   Batch Accuracy:    0.797 
Iteration:    259: Loss:     1.061743   Batch Accuracy:    0.812 
Iteration:    260: Loss:     1.134799   Batch Accuracy:    0.773 
Iteration:    261: Loss:     1.101773   Batch Accuracy:    0.789 
Iteration:    262: Loss:     1.134553   Batch Accuracy:    0.797 
Iteration:    263: Loss:     1.039908   Batch Accuracy:    0.844 
Iteration:    264: Loss:     1.164412   Batch Accuracy:    0.781 
Iteration:    265: Loss:     1.197664   Batch Accuracy:    0.734 
Iteration:    266: Loss:     1.035905   Batch Accuracy:    0.812 
Iteration:    267: Loss:     0.981953   Batch Accuracy:    0.836 
Iteration:    268: Loss:     1.085478   Batch Accuracy:    0.797 
Iteration:    269: Loss:     1.021395   Batch Accuracy:    0.836 
Iteration:    270: Loss:     1.028321   Batch Accuracy:    0.812 
Iteration:    271: Loss:     1.065113   Batch Accuracy:    0.828 
Iteration:    272: Loss:     1.097463   Batch Accuracy:    0.797 
Iteration:    273: Loss:     1.080644   Batch Accuracy:    0.820 
Iteration:    274: Loss:     1.105804   Batch Accuracy:    0.773 
Iteration:    275: Loss:     1.084176   Batch Accuracy:    0.789 
Iteration:    276: Loss:     1.104824   Batch Accuracy:    0.789 
Iteration:    277: Loss:     1.173763   Batch Accuracy:    0.758 
Iteration:    278: Loss:     1.044016   Batch Accuracy:    0.812 
Iteration:    279: Loss:     1.031294   Batch Accuracy:    0.859 
Iteration:    280: Loss:     1.132202   Batch Accuracy:    0.758 
Iteration:    281: Loss:     1.025692   Batch Accuracy:    0.797 
Iteration:    282: Loss:     1.078373   Batch Accuracy:    0.773 
Iteration:    283: Loss:     1.044905   Batch Accuracy:    0.828 
Iteration:    284: Loss:     1.108512   Batch Accuracy:    0.758 
Iteration:    285: Loss:     0.973823   Batch Accuracy:    0.789 
Iteration:    286: Loss:     1.045783   Batch Accuracy:    0.812 
Iteration:    287: Loss:     1.029133   Batch Accuracy:    0.812 
Iteration:    288: Loss:     1.083032   Batch Accuracy:    0.781 
Iteration:    289: Loss:     1.170664   Batch Accuracy:    0.750 
Iteration:    290: Loss:     0.995207   Batch Accuracy:    0.828 
Iteration:    291: Loss:     1.092133   Batch Accuracy:    0.789 
Iteration:    292: Loss:     1.005738   Batch Accuracy:    0.812 
Iteration:    293: Loss:     0.935180   Batch Accuracy:    0.859 
Iteration:    294: Loss:     1.033344   Batch Accuracy:    0.773 
Iteration:    295: Loss:     1.022252   Batch Accuracy:    0.789 
Iteration:    296: Loss:     1.024027   Batch Accuracy:    0.789 
Iteration:    297: Loss:     1.020438   Batch Accuracy:    0.820 
Iteration:    298: Loss:     1.043279   Batch Accuracy:    0.820 
Iteration:    299: Loss:     1.085832   Batch Accuracy:    0.750 
Iteration:    300: Loss:     0.994220   Batch Accuracy:    0.797 
Iteration:    301: Loss:     0.994494   Batch Accuracy:    0.844 
Iteration:    302: Loss:     0.923986   Batch Accuracy:    0.836 
Iteration:    303: Loss:     1.050305   Batch Accuracy:    0.812 
Iteration:    304: Loss:     1.052029   Batch Accuracy:    0.797 
Iteration:    305: Loss:     0.931177   Batch Accuracy:    0.805 
Iteration:    306: Loss:     0.856598   Batch Accuracy:    0.938 
Iteration:    307: Loss:     0.921145   Batch Accuracy:    0.844 
Iteration:    308: Loss:     1.056352   Batch Accuracy:    0.773 
Iteration:    309: Loss:     0.910093   Batch Accuracy:    0.828 
Iteration:    310: Loss:     0.983260   Batch Accuracy:    0.789 
Iteration:    311: Loss:     0.992284   Batch Accuracy:    0.781 
Iteration:    312: Loss:     0.924940   Batch Accuracy:    0.867 
Iteration:    313: Loss:     1.031080   Batch Accuracy:    0.812 
Iteration:    314: Loss:     1.051333   Batch Accuracy:    0.797 
Iteration:    315: Loss:     1.007780   Batch Accuracy:    0.797 
Iteration:    316: Loss:     0.935583   Batch Accuracy:    0.789 
Iteration:    317: Loss:     0.995222   Batch Accuracy:    0.820 
Iteration:    318: Loss:     1.032915   Batch Accuracy:    0.766 
Iteration:    319: Loss:     0.980684   Batch Accuracy:    0.836 
Iteration:    320: Loss:     1.040457   Batch Accuracy:    0.812 
Iteration:    321: Loss:     1.074578   Batch Accuracy:    0.789 
Iteration:    322: Loss:     0.986478   Batch Accuracy:    0.805 
Iteration:    323: Loss:     0.865396   Batch Accuracy:    0.875 
Iteration:    324: Loss:     0.990569   Batch Accuracy:    0.828 
Iteration:    325: Loss:     0.933886   Batch Accuracy:    0.859 
Iteration:    326: Loss:     0.986306   Batch Accuracy:    0.836 
Iteration:    327: Loss:     0.951082   Batch Accuracy:    0.852 
Iteration:    328: Loss:     0.916127   Batch Accuracy:    0.852 
Iteration:    329: Loss:     1.044286   Batch Accuracy:    0.773 
Iteration:    330: Loss:     0.816668   Batch Accuracy:    0.938 
Iteration:    331: Loss:     0.916992   Batch Accuracy:    0.867 
Iteration:    332: Loss:     0.962026   Batch Accuracy:    0.820 
Iteration:    333: Loss:     0.966291   Batch Accuracy:    0.836 
Iteration:    334: Loss:     1.044801   Batch Accuracy:    0.766 
Iteration:    335: Loss:     0.878203   Batch Accuracy:    0.867 
Iteration:    336: Loss:     0.870810   Batch Accuracy:    0.844 
Iteration:    337: Loss:     0.924515   Batch Accuracy:    0.844 
Iteration:    338: Loss:     0.942387   Batch Accuracy:    0.812 
Iteration:    339: Loss:     1.002642   Batch Accuracy:    0.828 
Iteration:    340: Loss:     0.936901   Batch Accuracy:    0.797 
Iteration:    341: Loss:     0.978580   Batch Accuracy:    0.828 
Iteration:    342: Loss:     0.992554   Batch Accuracy:    0.805 
Iteration:    343: Loss:     0.931762   Batch Accuracy:    0.805 
Iteration:    344: Loss:     0.970204   Batch Accuracy:    0.859 
Iteration:    345: Loss:     1.034340   Batch Accuracy:    0.781 
Iteration:    346: Loss:     0.929356   Batch Accuracy:    0.875 
Iteration:    347: Loss:     0.931924   Batch Accuracy:    0.812 
Iteration:    348: Loss:     1.022705   Batch Accuracy:    0.773 
Iteration:    349: Loss:     0.966047   Batch Accuracy:    0.805 
Iteration:    350: Loss:     0.900274   Batch Accuracy:    0.875 
Iteration:    351: Loss:     0.896843   Batch Accuracy:    0.820 
Iteration:    352: Loss:     0.885616   Batch Accuracy:    0.828 
Iteration:    353: Loss:     0.992238   Batch Accuracy:    0.844 
Iteration:    354: Loss:     0.942016   Batch Accuracy:    0.820 
Iteration:    355: Loss:     0.960171   Batch Accuracy:    0.828 
Iteration:    356: Loss:     0.921572   Batch Accuracy:    0.820 
Iteration:    357: Loss:     0.903378   Batch Accuracy:    0.781 
Iteration:    358: Loss:     0.841043   Batch Accuracy:    0.867 
Iteration:    359: Loss:     0.818869   Batch Accuracy:    0.836 
Iteration:    360: Loss:     0.953758   Batch Accuracy:    0.805 
Iteration:    361: Loss:     0.953546   Batch Accuracy:    0.812 
Iteration:    362: Loss:     0.930034   Batch Accuracy:    0.828 
Iteration:    363: Loss:     0.956945   Batch Accuracy:    0.789 
Iteration:    364: Loss:     0.867098   Batch Accuracy:    0.867 
Iteration:    365: Loss:     0.957650   Batch Accuracy:    0.812 
Iteration:    366: Loss:     1.083624   Batch Accuracy:    0.742 
Iteration:    367: Loss:     0.872046   Batch Accuracy:    0.844 
Iteration:    368: Loss:     0.913360   Batch Accuracy:    0.844 
Iteration:    369: Loss:     1.000634   Batch Accuracy:    0.742 
Iteration:    370: Loss:     0.903000   Batch Accuracy:    0.828 
Iteration:    371: Loss:     0.898225   Batch Accuracy:    0.859 
Iteration:    372: Loss:     0.920299   Batch Accuracy:    0.805 
Iteration:    373: Loss:     0.832674   Batch Accuracy:    0.883 
Iteration:    374: Loss:     0.876646   Batch Accuracy:    0.836 
Iteration:    375: Loss:     0.893360   Batch Accuracy:    0.828 
Iteration:    376: Loss:     0.814658   Batch Accuracy:    0.867 
Iteration:    377: Loss:     0.959218   Batch Accuracy:    0.805 
Iteration:    378: Loss:     0.895411   Batch Accuracy:    0.859 
Iteration:    379: Loss:     0.958555   Batch Accuracy:    0.805 
Iteration:    380: Loss:     0.967427   Batch Accuracy:    0.836 
Iteration:    381: Loss:     0.962921   Batch Accuracy:    0.781 
Iteration:    382: Loss:     0.911091   Batch Accuracy:    0.852 
Iteration:    383: Loss:     0.836299   Batch Accuracy:    0.836 
Iteration:    384: Loss:     0.935773   Batch Accuracy:    0.773 
Iteration:    385: Loss:     0.838759   Batch Accuracy:    0.852 
Iteration:    386: Loss:     0.911714   Batch Accuracy:    0.805 
Iteration:    387: Loss:     0.877647   Batch Accuracy:    0.836 
Iteration:    388: Loss:     0.962461   Batch Accuracy:    0.805 
Iteration:    389: Loss:     0.898155   Batch Accuracy:    0.820 
Iteration:    390: Loss:     0.916432   Batch Accuracy:    0.812 
Iteration:    391: Loss:     0.858163   Batch Accuracy:    0.898 
Iteration:    392: Loss:     0.895341   Batch Accuracy:    0.844 
Iteration:    393: Loss:     0.920436   Batch Accuracy:    0.797 
Iteration:    394: Loss:     0.935790   Batch Accuracy:    0.812 
Iteration:    395: Loss:     0.911767   Batch Accuracy:    0.828 
Iteration:    396: Loss:     0.837510   Batch Accuracy:    0.875 
Iteration:    397: Loss:     0.915705   Batch Accuracy:    0.805 
Iteration:    398: Loss:     0.918654   Batch Accuracy:    0.820 
Iteration:    399: Loss:     1.006243   Batch Accuracy:    0.797 
Iteration:    400: Loss:     0.813214   Batch Accuracy:    0.891 
Iteration:    401: Loss:     0.888255   Batch Accuracy:    0.859 
Iteration:    402: Loss:     0.832451   Batch Accuracy:    0.883 
Iteration:    403: Loss:     0.892847   Batch Accuracy:    0.836 
Iteration:    404: Loss:     0.840277   Batch Accuracy:    0.859 
Iteration:    405: Loss:     0.873002   Batch Accuracy:    0.820 
Iteration:    406: Loss:     0.913917   Batch Accuracy:    0.797 
Iteration:    407: Loss:     0.780338   Batch Accuracy:    0.859 
Iteration:    408: Loss:     0.998171   Batch Accuracy:    0.766 
Iteration:    409: Loss:     0.830881   Batch Accuracy:    0.852 
Iteration:    410: Loss:     0.934797   Batch Accuracy:    0.773 
Iteration:    411: Loss:     0.786360   Batch Accuracy:    0.898 
Iteration:    412: Loss:     0.845369   Batch Accuracy:    0.828 
Iteration:    413: Loss:     0.896645   Batch Accuracy:    0.797 
Iteration:    414: Loss:     0.831633   Batch Accuracy:    0.852 
Iteration:    415: Loss:     0.902354   Batch Accuracy:    0.820 
Iteration:    416: Loss:     0.945831   Batch Accuracy:    0.773 
Iteration:    417: Loss:     0.955718   Batch Accuracy:    0.781 
Iteration:    418: Loss:     0.960168   Batch Accuracy:    0.758 
Iteration:    419: Loss:     0.875216   Batch Accuracy:    0.789 
Iteration:    420: Loss:     0.886023   Batch Accuracy:    0.797 
Iteration:    421: Loss:     0.860949   Batch Accuracy:    0.844 
Iteration:    422: Loss:     0.845727   Batch Accuracy:    0.844 
Iteration:    423: Loss:     0.851276   Batch Accuracy:    0.836 
Iteration:    424: Loss:     0.942275   Batch Accuracy:    0.828 
Iteration:    425: Loss:     0.815527   Batch Accuracy:    0.844 
Iteration:    426: Loss:     0.866316   Batch Accuracy:    0.820 
Iteration:    427: Loss:     0.895288   Batch Accuracy:    0.812 
Iteration:    428: Loss:     0.781757   Batch Accuracy:    0.867 
Iteration:    429: Loss:     0.817048   Batch Accuracy:    0.844 
Iteration:    430: Loss:     0.832298   Batch Accuracy:    0.797 
Iteration:    431: Loss:     0.886415   Batch Accuracy:    0.805 
Iteration:    432: Loss:     0.854670   Batch Accuracy:    0.828 
Iteration:    433: Loss:     0.906086   Batch Accuracy:    0.789 
Iteration:    434: Loss:     0.799763   Batch Accuracy:    0.828 
Iteration:    435: Loss:     0.784479   Batch Accuracy:    0.852 
Iteration:    436: Loss:     0.844410   Batch Accuracy:    0.891 
Iteration:    437: Loss:     0.847410   Batch Accuracy:    0.867 
Iteration:    438: Loss:     0.957048   Batch Accuracy:    0.758 
Iteration:    439: Loss:     0.771414   Batch Accuracy:    0.852 
Iteration:    440: Loss:     0.799802   Batch Accuracy:    0.852 
Iteration:    441: Loss:     0.809675   Batch Accuracy:    0.844 
Iteration:    442: Loss:     0.914178   Batch Accuracy:    0.836 
Iteration:    443: Loss:     0.841727   Batch Accuracy:    0.836 
Iteration:    444: Loss:     0.831349   Batch Accuracy:    0.898 
Iteration:    445: Loss:     0.765334   Batch Accuracy:    0.898 
Iteration:    446: Loss:     0.834156   Batch Accuracy:    0.828 
Iteration:    447: Loss:     0.807966   Batch Accuracy:    0.836 
Iteration:    448: Loss:     0.783688   Batch Accuracy:    0.844 
Iteration:    449: Loss:     0.829669   Batch Accuracy:    0.812 
Iteration:    450: Loss:     0.856814   Batch Accuracy:    0.828 
Iteration:    451: Loss:     0.823266   Batch Accuracy:    0.836 
Iteration:    452: Loss:     0.849077   Batch Accuracy:    0.812 
Iteration:    453: Loss:     0.766353   Batch Accuracy:    0.883 
Iteration:    454: Loss:     0.778674   Batch Accuracy:    0.836 
Iteration:    455: Loss:     0.928252   Batch Accuracy:    0.836 
Iteration:    456: Loss:     0.778567   Batch Accuracy:    0.891 
Iteration:    457: Loss:     0.734345   Batch Accuracy:    0.844 
Iteration:    458: Loss:     0.911935   Batch Accuracy:    0.773 
Iteration:    459: Loss:     0.821151   Batch Accuracy:    0.812 
Iteration:    460: Loss:     0.756452   Batch Accuracy:    0.906 
Iteration:    461: Loss:     0.887426   Batch Accuracy:    0.852 
Iteration:    462: Loss:     0.906553   Batch Accuracy:    0.820 
Iteration:    463: Loss:     0.851697   Batch Accuracy:    0.828 
Iteration:    464: Loss:     0.866293   Batch Accuracy:    0.828 
Iteration:    465: Loss:     0.878131   Batch Accuracy:    0.805 
Iteration:    466: Loss:     0.787576   Batch Accuracy:    0.875 
Iteration:    467: Loss:     0.879764   Batch Accuracy:    0.797 
Iteration:    468: Loss:     0.948118   Batch Accuracy:    0.766 
Iteration:    469: Loss:     0.761683   Batch Accuracy:    0.820 
Iteration:    470: Loss:     0.903525   Batch Accuracy:    0.773 
Iteration:    471: Loss:     0.855440   Batch Accuracy:    0.820 
Iteration:    472: Loss:     0.780508   Batch Accuracy:    0.820 
Iteration:    473: Loss:     0.797007   Batch Accuracy:    0.891 
Iteration:    474: Loss:     0.852963   Batch Accuracy:    0.812 
Iteration:    475: Loss:     0.774894   Batch Accuracy:    0.828 
Iteration:    476: Loss:     0.868738   Batch Accuracy:    0.797 
Iteration:    477: Loss:     0.837259   Batch Accuracy:    0.812 
Iteration:    478: Loss:     0.862197   Batch Accuracy:    0.844 
Iteration:    479: Loss:     0.829689   Batch Accuracy:    0.828 
Iteration:    480: Loss:     0.762264   Batch Accuracy:    0.852 
Iteration:    481: Loss:     0.880655   Batch Accuracy:    0.828 
Iteration:    482: Loss:     0.792575   Batch Accuracy:    0.859 
Iteration:    483: Loss:     0.795144   Batch Accuracy:    0.812 
Iteration:    484: Loss:     0.736833   Batch Accuracy:    0.844 
Iteration:    485: Loss:     0.739513   Batch Accuracy:    0.844 
Iteration:    486: Loss:     0.809136   Batch Accuracy:    0.883 
Iteration:    487: Loss:     0.803722   Batch Accuracy:    0.828 
Iteration:    488: Loss:     0.783946   Batch Accuracy:    0.883 
Iteration:    489: Loss:     0.805131   Batch Accuracy:    0.820 
Iteration:    490: Loss:     0.743943   Batch Accuracy:    0.852 
Iteration:    491: Loss:     0.800369   Batch Accuracy:    0.844 
Iteration:    492: Loss:     0.821618   Batch Accuracy:    0.844 
Iteration:    493: Loss:     0.766786   Batch Accuracy:    0.867 
Iteration:    494: Loss:     0.748660   Batch Accuracy:    0.875 
Iteration:    495: Loss:     0.848171   Batch Accuracy:    0.789 
Iteration:    496: Loss:     0.965296   Batch Accuracy:    0.781 
Iteration:    497: Loss:     0.764025   Batch Accuracy:    0.867 
Iteration:    498: Loss:     0.668254   Batch Accuracy:    0.859 
Iteration:    499: Loss:     0.762662   Batch Accuracy:    0.883 
Iteration:    500: Loss:     0.760809   Batch Accuracy:    0.867 
Iteration:    501: Loss:     0.795542   Batch Accuracy:    0.836 
Iteration:    502: Loss:     0.842219   Batch Accuracy:    0.859 
Iteration:    503: Loss:     0.895969   Batch Accuracy:    0.805 
Iteration:    504: Loss:     0.757299   Batch Accuracy:    0.875 
Iteration:    505: Loss:     0.890557   Batch Accuracy:    0.805 
Iteration:    506: Loss:     0.778967   Batch Accuracy:    0.828 
Iteration:    507: Loss:     0.778778   Batch Accuracy:    0.859 
Iteration:    508: Loss:     0.691506   Batch Accuracy:    0.891 
Iteration:    509: Loss:     0.750074   Batch Accuracy:    0.859 
Iteration:    510: Loss:     0.858992   Batch Accuracy:    0.820 
Iteration:    511: Loss:     0.932923   Batch Accuracy:    0.758 
Iteration:    512: Loss:     0.704210   Batch Accuracy:    0.883 
Iteration:    513: Loss:     0.764164   Batch Accuracy:    0.844 
Iteration:    514: Loss:     0.750416   Batch Accuracy:    0.859 
Iteration:    515: Loss:     0.752253   Batch Accuracy:    0.859 
Iteration:    516: Loss:     0.792683   Batch Accuracy:    0.828 
Iteration:    517: Loss:     0.729632   Batch Accuracy:    0.875 
Iteration:    518: Loss:     0.788385   Batch Accuracy:    0.844 
Iteration:    519: Loss:     0.678760   Batch Accuracy:    0.859 
Iteration:    520: Loss:     0.716442   Batch Accuracy:    0.891 
Iteration:    521: Loss:     0.850425   Batch Accuracy:    0.812 
Iteration:    522: Loss:     0.841174   Batch Accuracy:    0.789 
Iteration:    523: Loss:     0.787779   Batch Accuracy:    0.836 
Iteration:    524: Loss:     0.950453   Batch Accuracy:    0.742 
Iteration:    525: Loss:     0.780431   Batch Accuracy:    0.812 
Iteration:    526: Loss:     0.746909   Batch Accuracy:    0.828 
Iteration:    527: Loss:     0.796296   Batch Accuracy:    0.805 
Iteration:    528: Loss:     0.676343   Batch Accuracy:    0.922 
Iteration:    529: Loss:     0.740584   Batch Accuracy:    0.836 
Iteration:    530: Loss:     0.799741   Batch Accuracy:    0.789 
Iteration:    531: Loss:     0.835346   Batch Accuracy:    0.859 
Iteration:    532: Loss:     0.814077   Batch Accuracy:    0.836 
Iteration:    533: Loss:     0.781165   Batch Accuracy:    0.828 
Iteration:    534: Loss:     0.791842   Batch Accuracy:    0.828 
Iteration:    535: Loss:     0.715298   Batch Accuracy:    0.852 
Iteration:    536: Loss:     0.786995   Batch Accuracy:    0.844 
Iteration:    537: Loss:     0.766906   Batch Accuracy:    0.812 
Iteration:    538: Loss:     0.866105   Batch Accuracy:    0.828 
Iteration:    539: Loss:     0.813933   Batch Accuracy:    0.836 
Iteration:    540: Loss:     0.850087   Batch Accuracy:    0.789 
Iteration:    541: Loss:     0.756179   Batch Accuracy:    0.883 
Iteration:    542: Loss:     0.907051   Batch Accuracy:    0.805 
Iteration:    543: Loss:     0.795267   Batch Accuracy:    0.789 
Iteration:    544: Loss:     0.686526   Batch Accuracy:    0.852 
Iteration:    545: Loss:     0.749174   Batch Accuracy:    0.891 
Iteration:    546: Loss:     0.787001   Batch Accuracy:    0.805 
Iteration:    547: Loss:     0.771579   Batch Accuracy:    0.852 
Iteration:    548: Loss:     0.875078   Batch Accuracy:    0.781 
Iteration:    549: Loss:     0.784641   Batch Accuracy:    0.820 
Iteration:    550: Loss:     0.722030   Batch Accuracy:    0.875 
Iteration:    551: Loss:     0.807660   Batch Accuracy:    0.797 
Iteration:    552: Loss:     0.680028   Batch Accuracy:    0.898 
Iteration:    553: Loss:     0.760169   Batch Accuracy:    0.859 
Iteration:    554: Loss:     0.861697   Batch Accuracy:    0.812 
Iteration:    555: Loss:     0.764931   Batch Accuracy:    0.852 
Iteration:    556: Loss:     0.799730   Batch Accuracy:    0.836 
Iteration:    557: Loss:     0.679371   Batch Accuracy:    0.859 
Iteration:    558: Loss:     0.849502   Batch Accuracy:    0.812 
Iteration:    559: Loss:     0.757326   Batch Accuracy:    0.836 
Iteration:    560: Loss:     0.725153   Batch Accuracy:    0.883 
Iteration:    561: Loss:     0.754499   Batch Accuracy:    0.859 
Iteration:    562: Loss:     0.806463   Batch Accuracy:    0.820 
Iteration:    563: Loss:     0.827879   Batch Accuracy:    0.836 
Iteration:    564: Loss:     0.796108   Batch Accuracy:    0.844 
Iteration:    565: Loss:     0.702951   Batch Accuracy:    0.891 
Iteration:    566: Loss:     0.864138   Batch Accuracy:    0.828 
Iteration:    567: Loss:     0.703634   Batch Accuracy:    0.859 
Iteration:    568: Loss:     0.736813   Batch Accuracy:    0.836 
Iteration:    569: Loss:     0.831770   Batch Accuracy:    0.844 
Iteration:    570: Loss:     0.745871   Batch Accuracy:    0.867 
Iteration:    571: Loss:     0.730495   Batch Accuracy:    0.883 
Iteration:    572: Loss:     0.746917   Batch Accuracy:    0.859 
Iteration:    573: Loss:     0.688311   Batch Accuracy:    0.867 
Iteration:    574: Loss:     0.837569   Batch Accuracy:    0.828 
Iteration:    575: Loss:     0.700237   Batch Accuracy:    0.852 
Iteration:    576: Loss:     0.761261   Batch Accuracy:    0.828 
Iteration:    577: Loss:     0.762160   Batch Accuracy:    0.797 
Iteration:    578: Loss:     0.819344   Batch Accuracy:    0.781 
Iteration:    579: Loss:     0.626094   Batch Accuracy:    0.922 
Iteration:    580: Loss:     0.765886   Batch Accuracy:    0.852 
Iteration:    581: Loss:     0.721149   Batch Accuracy:    0.891 
Iteration:    582: Loss:     0.687239   Batch Accuracy:    0.875 
Iteration:    583: Loss:     0.743161   Batch Accuracy:    0.867 
Iteration:    584: Loss:     0.694426   Batch Accuracy:    0.883 
Iteration:    585: Loss:     0.725074   Batch Accuracy:    0.836 
Iteration:    586: Loss:     0.691629   Batch Accuracy:    0.883 
Iteration:    587: Loss:     0.772590   Batch Accuracy:    0.859 
Iteration:    588: Loss:     0.708473   Batch Accuracy:    0.844 
Iteration:    589: Loss:     0.657957   Batch Accuracy:    0.875 
Iteration:    590: Loss:     0.814038   Batch Accuracy:    0.805 
Iteration:    591: Loss:     0.653326   Batch Accuracy:    0.883 
Iteration:    592: Loss:     0.722066   Batch Accuracy:    0.852 
Iteration:    593: Loss:     0.680982   Batch Accuracy:    0.867 
Iteration:    594: Loss:     0.841309   Batch Accuracy:    0.820 
Iteration:    595: Loss:     0.731301   Batch Accuracy:    0.852 
Iteration:    596: Loss:     0.688467   Batch Accuracy:    0.812 
Iteration:    597: Loss:     0.830989   Batch Accuracy:    0.820 
Iteration:    598: Loss:     0.763975   Batch Accuracy:    0.852 
Iteration:    599: Loss:     0.801167   Batch Accuracy:    0.828 
Iteration:    600: Loss:     0.678744   Batch Accuracy:    0.875 
Iteration:    601: Loss:     0.705281   Batch Accuracy:    0.836 
Iteration:    602: Loss:     0.813054   Batch Accuracy:    0.797 
Iteration:    603: Loss:     0.751732   Batch Accuracy:    0.836 
Iteration:    604: Loss:     0.759113   Batch Accuracy:    0.906 
Iteration:    605: Loss:     0.742755   Batch Accuracy:    0.844 
Iteration:    606: Loss:     0.790019   Batch Accuracy:    0.828 
Iteration:    607: Loss:     0.777720   Batch Accuracy:    0.836 
Iteration:    608: Loss:     0.852297   Batch Accuracy:    0.820 
Iteration:    609: Loss:     0.794978   Batch Accuracy:    0.812 
Iteration:    610: Loss:     0.698025   Batch Accuracy:    0.852 
Iteration:    611: Loss:     0.827874   Batch Accuracy:    0.812 
Iteration:    612: Loss:     0.825156   Batch Accuracy:    0.805 
Iteration:    613: Loss:     0.748844   Batch Accuracy:    0.844 
Iteration:    614: Loss:     0.635915   Batch Accuracy:    0.867 
Iteration:    615: Loss:     0.707644   Batch Accuracy:    0.875 
Iteration:    616: Loss:     0.701609   Batch Accuracy:    0.891 
Iteration:    617: Loss:     0.853572   Batch Accuracy:    0.789 
Iteration:    618: Loss:     0.697713   Batch Accuracy:    0.867 
Iteration:    619: Loss:     0.724526   Batch Accuracy:    0.859 
Iteration:    620: Loss:     0.727914   Batch Accuracy:    0.844 
Iteration:    621: Loss:     0.625910   Batch Accuracy:    0.891 
Iteration:    622: Loss:     0.796848   Batch Accuracy:    0.820 
Iteration:    623: Loss:     0.744868   Batch Accuracy:    0.844 
Iteration:    624: Loss:     0.839623   Batch Accuracy:    0.820 
Iteration:    625: Loss:     0.743100   Batch Accuracy:    0.852 
Iteration:    626: Loss:     0.804518   Batch Accuracy:    0.781 
Iteration:    627: Loss:     0.691953   Batch Accuracy:    0.867 
Iteration:    628: Loss:     0.706218   Batch Accuracy:    0.852 
Iteration:    629: Loss:     0.594214   Batch Accuracy:    0.883 
Iteration:    630: Loss:     0.676190   Batch Accuracy:    0.883 
Iteration:    631: Loss:     0.676395   Batch Accuracy:    0.852 
Iteration:    632: Loss:     0.787484   Batch Accuracy:    0.852 
Iteration:    633: Loss:     0.668949   Batch Accuracy:    0.883 
Iteration:    634: Loss:     0.723157   Batch Accuracy:    0.844 
Iteration:    635: Loss:     0.735813   Batch Accuracy:    0.852 
Iteration:    636: Loss:     0.650283   Batch Accuracy:    0.875 
Iteration:    637: Loss:     0.728650   Batch Accuracy:    0.844 
Iteration:    638: Loss:     0.653667   Batch Accuracy:    0.875 
Iteration:    639: Loss:     0.628185   Batch Accuracy:    0.875 
Iteration:    640: Loss:     0.740371   Batch Accuracy:    0.859 
Iteration:    641: Loss:     0.694760   Batch Accuracy:    0.820 
Iteration:    642: Loss:     0.673637   Batch Accuracy:    0.867 
Iteration:    643: Loss:     0.810515   Batch Accuracy:    0.797 
Iteration:    644: Loss:     0.720996   Batch Accuracy:    0.836 
Iteration:    645: Loss:     0.813531   Batch Accuracy:    0.828 
Iteration:    646: Loss:     0.703833   Batch Accuracy:    0.828 
Iteration:    647: Loss:     0.712710   Batch Accuracy:    0.852 
Iteration:    648: Loss:     0.628877   Batch Accuracy:    0.883 
Iteration:    649: Loss:     0.711047   Batch Accuracy:    0.844 
Iteration:    650: Loss:     0.746424   Batch Accuracy:    0.797 
Iteration:    651: Loss:     0.779963   Batch Accuracy:    0.812 
Iteration:    652: Loss:     0.733383   Batch Accuracy:    0.859 
Iteration:    653: Loss:     0.800833   Batch Accuracy:    0.805 
Iteration:    654: Loss:     0.684032   Batch Accuracy:    0.867 
Iteration:    655: Loss:     0.705529   Batch Accuracy:    0.820 
Iteration:    656: Loss:     0.756454   Batch Accuracy:    0.836 
Iteration:    657: Loss:     0.781699   Batch Accuracy:    0.773 
Iteration:    658: Loss:     0.697786   Batch Accuracy:    0.867 
Iteration:    659: Loss:     0.714654   Batch Accuracy:    0.836 
Iteration:    660: Loss:     0.675967   Batch Accuracy:    0.875 
Iteration:    661: Loss:     0.718202   Batch Accuracy:    0.836 
Iteration:    662: Loss:     0.684998   Batch Accuracy:    0.875 
Iteration:    663: Loss:     0.694518   Batch Accuracy:    0.820 
Iteration:    664: Loss:     0.744850   Batch Accuracy:    0.875 
Iteration:    665: Loss:     0.697210   Batch Accuracy:    0.859 
Iteration:    666: Loss:     0.753220   Batch Accuracy:    0.836 
Iteration:    667: Loss:     0.647498   Batch Accuracy:    0.875 
Iteration:    668: Loss:     0.740473   Batch Accuracy:    0.797 
Iteration:    669: Loss:     0.664436   Batch Accuracy:    0.875 
Iteration:    670: Loss:     0.810055   Batch Accuracy:    0.797 
Iteration:    671: Loss:     0.624249   Batch Accuracy:    0.875 
Iteration:    672: Loss:     0.761152   Batch Accuracy:    0.828 
Iteration:    673: Loss:     0.675760   Batch Accuracy:    0.891 
Iteration:    674: Loss:     0.676121   Batch Accuracy:    0.836 
Iteration:    675: Loss:     0.594153   Batch Accuracy:    0.930 
Iteration:    676: Loss:     0.667115   Batch Accuracy:    0.844 
Iteration:    677: Loss:     0.637662   Batch Accuracy:    0.852 
Iteration:    678: Loss:     0.695336   Batch Accuracy:    0.812 
Iteration:    679: Loss:     0.601499   Batch Accuracy:    0.875 
Iteration:    680: Loss:     0.697684   Batch Accuracy:    0.820 
Iteration:    681: Loss:     0.658806   Batch Accuracy:    0.875 
Iteration:    682: Loss:     0.714131   Batch Accuracy:    0.867 
Iteration:    683: Loss:     0.670895   Batch Accuracy:    0.883 
Iteration:    684: Loss:     0.690707   Batch Accuracy:    0.820 
Iteration:    685: Loss:     0.645959   Batch Accuracy:    0.875 
Iteration:    686: Loss:     0.778089   Batch Accuracy:    0.820 
Iteration:    687: Loss:     0.718784   Batch Accuracy:    0.875 
Iteration:    688: Loss:     0.740696   Batch Accuracy:    0.820 
Iteration:    689: Loss:     0.718685   Batch Accuracy:    0.836 
Iteration:    690: Loss:     0.682224   Batch Accuracy:    0.867 
Iteration:    691: Loss:     0.817503   Batch Accuracy:    0.828 
Iteration:    692: Loss:     0.616013   Batch Accuracy:    0.898 
Iteration:    693: Loss:     0.810477   Batch Accuracy:    0.781 
Iteration:    694: Loss:     0.766302   Batch Accuracy:    0.836 
Iteration:    695: Loss:     0.785610   Batch Accuracy:    0.805 
Iteration:    696: Loss:     0.706216   Batch Accuracy:    0.859 
Iteration:    697: Loss:     0.693796   Batch Accuracy:    0.852 
Iteration:    698: Loss:     0.723909   Batch Accuracy:    0.859 
Iteration:    699: Loss:     0.767419   Batch Accuracy:    0.812 
Iteration:    700: Loss:     0.686163   Batch Accuracy:    0.859 
Iteration:    701: Loss:     0.643470   Batch Accuracy:    0.891 
Iteration:    702: Loss:     0.744015   Batch Accuracy:    0.812 
Iteration:    703: Loss:     0.688454   Batch Accuracy:    0.867 
Iteration:    704: Loss:     0.721055   Batch Accuracy:    0.844 
Iteration:    705: Loss:     0.698652   Batch Accuracy:    0.828 
Iteration:    706: Loss:     0.845582   Batch Accuracy:    0.773 
Iteration:    707: Loss:     0.583038   Batch Accuracy:    0.898 
Iteration:    708: Loss:     0.767944   Batch Accuracy:    0.820 
Iteration:    709: Loss:     0.689535   Batch Accuracy:    0.891 
Iteration:    710: Loss:     0.709780   Batch Accuracy:    0.820 
Iteration:    711: Loss:     0.691578   Batch Accuracy:    0.875 
Iteration:    712: Loss:     0.780010   Batch Accuracy:    0.812 
Iteration:    713: Loss:     0.723446   Batch Accuracy:    0.844 
Iteration:    714: Loss:     0.676332   Batch Accuracy:    0.820 
Iteration:    715: Loss:     0.591788   Batch Accuracy:    0.891 
Iteration:    716: Loss:     0.789522   Batch Accuracy:    0.805 
Iteration:    717: Loss:     0.634784   Batch Accuracy:    0.891 
Iteration:    718: Loss:     0.693611   Batch Accuracy:    0.836 
Iteration:    719: Loss:     0.733224   Batch Accuracy:    0.836 
Iteration:    720: Loss:     0.708128   Batch Accuracy:    0.844 
Iteration:    721: Loss:     0.685691   Batch Accuracy:    0.852 
Iteration:    722: Loss:     0.681941   Batch Accuracy:    0.883 
Iteration:    723: Loss:     0.626208   Batch Accuracy:    0.883 
Iteration:    724: Loss:     0.696513   Batch Accuracy:    0.867 
Iteration:    725: Loss:     0.672626   Batch Accuracy:    0.875 
Iteration:    726: Loss:     0.663019   Batch Accuracy:    0.883 
Iteration:    727: Loss:     0.579842   Batch Accuracy:    0.906 
Iteration:    728: Loss:     0.675504   Batch Accuracy:    0.867 
Iteration:    729: Loss:     0.734121   Batch Accuracy:    0.828 
Iteration:    730: Loss:     0.804768   Batch Accuracy:    0.812 
Iteration:    731: Loss:     0.553848   Batch Accuracy:    0.922 
Iteration:    732: Loss:     0.610805   Batch Accuracy:    0.891 
Iteration:    733: Loss:     0.719955   Batch Accuracy:    0.852 
Iteration:    734: Loss:     0.695165   Batch Accuracy:    0.875 
Iteration:    735: Loss:     0.713029   Batch Accuracy:    0.836 
Iteration:    736: Loss:     0.730122   Batch Accuracy:    0.859 
Iteration:    737: Loss:     0.619199   Batch Accuracy:    0.891 
Iteration:    738: Loss:     0.677656   Batch Accuracy:    0.875 
Iteration:    739: Loss:     0.697495   Batch Accuracy:    0.820 
Iteration:    740: Loss:     0.602352   Batch Accuracy:    0.867 
Iteration:    741: Loss:     0.734858   Batch Accuracy:    0.812 
Iteration:    742: Loss:     0.635518   Batch Accuracy:    0.859 
Iteration:    743: Loss:     0.619325   Batch Accuracy:    0.883 
Iteration:    744: Loss:     0.605819   Batch Accuracy:    0.852 
Iteration:    745: Loss:     0.720332   Batch Accuracy:    0.875 
Iteration:    746: Loss:     0.603885   Batch Accuracy:    0.898 
Iteration:    747: Loss:     0.660510   Batch Accuracy:    0.844 
Iteration:    748: Loss:     0.574241   Batch Accuracy:    0.914 
Iteration:    749: Loss:     0.703466   Batch Accuracy:    0.859 
Iteration:    750: Loss:     0.675903   Batch Accuracy:    0.852 
Iteration:    751: Loss:     0.644289   Batch Accuracy:    0.883 
Iteration:    752: Loss:     0.622355   Batch Accuracy:    0.898 
Iteration:    753: Loss:     0.698640   Batch Accuracy:    0.844 
Iteration:    754: Loss:     0.669609   Batch Accuracy:    0.820 
Iteration:    755: Loss:     0.672744   Batch Accuracy:    0.859 
Iteration:    756: Loss:     0.697873   Batch Accuracy:    0.859 
Iteration:    757: Loss:     0.690787   Batch Accuracy:    0.828 
Iteration:    758: Loss:     0.629967   Batch Accuracy:    0.867 
Iteration:    759: Loss:     0.781352   Batch Accuracy:    0.773 
Iteration:    760: Loss:     0.611183   Batch Accuracy:    0.875 
Iteration:    761: Loss:     0.635455   Batch Accuracy:    0.867 
Iteration:    762: Loss:     0.674543   Batch Accuracy:    0.836 
Iteration:    763: Loss:     0.643506   Batch Accuracy:    0.852 
Iteration:    764: Loss:     0.760862   Batch Accuracy:    0.797 
Iteration:    765: Loss:     0.761584   Batch Accuracy:    0.781 
Iteration:    766: Loss:     0.686433   Batch Accuracy:    0.844 
Iteration:    767: Loss:     0.617945   Batch Accuracy:    0.859 
Iteration:    768: Loss:     0.673728   Batch Accuracy:    0.836 
Iteration:    769: Loss:     0.648882   Batch Accuracy:    0.891 
Iteration:    770: Loss:     0.776538   Batch Accuracy:    0.805 
Iteration:    771: Loss:     0.623963   Batch Accuracy:    0.875 
Iteration:    772: Loss:     0.694824   Batch Accuracy:    0.836 
Iteration:    773: Loss:     0.748553   Batch Accuracy:    0.820 
Iteration:    774: Loss:     0.690703   Batch Accuracy:    0.805 
Iteration:    775: Loss:     0.672968   Batch Accuracy:    0.852 
Iteration:    776: Loss:     0.721136   Batch Accuracy:    0.844 
Iteration:    777: Loss:     0.629475   Batch Accuracy:    0.883 
Iteration:    778: Loss:     0.640148   Batch Accuracy:    0.891 
Iteration:    779: Loss:     0.627221   Batch Accuracy:    0.867 
Iteration:    780: Loss:     0.674427   Batch Accuracy:    0.836 
Iteration:    781: Loss:     0.691447   Batch Accuracy:    0.859 
Iteration:    782: Loss:     0.692561   Batch Accuracy:    0.828 
Iteration:    783: Loss:     0.638397   Batch Accuracy:    0.875 
Iteration:    784: Loss:     0.594722   Batch Accuracy:    0.867 
Iteration:    785: Loss:     0.634842   Batch Accuracy:    0.867 
Iteration:    786: Loss:     0.677843   Batch Accuracy:    0.898 
Iteration:    787: Loss:     0.630804   Batch Accuracy:    0.891 
Iteration:    788: Loss:     0.682524   Batch Accuracy:    0.844 
Iteration:    789: Loss:     0.605688   Batch Accuracy:    0.914 
Iteration:    790: Loss:     0.695384   Batch Accuracy:    0.820 
Iteration:    791: Loss:     0.677705   Batch Accuracy:    0.844 
Iteration:    792: Loss:     0.660180   Batch Accuracy:    0.852 
Iteration:    793: Loss:     0.705069   Batch Accuracy:    0.812 
Iteration:    794: Loss:     0.696023   Batch Accuracy:    0.828 
Iteration:    795: Loss:     0.518295   Batch Accuracy:    0.922 
Iteration:    796: Loss:     0.646057   Batch Accuracy:    0.867 
Iteration:    797: Loss:     0.686568   Batch Accuracy:    0.883 
Iteration:    798: Loss:     0.731887   Batch Accuracy:    0.836 
Iteration:    799: Loss:     0.692755   Batch Accuracy:    0.828 
Iteration:    800: Loss:     0.633381   Batch Accuracy:    0.891 
Iteration:    801: Loss:     0.720023   Batch Accuracy:    0.781 
Iteration:    802: Loss:     0.655780   Batch Accuracy:    0.867 
Iteration:    803: Loss:     0.641553   Batch Accuracy:    0.797 
Iteration:    804: Loss:     0.692455   Batch Accuracy:    0.828 
Iteration:    805: Loss:     0.735110   Batch Accuracy:    0.797 
Iteration:    806: Loss:     0.709036   Batch Accuracy:    0.828 
Iteration:    807: Loss:     0.804860   Batch Accuracy:    0.805 
Iteration:    808: Loss:     0.607601   Batch Accuracy:    0.891 
Iteration:    809: Loss:     0.643666   Batch Accuracy:    0.875 
Iteration:    810: Loss:     0.633400   Batch Accuracy:    0.867 
Iteration:    811: Loss:     0.645093   Batch Accuracy:    0.859 
Iteration:    812: Loss:     0.636712   Batch Accuracy:    0.836 
Iteration:    813: Loss:     0.533457   Batch Accuracy:    0.906 
Iteration:    814: Loss:     0.644283   Batch Accuracy:    0.883 
Iteration:    815: Loss:     0.696176   Batch Accuracy:    0.836 
Iteration:    816: Loss:     0.708022   Batch Accuracy:    0.836 
Iteration:    817: Loss:     0.730660   Batch Accuracy:    0.797 
Iteration:    818: Loss:     0.666128   Batch Accuracy:    0.852 
Iteration:    819: Loss:     0.595988   Batch Accuracy:    0.875 
Iteration:    820: Loss:     0.639825   Batch Accuracy:    0.836 
Iteration:    821: Loss:     0.663703   Batch Accuracy:    0.836 
Iteration:    822: Loss:     0.566094   Batch Accuracy:    0.891 
Iteration:    823: Loss:     0.640216   Batch Accuracy:    0.852 
Iteration:    824: Loss:     0.727001   Batch Accuracy:    0.836 
Iteration:    825: Loss:     0.711353   Batch Accuracy:    0.844 
Iteration:    826: Loss:     0.643926   Batch Accuracy:    0.859 
Iteration:    827: Loss:     0.602502   Batch Accuracy:    0.859 
Iteration:    828: Loss:     0.760128   Batch Accuracy:    0.852 
Iteration:    829: Loss:     0.767216   Batch Accuracy:    0.797 
Iteration:    830: Loss:     0.643416   Batch Accuracy:    0.852 
Iteration:    831: Loss:     0.684297   Batch Accuracy:    0.828 
Iteration:    832: Loss:     0.699066   Batch Accuracy:    0.844 
Iteration:    833: Loss:     0.694979   Batch Accuracy:    0.836 
Iteration:    834: Loss:     0.628160   Batch Accuracy:    0.867 
Iteration:    835: Loss:     0.682889   Batch Accuracy:    0.852 
Iteration:    836: Loss:     0.732713   Batch Accuracy:    0.805 
Iteration:    837: Loss:     0.609153   Batch Accuracy:    0.875 
Iteration:    838: Loss:     0.665302   Batch Accuracy:    0.852 
Iteration:    839: Loss:     0.607213   Batch Accuracy:    0.859 
Iteration:    840: Loss:     0.642807   Batch Accuracy:    0.844 
Iteration:    841: Loss:     0.683239   Batch Accuracy:    0.836 
Iteration:    842: Loss:     0.708006   Batch Accuracy:    0.836 
Iteration:    843: Loss:     0.701287   Batch Accuracy:    0.812 
Iteration:    844: Loss:     0.644625   Batch Accuracy:    0.852 
Iteration:    845: Loss:     0.594256   Batch Accuracy:    0.844 
Iteration:    846: Loss:     0.572789   Batch Accuracy:    0.867 
Iteration:    847: Loss:     0.594745   Batch Accuracy:    0.891 
Iteration:    848: Loss:     0.678021   Batch Accuracy:    0.812 
Iteration:    849: Loss:     0.647911   Batch Accuracy:    0.859 
Iteration:    850: Loss:     0.694141   Batch Accuracy:    0.859 
Iteration:    851: Loss:     0.548980   Batch Accuracy:    0.914 
Iteration:    852: Loss:     0.587904   Batch Accuracy:    0.836 
Iteration:    853: Loss:     0.695963   Batch Accuracy:    0.836 
Iteration:    854: Loss:     0.686243   Batch Accuracy:    0.828 
Iteration:    855: Loss:     0.689295   Batch Accuracy:    0.820 
Iteration:    856: Loss:     0.668295   Batch Accuracy:    0.828 
Iteration:    857: Loss:     0.634245   Batch Accuracy:    0.844 
Iteration:    858: Loss:     0.654122   Batch Accuracy:    0.820 
Iteration:    859: Loss:     0.679571   Batch Accuracy:    0.828 
Iteration:    860: Loss:     0.663000   Batch Accuracy:    0.859 
Iteration:    861: Loss:     0.617111   Batch Accuracy:    0.898 
Iteration:    862: Loss:     0.670245   Batch Accuracy:    0.844 
Iteration:    863: Loss:     0.669774   Batch Accuracy:    0.883 
Iteration:    864: Loss:     0.623916   Batch Accuracy:    0.867 
Iteration:    865: Loss:     0.595517   Batch Accuracy:    0.898 
Iteration:    866: Loss:     0.598850   Batch Accuracy:    0.875 
Iteration:    867: Loss:     0.653365   Batch Accuracy:    0.844 
Iteration:    868: Loss:     0.583607   Batch Accuracy:    0.875 
Iteration:    869: Loss:     0.670211   Batch Accuracy:    0.820 
Iteration:    870: Loss:     0.597120   Batch Accuracy:    0.867 
Iteration:    871: Loss:     0.608125   Batch Accuracy:    0.859 
Iteration:    872: Loss:     0.649447   Batch Accuracy:    0.852 
Iteration:    873: Loss:     0.595894   Batch Accuracy:    0.883 
Iteration:    874: Loss:     0.588363   Batch Accuracy:    0.844 
Iteration:    875: Loss:     0.575320   Batch Accuracy:    0.867 
Iteration:    876: Loss:     0.569118   Batch Accuracy:    0.875 
Iteration:    877: Loss:     0.755878   Batch Accuracy:    0.852 
Iteration:    878: Loss:     0.562485   Batch Accuracy:    0.883 
Iteration:    879: Loss:     0.718451   Batch Accuracy:    0.781 
Iteration:    880: Loss:     0.721006   Batch Accuracy:    0.828 
Iteration:    881: Loss:     0.711091   Batch Accuracy:    0.828 
Iteration:    882: Loss:     0.612861   Batch Accuracy:    0.875 
Iteration:    883: Loss:     0.651913   Batch Accuracy:    0.852 
Iteration:    884: Loss:     0.671730   Batch Accuracy:    0.852 
Iteration:    885: Loss:     0.566314   Batch Accuracy:    0.906 
Iteration:    886: Loss:     0.630329   Batch Accuracy:    0.844 
Iteration:    887: Loss:     0.566414   Batch Accuracy:    0.891 
Iteration:    888: Loss:     0.648473   Batch Accuracy:    0.867 
Iteration:    889: Loss:     0.566614   Batch Accuracy:    0.906 
Iteration:    890: Loss:     0.607743   Batch Accuracy:    0.852 
Iteration:    891: Loss:     0.555841   Batch Accuracy:    0.891 
Iteration:    892: Loss:     0.589241   Batch Accuracy:    0.875 
Iteration:    893: Loss:     0.551748   Batch Accuracy:    0.883 
Iteration:    894: Loss:     0.750423   Batch Accuracy:    0.844 
Iteration:    895: Loss:     0.558769   Batch Accuracy:    0.867 
Iteration:    896: Loss:     0.686513   Batch Accuracy:    0.852 
Iteration:    897: Loss:     0.566280   Batch Accuracy:    0.891 
Iteration:    898: Loss:     0.684062   Batch Accuracy:    0.836 
Iteration:    899: Loss:     0.608348   Batch Accuracy:    0.852 
Iteration:    900: Loss:     0.622710   Batch Accuracy:    0.867 
Iteration:    901: Loss:     0.530704   Batch Accuracy:    0.898 
Iteration:    902: Loss:     0.666391   Batch Accuracy:    0.836 
Iteration:    903: Loss:     0.679654   Batch Accuracy:    0.805 
Iteration:    904: Loss:     0.600894   Batch Accuracy:    0.891 
Iteration:    905: Loss:     0.550347   Batch Accuracy:    0.883 
Iteration:    906: Loss:     0.579823   Batch Accuracy:    0.852 
Iteration:    907: Loss:     0.603280   Batch Accuracy:    0.883 
Iteration:    908: Loss:     0.600055   Batch Accuracy:    0.883 
Iteration:    909: Loss:     0.550096   Batch Accuracy:    0.867 
Iteration:    910: Loss:     0.479146   Batch Accuracy:    0.938 
Iteration:    911: Loss:     0.478200   Batch Accuracy:    0.906 
Iteration:    912: Loss:     0.641957   Batch Accuracy:    0.859 
Iteration:    913: Loss:     0.692064   Batch Accuracy:    0.812 
Iteration:    914: Loss:     0.720406   Batch Accuracy:    0.805 
Iteration:    915: Loss:     0.719660   Batch Accuracy:    0.820 
Iteration:    916: Loss:     0.658148   Batch Accuracy:    0.828 
Iteration:    917: Loss:     0.634242   Batch Accuracy:    0.859 
Iteration:    918: Loss:     0.597702   Batch Accuracy:    0.867 
Iteration:    919: Loss:     0.535691   Batch Accuracy:    0.922 
Iteration:    920: Loss:     0.703713   Batch Accuracy:    0.797 
Iteration:    921: Loss:     0.534568   Batch Accuracy:    0.875 
Iteration:    922: Loss:     0.576750   Batch Accuracy:    0.867 
Iteration:    923: Loss:     0.676072   Batch Accuracy:    0.844 
Iteration:    924: Loss:     0.650473   Batch Accuracy:    0.875 
Iteration:    925: Loss:     0.581954   Batch Accuracy:    0.836 
Iteration:    926: Loss:     0.667865   Batch Accuracy:    0.867 
Iteration:    927: Loss:     0.743364   Batch Accuracy:    0.805 
Iteration:    928: Loss:     0.792528   Batch Accuracy:    0.758 
Iteration:    929: Loss:     0.639422   Batch Accuracy:    0.859 
Iteration:    930: Loss:     0.596132   Batch Accuracy:    0.883 
Iteration:    931: Loss:     0.681229   Batch Accuracy:    0.844 
Iteration:    932: Loss:     0.596723   Batch Accuracy:    0.898 
Iteration:    933: Loss:     0.585606   Batch Accuracy:    0.875 
Iteration:    934: Loss:     0.664648   Batch Accuracy:    0.828 
Iteration:    935: Loss:     0.538372   Batch Accuracy:    0.914 
Iteration:    936: Loss:     0.662118   Batch Accuracy:    0.859 
Iteration:    937: Loss:     0.657431   Batch Accuracy:    0.805 
Iteration:    938: Loss:     0.766425   Batch Accuracy:    0.820 
Iteration:    939: Loss:     0.609987   Batch Accuracy:    0.859 
Iteration:    940: Loss:     0.693136   Batch Accuracy:    0.844 
Iteration:    941: Loss:     0.585825   Batch Accuracy:    0.859 
Iteration:    942: Loss:     0.631805   Batch Accuracy:    0.844 
Iteration:    943: Loss:     0.604382   Batch Accuracy:    0.875 
Iteration:    944: Loss:     0.585840   Batch Accuracy:    0.828 
Iteration:    945: Loss:     0.639712   Batch Accuracy:    0.859 
Iteration:    946: Loss:     0.714131   Batch Accuracy:    0.812 
Iteration:    947: Loss:     0.511057   Batch Accuracy:    0.914 
Iteration:    948: Loss:     0.621605   Batch Accuracy:    0.867 
Iteration:    949: Loss:     0.674252   Batch Accuracy:    0.828 
Iteration:    950: Loss:     0.660066   Batch Accuracy:    0.797 
Iteration:    951: Loss:     0.645238   Batch Accuracy:    0.820 
Iteration:    952: Loss:     0.519938   Batch Accuracy:    0.898 
Iteration:    953: Loss:     0.642307   Batch Accuracy:    0.836 
Iteration:    954: Loss:     0.698182   Batch Accuracy:    0.828 
Iteration:    955: Loss:     0.688755   Batch Accuracy:    0.859 
Iteration:    956: Loss:     0.680140   Batch Accuracy:    0.852 
Iteration:    957: Loss:     0.614889   Batch Accuracy:    0.859 
Iteration:    958: Loss:     0.635307   Batch Accuracy:    0.828 
Iteration:    959: Loss:     0.636605   Batch Accuracy:    0.836 
Iteration:    960: Loss:     0.525805   Batch Accuracy:    0.914 
Iteration:    961: Loss:     0.593107   Batch Accuracy:    0.875 
Iteration:    962: Loss:     0.584660   Batch Accuracy:    0.898 
Iteration:    963: Loss:     0.609204   Batch Accuracy:    0.883 
Iteration:    964: Loss:     0.517735   Batch Accuracy:    0.922 
Iteration:    965: Loss:     0.618405   Batch Accuracy:    0.867 
Iteration:    966: Loss:     0.602397   Batch Accuracy:    0.875 
Iteration:    967: Loss:     0.611049   Batch Accuracy:    0.875 
Iteration:    968: Loss:     0.773191   Batch Accuracy:    0.781 
Iteration:    969: Loss:     0.785054   Batch Accuracy:    0.812 
Iteration:    970: Loss:     0.540549   Batch Accuracy:    0.883 
Iteration:    971: Loss:     0.671748   Batch Accuracy:    0.836 
Iteration:    972: Loss:     0.672957   Batch Accuracy:    0.812 
Iteration:    973: Loss:     0.622496   Batch Accuracy:    0.891 
Iteration:    974: Loss:     0.674391   Batch Accuracy:    0.812 
Iteration:    975: Loss:     0.695212   Batch Accuracy:    0.805 
Iteration:    976: Loss:     0.576402   Batch Accuracy:    0.867 
Iteration:    977: Loss:     0.666433   Batch Accuracy:    0.867 
Iteration:    978: Loss:     0.617854   Batch Accuracy:    0.859 
Iteration:    979: Loss:     0.597434   Batch Accuracy:    0.867 
Iteration:    980: Loss:     0.626782   Batch Accuracy:    0.859 
Iteration:    981: Loss:     0.633046   Batch Accuracy:    0.852 
Iteration:    982: Loss:     0.530258   Batch Accuracy:    0.883 
Iteration:    983: Loss:     0.681658   Batch Accuracy:    0.789 
Iteration:    984: Loss:     0.568259   Batch Accuracy:    0.883 
Iteration:    985: Loss:     0.659744   Batch Accuracy:    0.852 
Iteration:    986: Loss:     0.574092   Batch Accuracy:    0.883 
Iteration:    987: Loss:     0.586905   Batch Accuracy:    0.867 
Iteration:    988: Loss:     0.650414   Batch Accuracy:    0.844 
Iteration:    989: Loss:     0.621430   Batch Accuracy:    0.852 
Iteration:    990: Loss:     0.654705   Batch Accuracy:    0.805 
Iteration:    991: Loss:     0.640276   Batch Accuracy:    0.852 
Iteration:    992: Loss:     0.589788   Batch Accuracy:    0.852 
Iteration:    993: Loss:     0.627008   Batch Accuracy:    0.812 
Iteration:    994: Loss:     0.564542   Batch Accuracy:    0.883 
Iteration:    995: Loss:     0.571102   Batch Accuracy:    0.891 
Iteration:    996: Loss:     0.629671   Batch Accuracy:    0.883 
Iteration:    997: Loss:     0.485444   Batch Accuracy:    0.875 
Iteration:    998: Loss:     0.574017   Batch Accuracy:    0.867 
Iteration:    999: Loss:     0.739483   Batch Accuracy:    0.781 
evaluating model...
training accuracy: 0.856700
test accuracy:     0.866900
(base) Jasons-MacBook-Pro:cse576_sp20_hw3 jasonhoffman$ 
